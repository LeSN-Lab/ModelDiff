{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "from benchmark import ImageBenchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t pretrain(mbnetv2,ImageNet)-\n",
      "1\t pretrain(resnet18,ImageNet)-\n",
      "8\t pretrain(mbnetv2,ImageNet)-transfer(MIT67,0.1)-\n",
      "9\t pretrain(mbnetv2,ImageNet)-transfer(MIT67,0.5)-\n",
      "10\t pretrain(mbnetv2,ImageNet)-transfer(MIT67,1)-\n",
      "11\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "12\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "13\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "14\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "15\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "16\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "17\t pretrain(resnet18,ImageNet)-transfer(MIT67,0.1)-\n",
      "18\t pretrain(resnet18,ImageNet)-transfer(MIT67,0.5)-\n",
      "19\t pretrain(resnet18,ImageNet)-transfer(MIT67,1)-\n",
      "20\t pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "21\t pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "22\t pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "23\t pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "24\t pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "25\t pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n"
     ]
    }
   ],
   "source": [
    "bench = ImageBenchmark()\n",
    "models = list(bench.list_models())\n",
    "for i, model in enumerate(models):\n",
    "    if not model.torch_model_exists():\n",
    "        continue\n",
    "    print(f'{i}\\t {model.__str__()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeldiff import ModelDiff\n",
    "\n",
    "def compare_with_seed(model1, model2, truth=-1):\n",
    "    print(f'comparing:\\n  model1={model1}\\n  model2={model2}')\n",
    "    md = ModelDiff(model1, model2)\n",
    "    seed_inputs = md.get_seed_inputs(rand=False)\n",
    "    sim = md._compute_distance(seed_inputs)\n",
    "    if truth == -1:\n",
    "        truth = 1 if model1.__str__().split('-')[0] == model2.__str__().split('-')[0] else 0\n",
    "    print(f' similarity is {sim}, truth is {truth}')\n",
    "\n",
    "def test(compare):\n",
    "    compare(models[1], models[0], 0)   # should be different\n",
    "    compare(models[13], models[25], 0) # should be different\n",
    "    compare(models[13], models[22], 0) # should be different\n",
    "    compare(models[1], models[17], 1)  # should be similar\n",
    "    compare(models[16], models[13], 1) # should be similar\n",
    "    compare(models[13], models[12], 1) # should be similar\n",
    "    \n",
    "# test(compare_with_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comparing:\n",
      "  model1=pretrain(resnet18,ImageNet)-\n",
      "  model2=pretrain(mbnetv2,ImageNet)-\n",
      " similarity is 0.9385082105626885, truth is 0\n",
      "  batch_preds1=tensor([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0, 179, 925, 925, 825, 293, 912, 817,  31, 563, 241, 202, 925,\n",
      "        925, 435, 985, 925, 879, 925, 326, 811, 925, 985, 817, 925, 925, 925,\n",
      "         31, 925, 811, 925, 985, 985, 825, 563, 925, 925, 825, 478, 925, 925,\n",
      "        925, 310, 825, 925, 925, 720, 925, 563, 825, 925, 811, 199, 705, 817,\n",
      "        985, 241, 925, 925,  31, 563, 825, 734, 199, 563, 879, 442, 872, 625,\n",
      "        734, 925, 825, 925, 925, 817, 925, 817, 563, 925, 925, 925, 925, 822,\n",
      "        925, 563, 817, 925, 925, 705, 705, 735, 241, 925, 535, 925, 925, 811,\n",
      "        811, 925, 276, 817])\n",
      "  batch_preds2=tensor([692, 692, 310, 692, 542, 692,  15, 692, 336, 336, 336, 802, 692, 692,\n",
      "        285,  15, 692, 191, 765, 692, 692, 388, 692, 336, 336,  15, 201, 692,\n",
      "        692, 505, 565, 366, 692, 169, 692, 692, 336, 692,  34, 792, 692, 247,\n",
      "        643, 692, 366, 765, 965, 287,  15, 749, 692, 851, 336, 692, 201, 692,\n",
      "         34, 336,  34, 692, 692, 692,  15,  34,  34, 278, 366,  34, 191, 581,\n",
      "         34, 792, 359, 643, 692, 792, 327,  34, 336,  34, 851, 692, 285, 201,\n",
      "        692, 201, 327,  15, 227, 692,  15, 366, 336, 336, 487, 285,  15, 103,\n",
      "        336, 692,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0])\n",
      "comparing:\n",
      "  model1=pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "  model2=pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      " similarity is 0.9792573506573704, truth is 0\n",
      "  batch_preds1=tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 67,  8, 67, 67, 34, 34, 67, 34,\n",
      "        67, 67,  8, 67,  2,  8, 34, 25, 67, 25, 34, 22, 34, 78, 97, 67, 67, 74,\n",
      "        74, 34, 97, 67, 34, 42,  8, 67, 67, 34, 97,  8, 25, 81,  8, 34,  8, 76,\n",
      "        34, 34, 67,  8,  3, 74, 67,  8, 74, 74, 67, 74, 67,  7, 34, 74, 74, 53,\n",
      "        67, 67, 74,  8, 67,  7, 97, 67,  8, 67, 53,  8, 90, 67, 67, 67, 67,  8,\n",
      "        34, 67, 67, 67, 67,  2, 67, 67, 67, 67, 74, 34, 74, 74, 67, 13, 74, 67,\n",
      "        67, 74])\n",
      "  batch_preds2=tensor([107, 107,   0,   2,   2,  53,   2,  60,  27, 107,   2,   0,  60,  27,\n",
      "          0, 113,  27,   2,  36,  70, 100,   2,   0,  27, 113,   0,  36,  17,\n",
      "          2,  60,  27,  69,  27,  94, 113,  60,   0,   2,  36,   2,   2,   2,\n",
      "         36,   0, 119,  79,   2,   0,   0,  20,   2,   2,  20,  60,  60,   2,\n",
      "        113,  20,   0, 107,   0,  27,   0,  36, 113,   0,  32,  36,   2, 113,\n",
      "         85,   2,  77, 113,   2,   2,  36,  94,  36,  38,   2, 113,   2,  20,\n",
      "          2,  64,  32,  20,   2,   0, 113,  20, 115, 100,   2,  60,  94,  77,\n",
      "         36,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0])\n",
      "comparing:\n",
      "  model1=pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "  model2=pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda'\n",
    "\n",
    "def gen_adv_inputs(model, inputs):\n",
    "    from advertorch.attacks import LinfPGDAttack\n",
    "    def myloss(yhat, y):\n",
    "        return -((yhat[:,0]-y[:,0])**2 + 0.1*((yhat[:,1:]-y[:,1:])**2).mean(1)).mean()\n",
    "        \n",
    "    model = model.to(DEVICE)\n",
    "    inputs = torch.from_numpy(inputs).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        clean_outputs = model(inputs)\n",
    "    \n",
    "    output_shape = clean_outputs.shape\n",
    "    batch_size = output_shape[0]\n",
    "    num_classes = output_shape[1]\n",
    "    y = torch.zeros(size=output_shape).to(DEVICE)\n",
    "    y[:, 0] = 1000\n",
    "#     # more diversity\n",
    "#     rand_idx = torch.randint(low=0, high=num_classes, size=(batch_size,))\n",
    "#     y = torch.nn.functional.one_hot(rand_idx, num_classes=num_classes).to(DEVICE) * 1000\n",
    "#     print(y)\n",
    "    \n",
    "    adversary = LinfPGDAttack(\n",
    "        model, loss_fn=myloss, eps=0.1,\n",
    "        nb_iter=40, eps_iter=0.01, \n",
    "        rand_init=True, clip_min=-2.2, clip_max=2.2,\n",
    "        targeted=False\n",
    "    )\n",
    "    \n",
    "    adv_inputs = adversary.perturb(inputs, y)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        adv_outputs = model(adv_inputs).to('cpu').numpy()\n",
    "#     print(adv_outputs)\n",
    "    torch.cuda.empty_cache()\n",
    "    return adv_inputs.to('cpu').numpy()\n",
    "\n",
    "\n",
    "def compare_with_adv(model1, model2, truth=-1):\n",
    "    print(f'comparing:\\n  model1={model1}\\n  model2={model2}')\n",
    "    md = ModelDiff(model1, model2)\n",
    "    rand = False\n",
    "    seed_inputs1 = model1.get_seed_inputs(100, rand=rand)\n",
    "    seed_inputs2 = model2.get_seed_inputs(100, rand=rand)\n",
    "    seed_inputs = np.concatenate([seed_inputs1, seed_inputs2])\n",
    "    \n",
    "    adv_inputs1 = gen_adv_inputs(model1.torch_model, seed_inputs1)\n",
    "    adv_inputs2 = gen_adv_inputs(model2.torch_model, seed_inputs2)\n",
    "    adv_inputs = np.concatenate([adv_inputs1, adv_inputs2])\n",
    "    \n",
    "    adv_inputs_shuffle = list(adv_inputs)\n",
    "    np.random.shuffle(adv_inputs_shuffle)\n",
    "    adv_inputs_shuffle = np.array(adv_inputs_shuffle)\n",
    "    \n",
    "    sim = md._compute_distance(adv_inputs_shuffle)\n",
    "    if truth == -1:\n",
    "        truth = 1 if model1.__str__().split('-')[0] == model2.__str__().split('-')[0] else 0\n",
    "    print(f' similarity is {sim}, truth is {truth}')\n",
    "    batch_outputs1 = model1.batch_forward(adv_inputs)\n",
    "    _, batch_preds1 = batch_outputs1.to('cpu').data.max(1)\n",
    "    batch_outputs2 = model2.batch_forward(adv_inputs)\n",
    "    _, batch_preds2 = batch_outputs2.to('cpu').data.max(1)\n",
    "    print(f'  batch_preds1={batch_preds1}\\n  batch_preds2={batch_preds2}')\n",
    "\n",
    "\n",
    "# compare_with_adv(models[1], models[17], 1)\n",
    "test(compare_with_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Utils\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def show_images(images, labels, title='examples'):\n",
    "    images = np.transpose(images, (0, 2, 3, 1))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "    for n in range(25):\n",
    "        plt.subplot(5,5,n+1)\n",
    "        img = images[n]\n",
    "        img = img.squeeze()\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'{labels[n]}')\n",
    "        plt.axis('off')\n",
    "    _ = plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "# show_images(seed_inputs, list(range(seed_inputs.shape[0])))\n",
    "# print(seed_inputs[0])\n",
    "# batch_outputs1 = model1.batch_forward(seed_inputs)\n",
    "# batch_preds1 = batch_outputs1.to('cpu').data.max(1)\n",
    "# print(batch_preds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
