{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(name)-12s %(levelname)-8s %(message)s\")\n",
    "\n",
    "from benchmark import ImageBenchmark\n",
    "bench = ImageBenchmark()\n",
    "models = list(bench.list_models())\n",
    "models_dict = {}\n",
    "for i, model in enumerate(models):\n",
    "    if not model.torch_model_exists():\n",
    "        continue\n",
    "    print(f'{i}\\t {model.__str__()}')\n",
    "    models_dict[model.__str__()] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeldiff import ModelDiff\n",
    "\n",
    "def compare_with_seed(model1, model2, truth=-1):\n",
    "    print(f'comparing:\\n  model1={model1}\\n  model2={model2}')\n",
    "    md = ModelDiff(model1, model2)\n",
    "    seed_inputs = md.get_seed_inputs(rand=False)\n",
    "    sim = md.compute_similarity_with_inputs(seed_inputs)\n",
    "    if truth == -1:\n",
    "        truth = 1 if model1.__str__().split('-')[0] == model2.__str__().split('-')[0] else 0\n",
    "    print(f' similarity is {sim}, truth is {truth}')\n",
    "\n",
    "def test(compare):\n",
    "    # compare(models[23], models[38], 1) # should be similar\n",
    "    compare(models[1], models[0], 0)   # should be different\n",
    "#     compare(models[13], models[25], 0) # should be different\n",
    "#     compare(models[13], models[22], 0) # should be different\n",
    "    compare(models[1], models[17], 1)  # should be similar\n",
    "    compare(models[16], models[13], 1) # should be similar\n",
    "    compare(models[13], models[12], 1) # should be similar\n",
    "    \n",
    "# test(compare_with_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'\n",
    "\n",
    "def gen_adv_inputs(model, inputs):\n",
    "    from advertorch.attacks import LinfPGDAttack\n",
    "    def myloss(yhat, y):\n",
    "        return -((yhat[:,0]-y[:,0])**2 + 0.1*((yhat[:,1:]-y[:,1:])**2).mean(1)).mean()\n",
    "        \n",
    "    model = model.to(DEVICE)\n",
    "    inputs = torch.from_numpy(inputs).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        clean_outputs = model(inputs)\n",
    "    \n",
    "    output_shape = clean_outputs.shape\n",
    "    batch_size = output_shape[0]\n",
    "    num_classes = output_shape[1]\n",
    "    \n",
    "    y = torch.zeros(size=output_shape).to(DEVICE)\n",
    "    y[:, 0] = 1000\n",
    "    # more diversity\n",
    "#     rand_idx = torch.randint(low=0, high=num_classes, size=(batch_size,))\n",
    "#     y = torch.nn.functional.one_hot(rand_idx, num_classes=num_classes).to(DEVICE) * 10\n",
    "#     print(y)\n",
    "    \n",
    "    adversary = LinfPGDAttack(\n",
    "        model, loss_fn=myloss, eps=0.1,\n",
    "        nb_iter=40, eps_iter=0.01, \n",
    "        rand_init=True, clip_min=-2.2, clip_max=2.2,\n",
    "        targeted=False\n",
    "    )\n",
    "    \n",
    "    adv_inputs = adversary.perturb(inputs, y)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        adv_outputs = model(adv_inputs).to('cpu').numpy()\n",
    "#     print(adv_outputs)\n",
    "    torch.cuda.empty_cache()\n",
    "    return adv_inputs.to('cpu').numpy()\n",
    "\n",
    "\n",
    "model = models_dict['pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-']\n",
    "seed_inputs = model.get_seed_inputs(100, rand=False)\n",
    "seed_outputs = model.batch_forward(seed_inputs)\n",
    "_, seed_preds = seed_outputs.to('cpu').data.max(1)\n",
    "\n",
    "adv_inputs = gen_adv_inputs(model.torch_model, seed_inputs)\n",
    "adv_outputs = model.batch_forward(adv_inputs)\n",
    "_, adv_preds = adv_outputs.to('cpu').data.max(1)\n",
    "\n",
    "print(f\"seed_preds={seed_preds}, adv_preds={adv_preds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'\n",
    "image_size = 224\n",
    "\n",
    "def expand_vector(x, size):\n",
    "    batch_size = x.size(0)\n",
    "    x = x.view(-1, 3, size, size)\n",
    "    z = torch.zeros(batch_size, 3, image_size, image_size).to(DEVICE)\n",
    "    z[:, :, :size, :size] = x\n",
    "    return z\n",
    "\n",
    "def normalize(x):\n",
    "    return utils.apply_normalization(x, 'imagenet')\n",
    "\n",
    "def get_probs(model, x, y):\n",
    "    output = model(x)\n",
    "    probs = torch.index_select(torch.nn.functional.softmax(output, -1).data, 1, y)\n",
    "    return torch.diag(probs).cpu()\n",
    "\n",
    "def get_preds(model, x):\n",
    "    output = model(x)\n",
    "    _, preds = output.data.max(1)\n",
    "    return preds\n",
    "\n",
    "# runs simba on a batch of images <images_batch> with true labels (for untargeted attack) or target labels\n",
    "# (for targeted attack) <labels_batch>\n",
    "def dct_attack_batch(model, images_batch, labels_batch, max_iters, freq_dims, stride, epsilon, order='rand', targeted=False, pixel_attack=False, log_every=1):\n",
    "    batch_size = images_batch.size(0)\n",
    "    image_size = images_batch.size(2)\n",
    "    # sample a random ordering for coordinates independently per batch element\n",
    "    if order == 'rand':\n",
    "        indices = torch.randperm(3 * freq_dims * freq_dims)[:max_iters]\n",
    "    elif order == 'diag':\n",
    "        indices = utils.diagonal_order(image_size, 3)[:max_iters]\n",
    "    elif order == 'strided':\n",
    "        indices = utils.block_order(image_size, 3, initial_size=freq_dims, stride=stride)[:max_iters]\n",
    "    else:\n",
    "        indices = utils.block_order(image_size, 3)[:max_iters]\n",
    "    if order == 'rand':\n",
    "        expand_dims = freq_dims\n",
    "    else:\n",
    "        expand_dims = image_size\n",
    "    n_dims = 3 * expand_dims * expand_dims\n",
    "    x = torch.zeros(batch_size, n_dims)\n",
    "    # logging tensors\n",
    "    probs = torch.zeros(batch_size, max_iters)\n",
    "    succs = torch.zeros(batch_size, max_iters)\n",
    "    queries = torch.zeros(batch_size, max_iters)\n",
    "    l2_norms = torch.zeros(batch_size, max_iters)\n",
    "    linf_norms = torch.zeros(batch_size, max_iters)\n",
    "    prev_probs = get_probs(model, images_batch, labels_batch)\n",
    "    preds = get_preds(model, images_batch)\n",
    "    if pixel_attack:\n",
    "        trans = lambda z: z\n",
    "    else:\n",
    "        trans = lambda z: utils.block_idct(z, block_size=image_size, linf_bound=args.linf_bound)\n",
    "    remaining_indices = torch.arange(0, batch_size).long()\n",
    "    for k in range(max_iters):\n",
    "        dim = indices[k]\n",
    "        expanded = (images_batch[remaining_indices] + trans(expand_vector(x[remaining_indices], expand_dims))).clamp(-2.6, 2.6)\n",
    "        perturbation = trans(expand_vector(x, expand_dims))\n",
    "        l2_norms[:, k] = perturbation.view(batch_size, -1).norm(2, 1)\n",
    "        linf_norms[:, k] = perturbation.view(batch_size, -1).abs().max(1)[0]\n",
    "        preds_next = get_preds(model, expanded)\n",
    "        preds[remaining_indices] = preds_next\n",
    "        if targeted:\n",
    "            remaining = preds.ne(labels_batch)\n",
    "        else:\n",
    "            remaining = preds.eq(labels_batch)\n",
    "        # check if all images are misclassified and stop early\n",
    "        if remaining.sum() == 0:\n",
    "            adv = (images_batch + trans(expand_vector(x, expand_dims))).clamp(0, 1)\n",
    "            probs_k = get_probs(model, adv, labels_batch)\n",
    "            probs[:, k:] = probs_k.unsqueeze(1).repeat(1, max_iters - k)\n",
    "            succs[:, k:] = torch.ones(batch_size, max_iters - k)\n",
    "            queries[:, k:] = torch.zeros(batch_size, max_iters - k)\n",
    "            break\n",
    "        remaining_indices = torch.arange(0, batch_size)[remaining].long()\n",
    "        if k > 0:\n",
    "            succs[:, k-1] = ~remaining\n",
    "        diff = torch.zeros(remaining.sum(), n_dims)\n",
    "        diff[:, dim] = epsilon\n",
    "        left_vec = x[remaining_indices] - diff\n",
    "        right_vec = x[remaining_indices] + diff\n",
    "        # trying negative direction\n",
    "        adv = (images_batch[remaining_indices] + trans(expand_vector(left_vec, expand_dims))).clamp(-2.6, 2.6)\n",
    "        left_probs = get_probs(model, adv, labels_batch[remaining_indices])\n",
    "        queries_k = torch.zeros(batch_size)\n",
    "        # increase query count for all images\n",
    "        queries_k[remaining_indices] += 1\n",
    "        if targeted:\n",
    "            improved = left_probs.gt(prev_probs[remaining_indices])\n",
    "        else:\n",
    "            improved = left_probs.lt(prev_probs[remaining_indices])\n",
    "        # only increase query count further by 1 for images that did not improve in adversarial loss\n",
    "        if improved.sum() < remaining_indices.size(0):\n",
    "            queries_k[remaining_indices[~improved]] += 1\n",
    "        # try positive directions\n",
    "        adv = (images_batch[remaining_indices] + trans(expand_vector(right_vec, expand_dims))).clamp(-2.6, 2.6)\n",
    "        right_probs = get_probs(model, adv, labels_batch[remaining_indices])\n",
    "        if targeted:\n",
    "            right_improved = right_probs.gt(torch.max(prev_probs[remaining_indices], left_probs))\n",
    "        else:\n",
    "            right_improved = right_probs.lt(torch.min(prev_probs[remaining_indices], left_probs))\n",
    "        probs_k = prev_probs.clone()\n",
    "        # update x depending on which direction improved\n",
    "        if improved.sum() > 0:\n",
    "            left_indices = remaining_indices[improved]\n",
    "            left_mask_remaining = improved.unsqueeze(1).repeat(1, n_dims)\n",
    "            x[left_indices] = left_vec[left_mask_remaining].view(-1, n_dims)\n",
    "            probs_k[left_indices] = left_probs[improved]\n",
    "        if right_improved.sum() > 0:\n",
    "            right_indices = remaining_indices[right_improved]\n",
    "            right_mask_remaining = right_improved.unsqueeze(1).repeat(1, n_dims)\n",
    "            x[right_indices] = right_vec[right_mask_remaining].view(-1, n_dims)\n",
    "            probs_k[right_indices] = right_probs[right_improved]\n",
    "        probs[:, k] = probs_k\n",
    "        queries[:, k] = queries_k\n",
    "        prev_probs = probs[:, k]\n",
    "        if (k + 1) % log_every == 0 or k == max_iters - 1:\n",
    "            print('Iteration %d: queries = %.4f, prob = %.4f, remaining = %.4f' % (\n",
    "                    k + 1, queries.sum(1).mean(), probs[:, k].mean(), remaining.float().mean()))\n",
    "    expanded = (images_batch + trans(expand_vector(x, expand_dims))).clamp(-2.6, 2.6)\n",
    "    preds = get_preds(model, expanded)\n",
    "    if targeted:\n",
    "        remaining = preds.ne(labels_batch)\n",
    "    else:\n",
    "        remaining = preds.eq(labels_batch)\n",
    "    succs[:, max_iters-1] = ~remaining\n",
    "    return expanded, probs, succs, queries, l2_norms, linf_norms\n",
    "\n",
    "\n",
    "def search_adv_inputs(model, inputs, labels):\n",
    "    images_batch = torch.from_numpy(inputs).to(DEVICE)\n",
    "#     labels_batch = torch.zeros(len(inputs)).long().to(DEVICE)\n",
    "    labels_batch = labels.long().to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        adv, probs, succs, queries, l2_norms, linf_norms = dct_attack_batch(\n",
    "            model, images_batch=images_batch, labels_batch=labels_batch,\n",
    "            max_iters=5000, freq_dims=image_size, stride=7, epsilon=0.2, order='rand',\n",
    "            targeted=False, pixel_attack=True, log_every=10\n",
    "        )\n",
    "    return adv\n",
    "\n",
    "\n",
    "model = models_dict['pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-']\n",
    "seed_inputs = model.get_seed_inputs(100, rand=False)\n",
    "seed_outputs = model.batch_forward(seed_inputs)\n",
    "_, seed_preds = seed_outputs.to('cpu').data.max(1)\n",
    "\n",
    "adv_inputs = search_adv_inputs(model.torch_model, seed_inputs, seed_preds)\n",
    "adv_outputs = model.batch_forward(adv_inputs)\n",
    "_, adv_preds = adv_outputs.to('cpu').data.max(1)\n",
    "\n",
    "print(f\"seed_preds={seed_preds}, adv_preds={adv_preds}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import logging\n",
    "import copy\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(name)-12s %(levelname)-8s %(message)s\")\n",
    "\n",
    "\n",
    "from benchmark import ImageBenchmark\n",
    "bench = ImageBenchmark()\n",
    "models = list(bench.list_models())\n",
    "models_dict = {}\n",
    "for i, model in enumerate(models):\n",
    "    if not model.torch_model_exists():\n",
    "        continue\n",
    "#     print(f'{i}\\t {model.__str__()}')\n",
    "    models_dict[model.__str__()] = model\n",
    "\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "image_size = 224\n",
    "\n",
    "def expand_vector(x, image_size):\n",
    "    batch_size = x.size(0)\n",
    "    x = x.view(-1, 3, image_size, image_size)\n",
    "    z = torch.zeros(batch_size, 3, image_size, image_size).to(DEVICE)\n",
    "    z[:, :, :image_size, :image_size] = x\n",
    "    return z\n",
    "\n",
    "def evaluate_inputs(model, inputs, seed_outputs, seed_preds, lambda1=0.5):\n",
    "    outputs = model(inputs)\n",
    "    _, preds = outputs.data.max(1)\n",
    "    changed = preds.ne(seed_preds)\n",
    "    outputs = torch.nn.functional.softmax(outputs, -1)\n",
    "    seed_outputs = torch.nn.functional.softmax(seed_outputs, -1)\n",
    "    reduce_dims = tuple(range(outputs.dim())[1:])\n",
    "    divergence_arr = torch.sum((outputs - seed_outputs) ** 2, dim=reduce_dims) ** 0.5\n",
    "    divergence = torch.mean(divergence_arr)\n",
    "#     divergence_cos = F.cosine_similarity(outputs, seed_outputs)\n",
    "#     divergence_kld = F.kl_div(seed_outputs, outputs, reduction='none')\n",
    "#     print(divergence_kld)\n",
    "    diversity_matrix = torch.cdist(outputs, outputs, p=2.0)\n",
    "    diversity = torch.mean(diversity_matrix)\n",
    "    quantile = lambda t, q: t.view(-1).kthvalue(1 + round(float(q) * (t.numel() - 1))).values.item()\n",
    "    diversity_quantile = quantile(diversity_matrix, 0.011)\n",
    "#     diversity = diversity ** 2\n",
    "    score = divergence + lambda1 * diversity\n",
    "    succ = preds.ne(seed_preds)\n",
    "    low_divergence_indices = list(torch.nonzero(divergence_arr.lt(divergence)).cpu().numpy())\n",
    "    low_diversity_indices = list(torch.nonzero(diversity_matrix.lt(diversity_quantile)).cpu().numpy())\n",
    "    remaining_indices = set()\n",
    "#     print(changed)\n",
    "    for i in low_divergence_indices:\n",
    "        if not changed[i].cpu():\n",
    "            remaining_indices.add(i[0])\n",
    "    for i in low_diversity_indices:\n",
    "        if i[0] == i[1]:\n",
    "            continue\n",
    "        if not changed[i[0]]:\n",
    "            remaining_indices.add(i[0])\n",
    "        if not changed[i[1]]:\n",
    "            remaining_indices.add(i[1])\n",
    "    remaining_indices = sorted(remaining_indices)\n",
    "#     print(f' low_divergence_indices={len(low_divergence_indices)}\\n low_diversity_indices={len(low_diversity_indices)}\\n remaining_indices={len(remaining_indices)}')\n",
    "    eval_line = f'score={score:.4f}, divergence={divergence:.4f}, diversity={diversity:.4f}, num_succ={succ.sum()}, num_remain={len(remaining_indices)}'\n",
    "    return {\n",
    "        'outputs': outputs,\n",
    "        'preds': preds,\n",
    "        'score': score,\n",
    "        'divergence': divergence,\n",
    "        'diversity': diversity,\n",
    "        'succ': succ,\n",
    "        'remaining': remaining_indices,\n",
    "        'eval_line': eval_line\n",
    "    }\n",
    "    \n",
    "    \n",
    "def optimize_towards_goal(\n",
    "    model, seed_inputs, seed_outputs, seed_preds, \n",
    "    max_iters=10000, mutation_size=1, epsilon=0.5, lambda1=0.0, log_every=100, save_every=1000):\n",
    "#     seed_inputs = torch.from_numpy(seed_inputs).to(DEVICE)\n",
    "#     seed_outputs = torch.from_numpy(seed_outputs).to(DEVICE)\n",
    "#     seed_preds = torch.from_numpy(seed_preds).to(DEVICE)\n",
    "    input_shape = seed_inputs[0].shape\n",
    "    n_inputs = seed_inputs.shape[0]\n",
    "    ndims = np.prod(input_shape)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = copy.copy(seed_inputs)\n",
    "        saved_inputs = {}\n",
    "        evaluation = evaluate_inputs(model, inputs, seed_outputs, seed_preds, lambda1)\n",
    "        print(f'initial_evaluation: {evaluation[\"eval_line\"]}')\n",
    "\n",
    "        for i in range(max_iters):\n",
    "#             print(f'mutation {i}-th iteration')\n",
    "\n",
    "            # mutation_pos = np.random.randint(0, ndims)\n",
    "            mutation_pos = np.random.choice(ndims, size=mutation_size, replace=False)\n",
    "            mutation = np.zeros(ndims).astype(np.float32)\n",
    "            mutation[mutation_pos] = epsilon\n",
    "            mutation = np.reshape(mutation, input_shape)\n",
    "\n",
    "            mutation_batch = np.zeros(shape=inputs.shape).astype(np.float32)\n",
    "#             all_indices = list(range(0, n_inputs))\n",
    "#             mutation_indices = np.random.choice(all_indices, size=int(n_inputs * 0.85), replace=False)\n",
    "#             print(mutation_indices)\n",
    "#             mutation_idx = np.random.randint(0, n_inputs)\n",
    "            mutation_indices = evaluation['remaining']\n",
    "            if len(mutation_indices) == 0:\n",
    "                print(f'{i:4d}-th - no remaining indice: {evaluation[\"eval_line\"]}')\n",
    "                break\n",
    "#             print(mutation_indices)\n",
    "            mutation_batch[mutation_indices] = mutation\n",
    "            mutation_batch = torch.from_numpy(mutation_batch).to(DEVICE)\n",
    "\n",
    "            prev_score = evaluation[\"score\"]\n",
    "            mutate_right_inputs = (inputs + mutation_batch).clamp(-2.6, 2.6)\n",
    "            mutate_right_eval = evaluate_inputs(model, mutate_right_inputs, seed_outputs, seed_preds)\n",
    "            mutate_right_score = mutate_right_eval['score']\n",
    "            mutate_left_inputs = (inputs - mutation_batch).clamp(-2.6, 2.6)\n",
    "            mutate_left_eval = evaluate_inputs(model, mutate_left_inputs, seed_outputs, seed_preds)\n",
    "            mutate_left_score = mutate_left_eval['score']\n",
    "\n",
    "            if mutate_right_score <= prev_score and mutate_left_score <= prev_score:\n",
    "                pass\n",
    "            elif mutate_right_score > mutate_left_score:\n",
    "#                 print(f'mutate right: {prev_score}->{mutate_right_score}')\n",
    "                inputs = mutate_right_inputs\n",
    "                evaluation = mutate_right_eval\n",
    "            else:\n",
    "#                 print(f'mutate left: {prev_score}->{mutate_left_score}')\n",
    "                inputs = mutate_left_inputs\n",
    "                evaluation = mutate_left_eval\n",
    "            if i % log_every == 0:\n",
    "                print(f'{i:4d}-th evaluation: {evaluation[\"eval_line\"]}')\n",
    "            if i % save_every == 0:\n",
    "                saved_inputs[i] = copy.copy(inputs.cpu().numpy())\n",
    "        return inputs, saved_inputs\n",
    "\n",
    "model = models_dict['pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-']\n",
    "seed_inputs = model.get_seed_inputs(100, rand=False)\n",
    "seed_inputs = torch.from_numpy(seed_inputs).to(DEVICE)\n",
    "seed_outputs = model.batch_forward(seed_inputs)\n",
    "_, seed_preds = seed_outputs.data.max(1)\n",
    "\n",
    "adv_inputs, _ = optimize_towards_goal(model.torch_model_on_device, seed_inputs, seed_outputs, seed_preds, log_every=100)\n",
    "adv_outputs = model.batch_forward(adv_inputs).cpu()\n",
    "_, adv_preds = adv_outputs.data.max(1)\n",
    "\n",
    "print(f\"seed_preds={seed_preds}, adv_preds={adv_preds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "from utils import lazy_property, Utils\n",
    "import os\n",
    "\n",
    "\n",
    "def compute_ddv(model, normal_outputs, adv_outputs):\n",
    "    output_pairs = zip(normal_outputs, adv_outputs)\n",
    "    # print(list(output_pairs)[0])\n",
    "    ddv = []  # DDV is short for decision distance vector\n",
    "    for i, (ya, yb) in enumerate(output_pairs):\n",
    "        dist = spatial.distance.cosine(ya, yb)\n",
    "        ddv.append(dist)\n",
    "    ddv = Utils.normalize(np.array(ddv))\n",
    "    return ddv\n",
    "\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    if not model.torch_model_exists():\n",
    "        continue\n",
    "    model_name = model.__str__()\n",
    "    model_path = model.torch_model_path\n",
    "    if i < 6: # skip pretrained models\n",
    "        continue\n",
    "    if 'quantize' in model_name: # skip quantized models\n",
    "        continue\n",
    "    print(f'{i}\\t generating inputs for {model.__str__()}')\n",
    "    seed_inputs = model.get_seed_inputs(100, rand=False)\n",
    "    seed_inputs = torch.from_numpy(seed_inputs).to(DEVICE)\n",
    "    seed_outputs = model.batch_forward(seed_inputs)\n",
    "    _, seed_preds = seed_outputs.data.max(1)\n",
    "\n",
    "    adv_inputs, saved_inputs = optimize_towards_goal(\n",
    "        model.torch_model_on_device, seed_inputs, seed_outputs, seed_preds,\n",
    "        epsilon=0.2, lambda1=0.5, max_iters=10000, log_every=100, save_every=1000)\n",
    "    adv_outputs = model.batch_forward(adv_inputs).cpu()\n",
    "    _, adv_preds = adv_outputs.data.max(1)\n",
    "    \n",
    "    ddv = compute_ddv(model, seed_outputs.cpu().numpy(), adv_outputs.cpu().numpy())\n",
    "    print(ddv)\n",
    "    \n",
    "    out_path = os.path.join(model_path, 'inputs.npz')\n",
    "    np.savez(out_path, seed_inputs=seed_inputs.cpu().numpy(), adv_inputs=adv_inputs.cpu().numpy(), ddv=ddv, saved_inputs=saved_inputs)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import copy\n",
    "from scipy import spatial\n",
    "from utils import lazy_property, Utils\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(name)-12s %(levelname)-8s %(message)s\")\n",
    "\n",
    "\n",
    "from benchmark import ImageBenchmark\n",
    "bench = ImageBenchmark()\n",
    "models = list(bench.list_models())\n",
    "models_dict = {}\n",
    "for i, model in enumerate(models):\n",
    "    if not model.torch_model_exists():\n",
    "        continue\n",
    "#     print(f'{i}\\t {model.__str__()}')\n",
    "    models_dict[model.__str__()] = model\n",
    "\n",
    "    \n",
    "def get_comparable_models(target_model):\n",
    "    target_model_name = target_model.__str__()\n",
    "    target_model_segs = target_model_name.split('-')\n",
    "    parent_model_name = '-'.join(target_model_segs[:-2]) + '-'\n",
    "    parent_model = models_dict[parent_model_name]\n",
    "    # print(f'parent_model: {parent_model}')\n",
    "    reference_models = []\n",
    "    for model in models:\n",
    "        if not model.__str__().startswith(target_model_segs[0]):\n",
    "            reference_models.append(model)\n",
    "            # print(f'reference_model: {model}')\n",
    "    return parent_model, reference_models\n",
    "\n",
    "\n",
    "def compute_ddv(model, normal_inputs, adv_inputs):\n",
    "    normal_outputs = model.batch_forward(normal_inputs).cpu().numpy()\n",
    "    adv_outputs = model.batch_forward(adv_inputs).cpu().numpy()\n",
    "    output_pairs = zip(normal_outputs, adv_outputs)\n",
    "    # print(list(output_pairs)[0])\n",
    "    ddv = []  # DDV is short for decision distance vector\n",
    "    for i, (ya, yb) in enumerate(output_pairs):\n",
    "        dist = spatial.distance.cosine(ya, yb)\n",
    "        ddv.append(dist)\n",
    "    ddv = Utils.normalize(np.array(ddv))\n",
    "    return ddv\n",
    "\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    # Background colors:\n",
    "    GREYBG = '\\033[100m'\n",
    "    REDBG = '\\033[101m'\n",
    "    GREENBG = '\\033[102m'\n",
    "    YELLOWBG = '\\033[103m'\n",
    "    BLUEBG = '\\033[104m'\n",
    "    PINKBG = '\\033[105m'\n",
    "    CYANBG = '\\033[106m'\n",
    "\n",
    "    \n",
    "DEVICE = 'cuda'\n",
    "image_size = 224\n",
    "\n",
    "\n",
    "def expand_vector(x, image_size):\n",
    "    batch_size = x.size(0)\n",
    "    x = x.view(-1, 3, image_size, image_size)\n",
    "    z = torch.zeros(batch_size, 3, image_size, image_size).to(DEVICE)\n",
    "    z[:, :, :image_size, :image_size] = x\n",
    "    return z\n",
    "\n",
    "\n",
    "def evaluate_inputs_1(model, inputs, seed_outputs, seed_preds, prev_score_arr, lambda1=0.5):\n",
    "    if prev_score_arr is None:\n",
    "        prev_score_arr = torch.ones(len(inputs)).to(DEVICE) * -1000\n",
    "    outputs = model(inputs)\n",
    "    _, preds = outputs.data.max(1)\n",
    "    changed = preds.ne(seed_preds)\n",
    "#     outputs = F.softmax(outputs, -1)\n",
    "#     seed_outputs = F.softmax(seed_outputs, -1)\n",
    "#     print(target_outputs)\n",
    "    reduce_dims = tuple(range(outputs.dim())[1:])\n",
    "    \n",
    "    output_mean = seed_outputs.mean(axis=0)\n",
    "    target_outputs = output_mean - seed_outputs\n",
    "#     print(seed_outputs)\n",
    "#     print(output_mean)\n",
    "#     print(target_outputs)\n",
    "    \n",
    "    target_dist_arr = -torch.sum((outputs - target_outputs) ** 2, dim=reduce_dims) ** 0.5\n",
    "    target_dist = target_dist_arr.mean()\n",
    "    \n",
    "    divergence_arr = torch.sum((outputs - seed_outputs) ** 2, dim=reduce_dims) ** 0.5\n",
    "    divergence = torch.mean(divergence_arr)\n",
    "    \n",
    "    seed_var_arr = torch.sum((seed_outputs - output_mean) ** 2, dim=reduce_dims) ** 0.5\n",
    "    seed_var = torch.mean(seed_var_arr)\n",
    "    \n",
    "    output_var_arr = torch.sum((outputs - output_mean) ** 2, dim=reduce_dims) ** 0.5\n",
    "    output_var = output_var_arr.mean()\n",
    "    \n",
    "#     print(seed_var_arr, output_var_arr.shape, sep='\\n')\n",
    "# #     divergence_cos = F.cosine_similarity(outputs, seed_outputs)\n",
    "# #     divergence_kld = F.kl_div(seed_outputs, outputs, reduction='none')\n",
    "# #     print(divergence_kld)\n",
    "#     diversity_matrix = torch.cdist(outputs, outputs, p=2.0)\n",
    "#     diversity = torch.mean(diversity_matrix)\n",
    "#     quantile = lambda t, q: t.view(-1).kthvalue(1 + round(float(q) * (t.numel() - 1))).values.item()\n",
    "#     diversity_quantile = quantile(diversity_matrix, 0.011)\n",
    "# #     diversity = diversity ** 2\n",
    "#     score = divergence + lambda1 * diversity\n",
    "    new_score_arr = divergence_arr\n",
    "    new_score_improved = new_score_arr.gt(prev_score_arr)\n",
    "    var_in_limit = seed_var_arr.ge(output_var_arr)\n",
    "#     improved = new_score_improved & var_in_limit\n",
    "    improved = new_score_improved\n",
    "    # print(f' new_score_improved={new_score_improved}\\n var_in_limit={var_in_limit}\\n improved={improved}')\n",
    "    improved_indices = torch.nonzero(improved).cpu().numpy().squeeze(-1).tolist()\n",
    "    # print(score_improved, var_in_limit, improved_indices, score_arr, sep='\\n')\n",
    "    \n",
    "#     succ = preds.ne(seed_preds)\n",
    "#     low_divergence_indices = list(torch.nonzero(divergence_arr.lt(divergence)).cpu().numpy())\n",
    "#     low_target_dist_indices = list(torch.nonzero(target_dist_arr.lt(target_dist)).cpu().numpy())\n",
    "# #     low_diversity_indices = list(torch.nonzero(diversity_matrix.lt(diversity_quantile)).cpu().numpy())\n",
    "#     remaining_indices = set()\n",
    "# #     print(changed)\n",
    "#     for i in low_target_dist_indices:\n",
    "#         remaining_indices.add(i[0])\n",
    "# #     for i in low_diversity_indices:\n",
    "# #         if i[0] == i[1]:\n",
    "# #             continue\n",
    "# #         remaining_indices.add(i[0])\n",
    "# #         remaining_indices.add(i[1])\n",
    "#     remaining_indices = sorted(remaining_indices)\n",
    "    remaining_indices = list(range(len(inputs)))\n",
    "#     print(f' low_divergence_indices={len(low_divergence_indices)}\\n low_diversity_indices={len(low_diversity_indices)}\\n remaining_indices={len(remaining_indices)}')\n",
    "    score_arr = copy.copy(prev_score_arr)\n",
    "    score_arr[improved_indices] = new_score_arr[improved_indices]\n",
    "    \n",
    "    score = score_arr.mean()\n",
    "    eval_line = f'score={score:.4f}, num_remain={len(remaining_indices)}, num_improved={len(improved_indices)}'\n",
    "    return {\n",
    "        'outputs': outputs,\n",
    "        'preds': preds,\n",
    "        'score_arr': score_arr,\n",
    "        'score': score,\n",
    "        'remaining': remaining_indices,\n",
    "        'improved_indices': improved_indices,\n",
    "        'eval_line': eval_line\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_inputs_2(model, inputs, seed_outputs, seed_preds, prev_score_arr, lambda1=0.5):\n",
    "    outputs = model(inputs)\n",
    "    _, preds = outputs.data.max(1)\n",
    "    changed = preds.ne(seed_preds)\n",
    "    outputs = torch.nn.functional.softmax(outputs, -1)\n",
    "    seed_outputs = torch.nn.functional.softmax(seed_outputs, -1)\n",
    "    reduce_dims = tuple(range(outputs.dim())[1:])\n",
    "    divergence_arr = torch.sum((outputs - seed_outputs) ** 2, dim=reduce_dims) ** 0.5\n",
    "    divergence = torch.mean(divergence_arr)\n",
    "#     divergence_cos = F.cosine_similarity(outputs, seed_outputs)\n",
    "#     divergence_kld = F.kl_div(seed_outputs, outputs, reduction='none')\n",
    "#     print(divergence_kld)\n",
    "    diversity_matrix = torch.cdist(outputs, outputs, p=2.0)\n",
    "    diversity = torch.mean(diversity_matrix)\n",
    "    quantile = lambda t, q: t.view(-1).kthvalue(1 + round(float(q) * (t.numel() - 1))).values.item()\n",
    "    diversity_quantile = quantile(diversity_matrix, 0.011)\n",
    "#     diversity = diversity ** 2\n",
    "    score = divergence + lambda1 * diversity\n",
    "    succ = preds.ne(seed_preds)\n",
    "    low_divergence_indices = list(torch.nonzero(divergence_arr.lt(divergence)).cpu().numpy())\n",
    "    low_diversity_indices = list(torch.nonzero(diversity_matrix.lt(diversity_quantile)).cpu().numpy())\n",
    "    remaining_indices = set()\n",
    "#     print(changed)\n",
    "    for i in low_divergence_indices:\n",
    "        if not changed[i].cpu():\n",
    "            remaining_indices.add(i[0])\n",
    "    for i in low_diversity_indices:\n",
    "        if i[0] == i[1]:\n",
    "            continue\n",
    "        if not changed[i[0]]:\n",
    "            remaining_indices.add(i[0])\n",
    "        if not changed[i[1]]:\n",
    "            remaining_indices.add(i[1])\n",
    "    remaining_indices = sorted(remaining_indices)\n",
    "    improved_indices = list(range(len(inputs)))\n",
    "#     print(f' low_divergence_indices={len(low_divergence_indices)}\\n low_diversity_indices={len(low_diversity_indices)}\\n remaining_indices={len(remaining_indices)}')\n",
    "    eval_line = f'score={score:.4f}, divergence={divergence:.4f}, diversity={diversity:.4f}, num_succ={succ.sum()}, num_remain={len(remaining_indices)}'\n",
    "    return {\n",
    "        'outputs': outputs,\n",
    "        'preds': preds,\n",
    "        'score_arr': divergence_arr,\n",
    "        'score': score,\n",
    "        'divergence': divergence,\n",
    "        'diversity': diversity,\n",
    "        'succ': succ,\n",
    "        'remaining': remaining_indices,\n",
    "        'improved_indices': improved_indices,\n",
    "        'eval_line': eval_line\n",
    "    }\n",
    "    \n",
    "    \n",
    "def optimize_towards_goal(\n",
    "    model, seed_inputs, seed_outputs, seed_preds, evaluate_inputs,\n",
    "    max_iters=10000, mutation_size=1, epsilon=0.5, lambda1=0.0,\n",
    "    log_every=100, save_every=1000):\n",
    "#     seed_inputs = torch.from_numpy(seed_inputs).to(DEVICE)\n",
    "#     seed_outputs = torch.from_numpy(seed_outputs).to(DEVICE)\n",
    "#     seed_preds = torch.from_numpy(seed_preds).to(DEVICE)\n",
    "    input_shape = seed_inputs[0].shape\n",
    "    n_inputs = seed_inputs.shape[0]\n",
    "    ndims = np.prod(input_shape)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = copy.deepcopy(seed_inputs)\n",
    "        saved_inputs = {}\n",
    "        evaluation = evaluate_inputs(model, inputs, seed_outputs, seed_preds, None, lambda1)\n",
    "        print(f'initial_evaluation: {evaluation[\"eval_line\"]}')\n",
    "        \n",
    "        remaining_pos = list(range(ndims))\n",
    "\n",
    "        for i in range(max_iters):\n",
    "#             print(f'mutation {i}-th iteration')\n",
    "            # mutation_pos = np.random.randint(0, ndims)\n",
    "            if len(remaining_pos) < mutation_size:\n",
    "                print(f'not enough remaining pos')\n",
    "                break\n",
    "            mutation_pos = np.random.choice(remaining_pos, size=mutation_size, replace=False)\n",
    "            mutation = np.zeros(ndims).astype(np.float32)\n",
    "            mutation[mutation_pos] = epsilon\n",
    "            mutation = np.reshape(mutation, input_shape)\n",
    "\n",
    "            mutation_batch = np.zeros(shape=inputs.shape).astype(np.float32)\n",
    "            mutation_indices = evaluation['remaining']\n",
    "            if len(mutation_indices) == 0:\n",
    "                print(f'no remaining indice')\n",
    "                break\n",
    "            mutation_batch[mutation_indices] = mutation\n",
    "            mutation_batch = torch.from_numpy(mutation_batch).to(DEVICE)\n",
    "\n",
    "            prev_score = evaluation[\"score\"]\n",
    "            mutate_right_inputs = (inputs + mutation_batch).clamp(-2.6, 2.6)\n",
    "            mutate_right_eval = evaluate_inputs(model, mutate_right_inputs, seed_outputs, seed_preds, evaluation[\"score_arr\"])\n",
    "            mutate_right_score = mutate_right_eval['score']\n",
    "            mutate_left_inputs = (inputs - mutation_batch).clamp(-2.6, 2.6)\n",
    "            mutate_left_eval = evaluate_inputs(model, mutate_left_inputs, seed_outputs, seed_preds, evaluation[\"score_arr\"])\n",
    "            mutate_left_score = mutate_left_eval['score']\n",
    "\n",
    "            if mutate_right_score <= prev_score and mutate_left_score <= prev_score:\n",
    "                pass\n",
    "            elif mutate_right_score > mutate_left_score:\n",
    "#                 print(f'mutate right: {prev_score}->{mutate_right_score}')\n",
    "                improved_indices = mutate_right_eval['improved_indices']\n",
    "                inputs[improved_indices] = mutate_right_inputs[improved_indices]\n",
    "                evaluation = mutate_right_eval\n",
    "                remaining_pos = sorted(set(remaining_pos) - set(mutation_pos))\n",
    "            else:\n",
    "#                 print(f'mutate left: {prev_score}->{mutate_left_score}')\n",
    "                improved_indices = mutate_left_eval['improved_indices']\n",
    "                inputs[improved_indices] = mutate_left_inputs[improved_indices]\n",
    "                evaluation = mutate_left_eval\n",
    "                remaining_pos = sorted(set(remaining_pos) - set(mutation_pos))\n",
    "            if i % log_every == 0:\n",
    "                print(f'{i:4d}-th evaluation: {evaluation[\"eval_line\"]}')\n",
    "            if i % save_every == 0:\n",
    "                saved_inputs[i] = copy.copy(inputs.cpu().numpy())\n",
    "        return inputs, saved_inputs\n",
    "\n",
    "    \n",
    "def compute_ddv_with_outputs(model, normal_outputs, adv_outputs):\n",
    "    output_pairs = zip(normal_outputs, adv_outputs)\n",
    "    # print(list(output_pairs)[0])\n",
    "    ddv = []  # DDV is short for decision distance vector\n",
    "    for i, (ya, yb) in enumerate(output_pairs):\n",
    "        dist = spatial.distance.cosine(ya, yb)\n",
    "        ddv.append(dist)\n",
    "    ddv = Utils.normalize(np.array(ddv))\n",
    "    return ddv\n",
    "\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    if not model.torch_model_exists():\n",
    "        continue\n",
    "    model_name = model.__str__()\n",
    "    model_path = model.torch_model_path\n",
    "    if i < 6: # skip pretrained models\n",
    "        continue\n",
    "    if 'quantize' in model_name: # skip quantized models\n",
    "        continue\n",
    "        \n",
    "#     if i != 8:\n",
    "#         continue\n",
    "    out_path = os.path.join(model_path, 'blackbox_inputs_diversity0.5_m1e0.2.npz')\n",
    "#     if os.path.exists(out_path):\n",
    "#         continue\n",
    "    \n",
    "    print(f'{i}\\t generating inputs for {model.__str__()}')\n",
    "    seed_inputs = model.get_seed_inputs(100, rand=False)\n",
    "    seed_inputs = torch.from_numpy(seed_inputs).to(DEVICE)\n",
    "    model.torch_model.to(DEVICE)\n",
    "    seed_outputs = model.batch_forward(seed_inputs)\n",
    "    _, seed_preds = seed_outputs.data.max(1)\n",
    "\n",
    "    adv_inputs, saved_inputs = optimize_towards_goal(\n",
    "        model.torch_model_on_device, seed_inputs, seed_outputs, seed_preds, evaluate_inputs=evaluate_inputs_2,\n",
    "        mutation_size=1, epsilon=0.1, lambda1=0.5, max_iters=1000, log_every=100, save_every=100)\n",
    "    adv_outputs = model.batch_forward(adv_inputs).cpu()\n",
    "    _, adv_preds = adv_outputs.data.max(1)\n",
    "    \n",
    "    seed_inputs=seed_inputs.cpu().numpy()\n",
    "    adv_inputs=adv_inputs.cpu().numpy()\n",
    "    \n",
    "    ddv = compute_ddv(model, seed_inputs, adv_inputs)\n",
    "    \n",
    "    print(f'evaluating inputs')\n",
    "    parent_model, ref_models = get_comparable_models(model)\n",
    "    parent_sim = 0\n",
    "    for i, ref_model in enumerate([parent_model] + ref_models):\n",
    "        if 'quantize' in ref_model.__str__(): # quantized models are equivalent to its teacher model\n",
    "            continue\n",
    "        try:\n",
    "            ref_model.torch_model.to(DEVICE)\n",
    "            ref_ddv = compute_ddv(ref_model, seed_inputs, adv_inputs)\n",
    "            ref_sim = spatial.distance.cosine(ddv, ref_ddv)\n",
    "            ref_model.torch_model.cpu()\n",
    "            if i == 0:\n",
    "                parent_sim = ref_sim\n",
    "                gap = 1\n",
    "                print(f'parent_sim: {ref_sim:.4f} {ref_model}')\n",
    "            else:\n",
    "                gap = ref_sim - parent_sim\n",
    "                if gap > 0:\n",
    "                    print(f'ref_sim: {ref_sim:.4f} gap={gap:.4f} {ref_model}')\n",
    "                else:\n",
    "                    print(f'{bcolors.WARNING}[ERROR] ref_sim: {ref_sim:.4f} gap={gap:.4f} {ref_model}{bcolors.ENDC}')\n",
    "        except Exception as e:\n",
    "            print(f'failed to compare: {ref_model}')\n",
    "            print(f'exception: {e}')\n",
    "    \n",
    "    np.savez(out_path, seed_inputs=seed_inputs, adv_inputs=adv_inputs, ddv=ddv, saved_inputs=saved_inputs)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Utils\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def show_images(images, labels, title='examples'):\n",
    "    images = np.transpose(images, (0, 2, 3, 1))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "    for n in range(25):\n",
    "        plt.subplot(5,5,n+1)\n",
    "        img = images[n]\n",
    "        img = img.squeeze()\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'{labels[n]}')\n",
    "        plt.axis('off')\n",
    "    _ = plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "# show_images(seed_inputs, list(range(seed_inputs.shape[0])))\n",
    "# print(seed_inputs[0])\n",
    "# batch_outputs1 = model1.batch_forward(seed_inputs)\n",
    "# batch_preds1 = batch_outputs1.to('cpu').data.max(1)\n",
    "# print(batch_preds1)\n",
    "\n",
    "m = models[2]\n",
    "mm = m.torch_model\n",
    "test_loader = m.benchmark.get_dataloader(m.dataset_id, split='test')\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     mm.eval()\n",
    "#     total = 0\n",
    "#     top1 = 0\n",
    "#     for i, (batch, label) in enumerate(test_loader):\n",
    "#         batch, label = batch.to(DEVICE), label.to(DEVICE)\n",
    "#         total += batch.size(0)\n",
    "#         out = mm(batch)\n",
    "#         _, pred = out.max(dim=1)\n",
    "#         top1 += int(pred.eq(label).sum().item())\n",
    "\n",
    "# acc = float(top1) / total * 100\n",
    "# print(top1, total, acc)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        if i != 10:\n",
    "            continue\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        outputs = mm(images)\n",
    "        _, preds = outputs.max(dim=1)\n",
    "        print(outputs[0])\n",
    "        labels = [f'{label}-{preds[i]}' for i,label in enumerate(list(labels))]\n",
    "        show_images(images.to('cpu').numpy(), labels)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.fe_mobilenet import mbnetv2_dropout\n",
    "import os\n",
    "\n",
    "torch_model = mbnetv2_dropout(\n",
    "            pretrained=False,\n",
    "            num_classes=67\n",
    "        )\n",
    "ckpt = torch.load(os.path.join('models', 'train(mbnetv2,MIT67)-', 'ckpt.pth'))\n",
    "torch_model.load_state_dict(ckpt['state_dict'])\n",
    "mm = torch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
