{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t pretrain(mbnetv2,ImageNet)-\n",
      "1\t pretrain(resnet18,ImageNet)-\n",
      "2\t train(mbnetv2,Flower102)-\n",
      "3\t train(mbnetv2,SDog120)-\n",
      "4\t train(resnet18,Flower102)-\n",
      "5\t train(resnet18,SDog120)-\n",
      "6\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "7\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "8\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "9\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "10\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "11\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "12\t pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "13\t pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "14\t pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "15\t pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "16\t pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "17\t pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "18\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-quantize(qint8)-\n",
      "19\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-quantize(float16)-\n",
      "20\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-quantize(qint8)-\n",
      "21\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-quantize(float16)-\n",
      "22\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-quantize(qint8)-\n",
      "23\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-quantize(float16)-\n",
      "24\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-quantize(qint8)-\n",
      "25\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-quantize(float16)-\n",
      "26\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-quantize(qint8)-\n",
      "27\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-quantize(float16)-\n",
      "28\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-quantize(qint8)-\n",
      "29\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-quantize(float16)-\n",
      "30\t pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-quantize(qint8)-\n",
      "31\t pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-quantize(float16)-\n",
      "32\t pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-quantize(qint8)-\n",
      "33\t pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-quantize(float16)-\n",
      "34\t pretrain(resnet18,ImageNet)-transfer(Flower102,1)-quantize(qint8)-\n",
      "35\t pretrain(resnet18,ImageNet)-transfer(Flower102,1)-quantize(float16)-\n",
      "36\t pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-quantize(qint8)-\n",
      "37\t pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-quantize(float16)-\n",
      "38\t pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-quantize(qint8)-\n",
      "39\t pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-quantize(float16)-\n",
      "40\t pretrain(resnet18,ImageNet)-transfer(SDog120,1)-quantize(qint8)-\n",
      "41\t pretrain(resnet18,ImageNet)-transfer(SDog120,1)-quantize(float16)-\n",
      "42\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "43\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "44\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "45\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "46\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "47\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "48\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "49\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "50\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "51\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "52\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "53\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "54\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "55\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "56\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "57\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "58\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "59\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "60\t pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "61\t pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "62\t pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "63\t pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "64\t pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "65\t pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "66\t pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "67\t pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "68\t pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "69\t pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "70\t pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "71\t pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "72\t pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "73\t pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "74\t pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "75\t pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "76\t pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "77\t pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "78\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "79\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "80\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "81\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "82\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "83\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "84\t pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "85\t pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "86\t pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "87\t pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "88\t pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "89\t pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "90\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "91\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "92\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "93\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "94\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "95\t pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "96\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "97\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "98\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "99\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "100\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "101\t pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "102\t pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "103\t pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "104\t pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "105\t pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "106\t pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "107\t pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "108\t pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "109\t pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "110\t pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "111\t pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "112\t pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "113\t pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "114\t train(mbnetv2,Flower102)-prune(0.2)-\n",
      "115\t train(mbnetv2,Flower102)-prune(0.5)-\n",
      "116\t train(mbnetv2,Flower102)-prune(0.8)-\n",
      "117\t train(mbnetv2,SDog120)-prune(0.2)-\n",
      "118\t train(mbnetv2,SDog120)-prune(0.5)-\n",
      "119\t train(mbnetv2,SDog120)-prune(0.8)-\n",
      "120\t train(resnet18,Flower102)-prune(0.2)-\n",
      "121\t train(resnet18,Flower102)-prune(0.5)-\n",
      "122\t train(resnet18,Flower102)-prune(0.8)-\n",
      "123\t train(resnet18,SDog120)-prune(0.2)-\n",
      "124\t train(resnet18,SDog120)-prune(0.5)-\n",
      "125\t train(resnet18,SDog120)-prune(0.8)-\n",
      "126\t train(mbnetv2,Flower102)-distill()-\n",
      "127\t train(mbnetv2,SDog120)-distill()-\n",
      "128\t train(resnet18,Flower102)-distill()-\n",
      "129\t train(resnet18,SDog120)-distill()-\n",
      "130\t train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "131\t train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "132\t train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "133\t train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "134\t train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "135\t train(resnet18,Flower102)-steal(resnet18)-\n",
      "136\t train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "137\t train(resnet18,SDog120)-steal(resnet18)-\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(name)-12s %(levelname)-8s %(message)s\")\n",
    "\n",
    "from benchmark import ImageBenchmark\n",
    "bench = ImageBenchmark()\n",
    "models = list(bench.list_models())\n",
    "models_dict = {}\n",
    "for i, model in enumerate(models):\n",
    "    if not model.torch_model_exists():\n",
    "        continue\n",
    "    print(f'{i}\\t {model.__str__()}')\n",
    "    models_dict[model.__str__()] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeldiff import ModelDiff\n",
    "\n",
    "def compare_with_seed(model1, model2, truth=-1):\n",
    "    print(f'comparing:\\n  model1={model1}\\n  model2={model2}')\n",
    "    md = ModelDiff(model1, model2)\n",
    "    seed_inputs = md.get_seed_inputs(rand=False)\n",
    "    sim = md.compute_similarity_with_inputs(seed_inputs)\n",
    "    if truth == -1:\n",
    "        truth = 1 if model1.__str__().split('-')[0] == model2.__str__().split('-')[0] else 0\n",
    "    print(f' similarity is {sim}, truth is {truth}')\n",
    "\n",
    "def test(compare):\n",
    "    # compare(models[23], models[38], 1) # should be similar\n",
    "    compare(models[1], models[0], 0)   # should be different\n",
    "#     compare(models[13], models[25], 0) # should be different\n",
    "#     compare(models[13], models[22], 0) # should be different\n",
    "    compare(models[1], models[17], 1)  # should be similar\n",
    "    compare(models[16], models[13], 1) # should be similar\n",
    "    compare(models[13], models[12], 1) # should be similar\n",
    "    \n",
    "# test(compare_with_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'\n",
    "\n",
    "def gen_adv_inputs(model, inputs):\n",
    "    from advertorch.attacks import LinfPGDAttack\n",
    "    def myloss(yhat, y):\n",
    "        return -((yhat[:,0]-y[:,0])**2 + 0.1*((yhat[:,1:]-y[:,1:])**2).mean(1)).mean()\n",
    "        \n",
    "    model = model.to(DEVICE)\n",
    "    inputs = torch.from_numpy(inputs).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        clean_outputs = model(inputs)\n",
    "    \n",
    "    output_shape = clean_outputs.shape\n",
    "    batch_size = output_shape[0]\n",
    "    num_classes = output_shape[1]\n",
    "    \n",
    "    y = torch.zeros(size=output_shape).to(DEVICE)\n",
    "    y[:, 0] = 1000\n",
    "    # more diversity\n",
    "#     rand_idx = torch.randint(low=0, high=num_classes, size=(batch_size,))\n",
    "#     y = torch.nn.functional.one_hot(rand_idx, num_classes=num_classes).to(DEVICE) * 10\n",
    "#     print(y)\n",
    "    \n",
    "    adversary = LinfPGDAttack(\n",
    "        model, loss_fn=myloss, eps=0.1,\n",
    "        nb_iter=40, eps_iter=0.01, \n",
    "        rand_init=True, clip_min=-2.2, clip_max=2.2,\n",
    "        targeted=False\n",
    "    )\n",
    "    \n",
    "    adv_inputs = adversary.perturb(inputs, y)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        adv_outputs = model(adv_inputs).to('cpu').numpy()\n",
    "#     print(adv_outputs)\n",
    "    torch.cuda.empty_cache()\n",
    "    return adv_inputs.to('cpu').numpy()\n",
    "\n",
    "\n",
    "model = models_dict['pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-']\n",
    "seed_inputs = model.get_seed_inputs(100, rand=False)\n",
    "seed_outputs = model.batch_forward(seed_inputs)\n",
    "_, seed_preds = seed_outputs.to('cpu').data.max(1)\n",
    "\n",
    "adv_inputs = gen_adv_inputs(model.torch_model, seed_inputs)\n",
    "adv_outputs = model.batch_forward(adv_inputs)\n",
    "_, adv_preds = adv_outputs.to('cpu').data.max(1)\n",
    "\n",
    "print(f\"seed_preds={seed_preds}, adv_preds={adv_preds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'\n",
    "image_size = 224\n",
    "\n",
    "def expand_vector(x, size):\n",
    "    batch_size = x.size(0)\n",
    "    x = x.view(-1, 3, size, size)\n",
    "    z = torch.zeros(batch_size, 3, image_size, image_size).to(DEVICE)\n",
    "    z[:, :, :size, :size] = x\n",
    "    return z\n",
    "\n",
    "def normalize(x):\n",
    "    return utils.apply_normalization(x, 'imagenet')\n",
    "\n",
    "def get_probs(model, x, y):\n",
    "    output = model(x)\n",
    "    probs = torch.index_select(torch.nn.functional.softmax(output, -1).data, 1, y)\n",
    "    return torch.diag(probs).cpu()\n",
    "\n",
    "def get_preds(model, x):\n",
    "    output = model(x)\n",
    "    _, preds = output.data.max(1)\n",
    "    return preds\n",
    "\n",
    "# runs simba on a batch of images <images_batch> with true labels (for untargeted attack) or target labels\n",
    "# (for targeted attack) <labels_batch>\n",
    "def dct_attack_batch(model, images_batch, labels_batch, max_iters, freq_dims, stride, epsilon, order='rand', targeted=False, pixel_attack=False, log_every=1):\n",
    "    batch_size = images_batch.size(0)\n",
    "    image_size = images_batch.size(2)\n",
    "    # sample a random ordering for coordinates independently per batch element\n",
    "    if order == 'rand':\n",
    "        indices = torch.randperm(3 * freq_dims * freq_dims)[:max_iters]\n",
    "    elif order == 'diag':\n",
    "        indices = utils.diagonal_order(image_size, 3)[:max_iters]\n",
    "    elif order == 'strided':\n",
    "        indices = utils.block_order(image_size, 3, initial_size=freq_dims, stride=stride)[:max_iters]\n",
    "    else:\n",
    "        indices = utils.block_order(image_size, 3)[:max_iters]\n",
    "    if order == 'rand':\n",
    "        expand_dims = freq_dims\n",
    "    else:\n",
    "        expand_dims = image_size\n",
    "    n_dims = 3 * expand_dims * expand_dims\n",
    "    x = torch.zeros(batch_size, n_dims)\n",
    "    # logging tensors\n",
    "    probs = torch.zeros(batch_size, max_iters)\n",
    "    succs = torch.zeros(batch_size, max_iters)\n",
    "    queries = torch.zeros(batch_size, max_iters)\n",
    "    l2_norms = torch.zeros(batch_size, max_iters)\n",
    "    linf_norms = torch.zeros(batch_size, max_iters)\n",
    "    prev_probs = get_probs(model, images_batch, labels_batch)\n",
    "    preds = get_preds(model, images_batch)\n",
    "    if pixel_attack:\n",
    "        trans = lambda z: z\n",
    "    else:\n",
    "        trans = lambda z: utils.block_idct(z, block_size=image_size, linf_bound=args.linf_bound)\n",
    "    remaining_indices = torch.arange(0, batch_size).long()\n",
    "    for k in range(max_iters):\n",
    "        dim = indices[k]\n",
    "        expanded = (images_batch[remaining_indices] + trans(expand_vector(x[remaining_indices], expand_dims))).clamp(-2.6, 2.6)\n",
    "        perturbation = trans(expand_vector(x, expand_dims))\n",
    "        l2_norms[:, k] = perturbation.view(batch_size, -1).norm(2, 1)\n",
    "        linf_norms[:, k] = perturbation.view(batch_size, -1).abs().max(1)[0]\n",
    "        preds_next = get_preds(model, expanded)\n",
    "        preds[remaining_indices] = preds_next\n",
    "        if targeted:\n",
    "            remaining = preds.ne(labels_batch)\n",
    "        else:\n",
    "            remaining = preds.eq(labels_batch)\n",
    "        # check if all images are misclassified and stop early\n",
    "        if remaining.sum() == 0:\n",
    "            adv = (images_batch + trans(expand_vector(x, expand_dims))).clamp(0, 1)\n",
    "            probs_k = get_probs(model, adv, labels_batch)\n",
    "            probs[:, k:] = probs_k.unsqueeze(1).repeat(1, max_iters - k)\n",
    "            succs[:, k:] = torch.ones(batch_size, max_iters - k)\n",
    "            queries[:, k:] = torch.zeros(batch_size, max_iters - k)\n",
    "            break\n",
    "        remaining_indices = torch.arange(0, batch_size)[remaining].long()\n",
    "        if k > 0:\n",
    "            succs[:, k-1] = ~remaining\n",
    "        diff = torch.zeros(remaining.sum(), n_dims)\n",
    "        diff[:, dim] = epsilon\n",
    "        left_vec = x[remaining_indices] - diff\n",
    "        right_vec = x[remaining_indices] + diff\n",
    "        # trying negative direction\n",
    "        adv = (images_batch[remaining_indices] + trans(expand_vector(left_vec, expand_dims))).clamp(-2.6, 2.6)\n",
    "        left_probs = get_probs(model, adv, labels_batch[remaining_indices])\n",
    "        queries_k = torch.zeros(batch_size)\n",
    "        # increase query count for all images\n",
    "        queries_k[remaining_indices] += 1\n",
    "        if targeted:\n",
    "            improved = left_probs.gt(prev_probs[remaining_indices])\n",
    "        else:\n",
    "            improved = left_probs.lt(prev_probs[remaining_indices])\n",
    "        # only increase query count further by 1 for images that did not improve in adversarial loss\n",
    "        if improved.sum() < remaining_indices.size(0):\n",
    "            queries_k[remaining_indices[~improved]] += 1\n",
    "        # try positive directions\n",
    "        adv = (images_batch[remaining_indices] + trans(expand_vector(right_vec, expand_dims))).clamp(-2.6, 2.6)\n",
    "        right_probs = get_probs(model, adv, labels_batch[remaining_indices])\n",
    "        if targeted:\n",
    "            right_improved = right_probs.gt(torch.max(prev_probs[remaining_indices], left_probs))\n",
    "        else:\n",
    "            right_improved = right_probs.lt(torch.min(prev_probs[remaining_indices], left_probs))\n",
    "        probs_k = prev_probs.clone()\n",
    "        # update x depending on which direction improved\n",
    "        if improved.sum() > 0:\n",
    "            left_indices = remaining_indices[improved]\n",
    "            left_mask_remaining = improved.unsqueeze(1).repeat(1, n_dims)\n",
    "            x[left_indices] = left_vec[left_mask_remaining].view(-1, n_dims)\n",
    "            probs_k[left_indices] = left_probs[improved]\n",
    "        if right_improved.sum() > 0:\n",
    "            right_indices = remaining_indices[right_improved]\n",
    "            right_mask_remaining = right_improved.unsqueeze(1).repeat(1, n_dims)\n",
    "            x[right_indices] = right_vec[right_mask_remaining].view(-1, n_dims)\n",
    "            probs_k[right_indices] = right_probs[right_improved]\n",
    "        probs[:, k] = probs_k\n",
    "        queries[:, k] = queries_k\n",
    "        prev_probs = probs[:, k]\n",
    "        if (k + 1) % log_every == 0 or k == max_iters - 1:\n",
    "            print('Iteration %d: queries = %.4f, prob = %.4f, remaining = %.4f' % (\n",
    "                    k + 1, queries.sum(1).mean(), probs[:, k].mean(), remaining.float().mean()))\n",
    "    expanded = (images_batch + trans(expand_vector(x, expand_dims))).clamp(-2.6, 2.6)\n",
    "    preds = get_preds(model, expanded)\n",
    "    if targeted:\n",
    "        remaining = preds.ne(labels_batch)\n",
    "    else:\n",
    "        remaining = preds.eq(labels_batch)\n",
    "    succs[:, max_iters-1] = ~remaining\n",
    "    return expanded, probs, succs, queries, l2_norms, linf_norms\n",
    "\n",
    "\n",
    "def search_adv_inputs(model, inputs, labels):\n",
    "    images_batch = torch.from_numpy(inputs).to(DEVICE)\n",
    "#     labels_batch = torch.zeros(len(inputs)).long().to(DEVICE)\n",
    "    labels_batch = labels.long().to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        adv, probs, succs, queries, l2_norms, linf_norms = dct_attack_batch(\n",
    "            model, images_batch=images_batch, labels_batch=labels_batch,\n",
    "            max_iters=5000, freq_dims=image_size, stride=7, epsilon=0.2, order='rand',\n",
    "            targeted=False, pixel_attack=True, log_every=10\n",
    "        )\n",
    "    return adv\n",
    "\n",
    "\n",
    "model = models_dict['pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-']\n",
    "seed_inputs = model.get_seed_inputs(100, rand=False)\n",
    "seed_outputs = model.batch_forward(seed_inputs)\n",
    "_, seed_preds = seed_outputs.to('cpu').data.max(1)\n",
    "\n",
    "adv_inputs = search_adv_inputs(model.torch_model, seed_inputs, seed_preds)\n",
    "adv_outputs = model.batch_forward(adv_inputs)\n",
    "_, adv_preds = adv_outputs.to('cpu').data.max(1)\n",
    "\n",
    "print(f\"seed_preds={seed_preds}, adv_preds={adv_preds}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_evaluation: score=0.0000, divergence=0.0000, diversity=1.3336, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6671, divergence=0.0002, diversity=1.3337, num_succ=0, num_remain=87\n",
      " 100-th evaluation: score=0.6848, divergence=0.0379, diversity=1.2937, num_succ=1, num_remain=39\n",
      " 200-th evaluation: score=0.6887, divergence=0.0508, diversity=1.2758, num_succ=1, num_remain=30\n",
      " 300-th evaluation: score=0.6948, divergence=0.0707, diversity=1.2482, num_succ=1, num_remain=38\n",
      " 400-th evaluation: score=0.7072, divergence=0.1054, diversity=1.2037, num_succ=1, num_remain=33\n",
      " 500-th evaluation: score=0.7203, divergence=0.1417, diversity=1.1571, num_succ=1, num_remain=23\n",
      " 600-th evaluation: score=0.7380, divergence=0.1865, diversity=1.1029, num_succ=1, num_remain=34\n",
      " 700-th evaluation: score=0.7486, divergence=0.2157, diversity=1.0658, num_succ=1, num_remain=30\n",
      " 800-th evaluation: score=0.7665, divergence=0.2593, diversity=1.0145, num_succ=1, num_remain=23\n",
      " 900-th evaluation: score=0.7801, divergence=0.2925, diversity=0.9753, num_succ=1, num_remain=20\n",
      "1000-th evaluation: score=0.7918, divergence=0.3211, diversity=0.9414, num_succ=2, num_remain=23\n",
      "1100-th evaluation: score=0.8032, divergence=0.3496, diversity=0.9073, num_succ=2, num_remain=20\n",
      "1200-th evaluation: score=0.8140, divergence=0.3753, diversity=0.8774, num_succ=3, num_remain=16\n",
      "1300-th evaluation: score=0.8240, divergence=0.3981, diversity=0.8518, num_succ=3, num_remain=25\n",
      "1400-th evaluation: score=0.8329, divergence=0.4177, diversity=0.8303, num_succ=3, num_remain=19\n",
      "1500-th evaluation: score=0.8410, divergence=0.4361, diversity=0.8098, num_succ=3, num_remain=16\n",
      "1600-th evaluation: score=0.8495, divergence=0.4547, diversity=0.7897, num_succ=3, num_remain=20\n",
      "1700-th evaluation: score=0.8595, divergence=0.4745, diversity=0.7700, num_succ=4, num_remain=17\n",
      "1800-th evaluation: score=0.8692, divergence=0.4949, diversity=0.7486, num_succ=4, num_remain=23\n",
      "1900-th evaluation: score=0.8768, divergence=0.5102, diversity=0.7332, num_succ=4, num_remain=19\n",
      "2000-th evaluation: score=0.8852, divergence=0.5264, diversity=0.7175, num_succ=6, num_remain=13\n",
      "2100-th evaluation: score=0.8930, divergence=0.5400, diversity=0.7060, num_succ=9, num_remain=16\n",
      "2200-th evaluation: score=0.8960, divergence=0.5467, diversity=0.6987, num_succ=9, num_remain=9\n",
      "2300-th evaluation: score=0.8983, divergence=0.5517, diversity=0.6932, num_succ=9, num_remain=8\n",
      "2400-th evaluation: score=0.9034, divergence=0.5602, diversity=0.6862, num_succ=11, num_remain=8\n",
      "2500-th evaluation: score=0.9061, divergence=0.5661, diversity=0.6801, num_succ=11, num_remain=7\n",
      "2600-th evaluation: score=0.9097, divergence=0.5729, diversity=0.6736, num_succ=13, num_remain=9\n",
      "2700-th evaluation: score=0.9130, divergence=0.5791, diversity=0.6678, num_succ=14, num_remain=9\n",
      "2800-th evaluation: score=0.9166, divergence=0.5863, diversity=0.6605, num_succ=15, num_remain=11\n",
      "2900-th evaluation: score=0.9201, divergence=0.5921, diversity=0.6560, num_succ=15, num_remain=7\n",
      "3000-th evaluation: score=0.9221, divergence=0.5959, diversity=0.6524, num_succ=16, num_remain=8\n",
      "3100-th evaluation: score=0.9243, divergence=0.6001, diversity=0.6485, num_succ=16, num_remain=7\n",
      "3200-th evaluation: score=0.9261, divergence=0.6039, diversity=0.6444, num_succ=16, num_remain=4\n",
      "3300-th evaluation: score=0.9277, divergence=0.6070, diversity=0.6414, num_succ=16, num_remain=4\n",
      "3400-th evaluation: score=0.9297, divergence=0.6108, diversity=0.6380, num_succ=16, num_remain=6\n",
      "3500-th evaluation: score=0.9313, divergence=0.6129, diversity=0.6368, num_succ=16, num_remain=5\n",
      "3600-th evaluation: score=0.9329, divergence=0.6156, diversity=0.6345, num_succ=17, num_remain=4\n",
      "3700-th evaluation: score=0.9345, divergence=0.6185, diversity=0.6321, num_succ=17, num_remain=3\n",
      "3800-th evaluation: score=0.9381, divergence=0.6243, diversity=0.6275, num_succ=17, num_remain=4\n",
      "3900-th evaluation: score=0.9387, divergence=0.6258, diversity=0.6257, num_succ=17, num_remain=3\n",
      "4000-th evaluation: score=0.9397, divergence=0.6281, diversity=0.6232, num_succ=17, num_remain=3\n",
      "4100-th evaluation: score=0.9409, divergence=0.6304, diversity=0.6210, num_succ=17, num_remain=4\n",
      "4200-th evaluation: score=0.9416, divergence=0.6324, diversity=0.6183, num_succ=17, num_remain=3\n",
      "4300-th evaluation: score=0.9435, divergence=0.6358, diversity=0.6154, num_succ=19, num_remain=4\n",
      "4400-th evaluation: score=0.9467, divergence=0.6411, diversity=0.6111, num_succ=19, num_remain=3\n",
      "4500-th evaluation: score=0.9498, divergence=0.6460, diversity=0.6078, num_succ=21, num_remain=3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-2886af3f86ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m \u001b[0madv_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize_towards_goal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_model_on_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0madv_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madv_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-119-2886af3f86ff>\u001b[0m in \u001b[0;36moptimize_towards_goal\u001b[0;34m(model, seed_inputs, seed_outputs, seed_preds, max_iters, epsilon, lambda1, log_every, save_every)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mprev_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mmutate_right_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmutation_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mmutate_right_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutate_right_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mmutate_right_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutate_right_eval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mmutate_left_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmutation_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-119-2886af3f86ff>\u001b[0m in \u001b[0;36mevaluate_inputs\u001b[0;34m(model, inputs, seed_outputs, seed_preds, lambda1)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mchanged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ycli/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/ModelDiff/model/fe_resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_resnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/ModelDiff/model/fe_resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_layer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_layer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ycli/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ycli/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ycli/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/ModelDiff/model/fe_resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ycli/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ycli/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ycli/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    711\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    712\u001b[0m                 \u001b[0m_global_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m                 self._forward_pre_hooks.values()):\n\u001b[0m\u001b[1;32m    714\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import logging\n",
    "import copy\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(name)-12s %(levelname)-8s %(message)s\")\n",
    "\n",
    "\n",
    "from benchmark import ImageBenchmark\n",
    "bench = ImageBenchmark()\n",
    "models = list(bench.list_models())\n",
    "models_dict = {}\n",
    "for i, model in enumerate(models):\n",
    "    if not model.torch_model_exists():\n",
    "        continue\n",
    "#     print(f'{i}\\t {model.__str__()}')\n",
    "    models_dict[model.__str__()] = model\n",
    "\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "image_size = 224\n",
    "\n",
    "def expand_vector(x, image_size):\n",
    "    batch_size = x.size(0)\n",
    "    x = x.view(-1, 3, image_size, image_size)\n",
    "    z = torch.zeros(batch_size, 3, image_size, image_size).to(DEVICE)\n",
    "    z[:, :, :image_size, :image_size] = x\n",
    "    return z\n",
    "\n",
    "def evaluate_inputs(model, inputs, seed_outputs, seed_preds, lambda1=0.5):\n",
    "    outputs = model(inputs)\n",
    "    _, preds = outputs.data.max(1)\n",
    "    changed = preds.ne(seed_preds)\n",
    "    outputs = torch.nn.functional.softmax(outputs, -1)\n",
    "    seed_outputs = torch.nn.functional.softmax(seed_outputs, -1)\n",
    "    reduce_dims = tuple(range(outputs.dim())[1:])\n",
    "    divergence_arr = torch.sum((outputs - seed_outputs) ** 2, dim=reduce_dims) ** 0.5\n",
    "    divergence = torch.mean(divergence_arr)\n",
    "#     divergence_cos = F.cosine_similarity(outputs, seed_outputs)\n",
    "#     divergence_kld = F.kl_div(seed_outputs, outputs, reduction='none')\n",
    "#     print(divergence_kld)\n",
    "    diversity_matrix = torch.cdist(outputs, outputs, p=2.0)\n",
    "    diversity = torch.mean(diversity_matrix)\n",
    "    quantile = lambda t, q: t.view(-1).kthvalue(1 + round(float(q) * (t.numel() - 1))).values.item()\n",
    "    diversity_quantile = quantile(diversity_matrix, 0.011)\n",
    "#     diversity = diversity ** 2\n",
    "    score = divergence + lambda1 * diversity\n",
    "    succ = preds.ne(seed_preds)\n",
    "    low_divergence_indices = list(torch.nonzero(divergence_arr.lt(divergence)).cpu().numpy())\n",
    "    low_diversity_indices = list(torch.nonzero(diversity_matrix.lt(diversity_quantile)).cpu().numpy())\n",
    "    remaining_indices = set()\n",
    "#     print(changed)\n",
    "    for i in low_divergence_indices:\n",
    "        if not changed[i].cpu():\n",
    "            remaining_indices.add(i[0])\n",
    "    for i in low_diversity_indices:\n",
    "        if i[0] == i[1]:\n",
    "            continue\n",
    "        if not changed[i[0]]:\n",
    "            remaining_indices.add(i[0])\n",
    "        if not changed[i[1]]:\n",
    "            remaining_indices.add(i[1])\n",
    "    remaining_indices = sorted(remaining_indices)\n",
    "#     print(f' low_divergence_indices={len(low_divergence_indices)}\\n low_diversity_indices={len(low_diversity_indices)}\\n remaining_indices={len(remaining_indices)}')\n",
    "    eval_line = f'score={score:.4f}, divergence={divergence:.4f}, diversity={diversity:.4f}, num_succ={succ.sum()}, num_remain={len(remaining_indices)}'\n",
    "    return {\n",
    "        'outputs': outputs,\n",
    "        'preds': preds,\n",
    "        'score': score,\n",
    "        'divergence': divergence,\n",
    "        'diversity': diversity,\n",
    "        'succ': succ,\n",
    "        'remaining': remaining_indices,\n",
    "        'eval_line': eval_line\n",
    "    }\n",
    "    \n",
    "    \n",
    "def optimize_towards_goal(\n",
    "    model, seed_inputs, seed_outputs, seed_preds, \n",
    "    max_iters=10000, mutation_size=1, epsilon=0.5, lambda1=0.0, log_every=100, save_every=1000):\n",
    "#     seed_inputs = torch.from_numpy(seed_inputs).to(DEVICE)\n",
    "#     seed_outputs = torch.from_numpy(seed_outputs).to(DEVICE)\n",
    "#     seed_preds = torch.from_numpy(seed_preds).to(DEVICE)\n",
    "    input_shape = seed_inputs[0].shape\n",
    "    n_inputs = seed_inputs.shape[0]\n",
    "    ndims = np.prod(input_shape)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = copy.copy(seed_inputs)\n",
    "        saved_inputs = {}\n",
    "        evaluation = evaluate_inputs(model, inputs, seed_outputs, seed_preds, lambda1)\n",
    "        print(f'initial_evaluation: {evaluation[\"eval_line\"]}')\n",
    "\n",
    "        for i in range(max_iters):\n",
    "#             print(f'mutation {i}-th iteration')\n",
    "\n",
    "            # mutation_pos = np.random.randint(0, ndims)\n",
    "            mutation_pos = np.random.choice(ndims, size=mutation_size, replace=False)\n",
    "            mutation = np.zeros(ndims).astype(np.float32)\n",
    "            mutation[mutation_pos] = epsilon\n",
    "            mutation = np.reshape(mutation, input_shape)\n",
    "\n",
    "            mutation_batch = np.zeros(shape=inputs.shape).astype(np.float32)\n",
    "#             all_indices = list(range(0, n_inputs))\n",
    "#             mutation_indices = np.random.choice(all_indices, size=int(n_inputs * 0.85), replace=False)\n",
    "#             print(mutation_indices)\n",
    "#             mutation_idx = np.random.randint(0, n_inputs)\n",
    "            mutation_indices = evaluation['remaining']\n",
    "            if len(mutation_indices) == 0:\n",
    "                print(f'{i:4d}-th - no remaining indice: {evaluation[\"eval_line\"]}')\n",
    "                break\n",
    "#             print(mutation_indices)\n",
    "            mutation_batch[mutation_indices] = mutation\n",
    "            mutation_batch = torch.from_numpy(mutation_batch).to(DEVICE)\n",
    "\n",
    "            prev_score = evaluation[\"score\"]\n",
    "            mutate_right_inputs = (inputs + mutation_batch).clamp(-2.6, 2.6)\n",
    "            mutate_right_eval = evaluate_inputs(model, mutate_right_inputs, seed_outputs, seed_preds)\n",
    "            mutate_right_score = mutate_right_eval['score']\n",
    "            mutate_left_inputs = (inputs - mutation_batch).clamp(-2.6, 2.6)\n",
    "            mutate_left_eval = evaluate_inputs(model, mutate_left_inputs, seed_outputs, seed_preds)\n",
    "            mutate_left_score = mutate_left_eval['score']\n",
    "\n",
    "            if mutate_right_score <= prev_score and mutate_left_score <= prev_score:\n",
    "                pass\n",
    "            elif mutate_right_score > mutate_left_score:\n",
    "#                 print(f'mutate right: {prev_score}->{mutate_right_score}')\n",
    "                inputs = mutate_right_inputs\n",
    "                evaluation = mutate_right_eval\n",
    "            else:\n",
    "#                 print(f'mutate left: {prev_score}->{mutate_left_score}')\n",
    "                inputs = mutate_left_inputs\n",
    "                evaluation = mutate_left_eval\n",
    "            if i % log_every == 0:\n",
    "                print(f'{i:4d}-th evaluation: {evaluation[\"eval_line\"]}')\n",
    "            if i % save_every == 0:\n",
    "                saved_inputs[i] = copy.copy(inputs.cpu().numpy())\n",
    "        return inputs, saved_inputs\n",
    "\n",
    "model = models_dict['pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-']\n",
    "seed_inputs = model.get_seed_inputs(100, rand=False)\n",
    "seed_inputs = torch.from_numpy(seed_inputs).to(DEVICE)\n",
    "seed_outputs = model.batch_forward(seed_inputs)\n",
    "_, seed_preds = seed_outputs.data.max(1)\n",
    "\n",
    "adv_inputs, _ = optimize_towards_goal(model.torch_model_on_device, seed_inputs, seed_outputs, seed_preds, log_every=100)\n",
    "adv_outputs = model.batch_forward(adv_inputs).cpu()\n",
    "_, adv_preds = adv_outputs.data.max(1)\n",
    "\n",
    "print(f\"seed_preds={seed_preds}, adv_preds={adv_preds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "initial_evaluation: score=0.6356, divergence=0.0000, diversity=1.2712, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6359, divergence=0.0003, diversity=1.2713, num_succ=0, num_remain=89\n",
      " 100-th evaluation: score=0.6460, divergence=0.0121, diversity=1.2679, num_succ=0, num_remain=34\n",
      " 200-th evaluation: score=0.6478, divergence=0.0144, diversity=1.2668, num_succ=0, num_remain=35\n",
      " 300-th evaluation: score=0.6481, divergence=0.0148, diversity=1.2667, num_succ=0, num_remain=33\n",
      " 400-th evaluation: score=0.6488, divergence=0.0156, diversity=1.2664, num_succ=0, num_remain=33\n",
      " 500-th evaluation: score=0.6490, divergence=0.0159, diversity=1.2661, num_succ=0, num_remain=33\n",
      " 600-th evaluation: score=0.6492, divergence=0.0164, diversity=1.2657, num_succ=0, num_remain=33\n",
      " 700-th evaluation: score=0.6495, divergence=0.0166, diversity=1.2657, num_succ=0, num_remain=31\n",
      " 800-th evaluation: score=0.6498, divergence=0.0172, diversity=1.2652, num_succ=0, num_remain=30\n",
      " 900-th evaluation: score=0.6500, divergence=0.0176, diversity=1.2648, num_succ=0, num_remain=28\n",
      "1000-th evaluation: score=0.6508, divergence=0.0189, diversity=1.2637, num_succ=0, num_remain=27\n",
      "1100-th evaluation: score=0.6509, divergence=0.0191, diversity=1.2637, num_succ=0, num_remain=27\n",
      "1200-th evaluation: score=0.6511, divergence=0.0193, diversity=1.2636, num_succ=0, num_remain=25\n",
      "1300-th evaluation: score=0.6512, divergence=0.0195, diversity=1.2635, num_succ=0, num_remain=24\n",
      "1400-th evaluation: score=0.6514, divergence=0.0197, diversity=1.2634, num_succ=0, num_remain=25\n",
      "1500-th evaluation: score=0.6540, divergence=0.0244, diversity=1.2594, num_succ=0, num_remain=33\n",
      "1600-th evaluation: score=0.6562, divergence=0.0275, diversity=1.2573, num_succ=0, num_remain=30\n",
      "1700-th evaluation: score=0.6567, divergence=0.0284, diversity=1.2565, num_succ=0, num_remain=31\n",
      "1800-th evaluation: score=0.6575, divergence=0.0298, diversity=1.2555, num_succ=0, num_remain=35\n",
      "1900-th evaluation: score=0.6580, divergence=0.0308, diversity=1.2545, num_succ=0, num_remain=30\n",
      "2000-th evaluation: score=0.6586, divergence=0.0316, diversity=1.2540, num_succ=0, num_remain=27\n",
      "2100-th evaluation: score=0.6590, divergence=0.0321, diversity=1.2536, num_succ=0, num_remain=24\n",
      "2200-th evaluation: score=0.6593, divergence=0.0329, diversity=1.2529, num_succ=0, num_remain=26\n",
      "2300-th evaluation: score=0.6603, divergence=0.0351, diversity=1.2502, num_succ=0, num_remain=37\n",
      "2400-th evaluation: score=0.6610, divergence=0.0363, diversity=1.2494, num_succ=0, num_remain=24\n",
      "2500-th evaluation: score=0.6614, divergence=0.0368, diversity=1.2492, num_succ=0, num_remain=25\n",
      "2600-th evaluation: score=0.6619, divergence=0.0377, diversity=1.2484, num_succ=0, num_remain=26\n",
      "2700-th evaluation: score=0.6620, divergence=0.0379, diversity=1.2484, num_succ=0, num_remain=22\n",
      "2800-th evaluation: score=0.6622, divergence=0.0380, diversity=1.2483, num_succ=0, num_remain=22\n",
      "2900-th evaluation: score=0.6628, divergence=0.0389, diversity=1.2477, num_succ=0, num_remain=25\n",
      "3000-th evaluation: score=0.6631, divergence=0.0394, diversity=1.2475, num_succ=0, num_remain=21\n",
      "3100-th evaluation: score=0.6632, divergence=0.0394, diversity=1.2476, num_succ=0, num_remain=21\n",
      "3200-th evaluation: score=0.6633, divergence=0.0395, diversity=1.2476, num_succ=0, num_remain=21\n",
      "3300-th evaluation: score=0.6639, divergence=0.0400, diversity=1.2477, num_succ=0, num_remain=21\n",
      "3400-th evaluation: score=0.6642, divergence=0.0407, diversity=1.2471, num_succ=0, num_remain=21\n",
      "3500-th evaluation: score=0.6643, divergence=0.0407, diversity=1.2471, num_succ=0, num_remain=22\n",
      "3600-th evaluation: score=0.6644, divergence=0.0410, diversity=1.2469, num_succ=0, num_remain=21\n",
      "3700-th evaluation: score=0.6646, divergence=0.0413, diversity=1.2466, num_succ=0, num_remain=21\n",
      "3800-th evaluation: score=0.6650, divergence=0.0418, diversity=1.2464, num_succ=0, num_remain=22\n",
      "3900-th evaluation: score=0.6654, divergence=0.0424, diversity=1.2461, num_succ=0, num_remain=22\n",
      "4000-th evaluation: score=0.6657, divergence=0.0430, diversity=1.2454, num_succ=0, num_remain=28\n",
      "4100-th evaluation: score=0.6664, divergence=0.0446, diversity=1.2436, num_succ=0, num_remain=27\n",
      "4200-th evaluation: score=0.6670, divergence=0.0457, diversity=1.2426, num_succ=0, num_remain=25\n",
      "4300-th evaluation: score=0.6671, divergence=0.0458, diversity=1.2426, num_succ=0, num_remain=26\n",
      "4400-th evaluation: score=0.6674, divergence=0.0463, diversity=1.2421, num_succ=0, num_remain=23\n",
      "4500-th evaluation: score=0.6676, divergence=0.0466, diversity=1.2419, num_succ=0, num_remain=28\n",
      "4600-th evaluation: score=0.6683, divergence=0.0487, diversity=1.2392, num_succ=0, num_remain=29\n",
      "4700-th evaluation: score=0.6686, divergence=0.0496, diversity=1.2381, num_succ=0, num_remain=26\n",
      "4800-th evaluation: score=0.6690, divergence=0.0502, diversity=1.2377, num_succ=0, num_remain=24\n",
      "4900-th evaluation: score=0.6694, divergence=0.0513, diversity=1.2362, num_succ=0, num_remain=26\n",
      "5000-th evaluation: score=0.6698, divergence=0.0521, diversity=1.2354, num_succ=0, num_remain=23\n",
      "5100-th evaluation: score=0.6703, divergence=0.0530, diversity=1.2345, num_succ=0, num_remain=23\n",
      "5200-th evaluation: score=0.6708, divergence=0.0539, diversity=1.2339, num_succ=0, num_remain=25\n",
      "5300-th evaluation: score=0.6712, divergence=0.0544, diversity=1.2336, num_succ=0, num_remain=25\n",
      "5400-th evaluation: score=0.6717, divergence=0.0556, diversity=1.2322, num_succ=0, num_remain=26\n",
      "5500-th evaluation: score=0.6722, divergence=0.0566, diversity=1.2310, num_succ=0, num_remain=26\n",
      "5600-th evaluation: score=0.6724, divergence=0.0571, diversity=1.2307, num_succ=0, num_remain=26\n",
      "5700-th evaluation: score=0.6729, divergence=0.0587, diversity=1.2285, num_succ=0, num_remain=27\n",
      "5800-th evaluation: score=0.6732, divergence=0.0593, diversity=1.2278, num_succ=0, num_remain=25\n",
      "5900-th evaluation: score=0.6746, divergence=0.0611, diversity=1.2270, num_succ=0, num_remain=31\n",
      "6000-th evaluation: score=0.6751, divergence=0.0619, diversity=1.2263, num_succ=0, num_remain=29\n",
      "6100-th evaluation: score=0.6758, divergence=0.0629, diversity=1.2257, num_succ=0, num_remain=29\n",
      "6200-th evaluation: score=0.6764, divergence=0.0643, diversity=1.2240, num_succ=0, num_remain=30\n",
      "6300-th evaluation: score=0.6771, divergence=0.0655, diversity=1.2232, num_succ=0, num_remain=24\n",
      "6400-th evaluation: score=0.6777, divergence=0.0662, diversity=1.2230, num_succ=0, num_remain=27\n",
      "6500-th evaluation: score=0.6780, divergence=0.0669, diversity=1.2222, num_succ=0, num_remain=25\n",
      "6600-th evaluation: score=0.6782, divergence=0.0671, diversity=1.2222, num_succ=0, num_remain=23\n",
      "6700-th evaluation: score=0.6783, divergence=0.0672, diversity=1.2223, num_succ=0, num_remain=24\n",
      "6800-th evaluation: score=0.6785, divergence=0.0673, diversity=1.2223, num_succ=0, num_remain=24\n",
      "6900-th evaluation: score=0.6785, divergence=0.0674, diversity=1.2223, num_succ=0, num_remain=23\n",
      "7000-th evaluation: score=0.6786, divergence=0.0675, diversity=1.2223, num_succ=0, num_remain=24\n",
      "7100-th evaluation: score=0.6787, divergence=0.0676, diversity=1.2222, num_succ=0, num_remain=23\n",
      "7200-th evaluation: score=0.6789, divergence=0.0680, diversity=1.2219, num_succ=0, num_remain=24\n",
      "7300-th evaluation: score=0.6791, divergence=0.0682, diversity=1.2218, num_succ=0, num_remain=23\n",
      "7400-th evaluation: score=0.6798, divergence=0.0696, diversity=1.2205, num_succ=0, num_remain=24\n",
      "7500-th evaluation: score=0.6801, divergence=0.0699, diversity=1.2204, num_succ=0, num_remain=25\n",
      "7600-th evaluation: score=0.6802, divergence=0.0700, diversity=1.2205, num_succ=0, num_remain=23\n",
      "7700-th evaluation: score=0.6803, divergence=0.0701, diversity=1.2205, num_succ=0, num_remain=23\n",
      "7800-th evaluation: score=0.6804, divergence=0.0701, diversity=1.2206, num_succ=0, num_remain=23\n",
      "7900-th evaluation: score=0.6806, divergence=0.0705, diversity=1.2202, num_succ=0, num_remain=24\n",
      "8000-th evaluation: score=0.6807, divergence=0.0706, diversity=1.2202, num_succ=0, num_remain=23\n",
      "8100-th evaluation: score=0.6808, divergence=0.0707, diversity=1.2202, num_succ=0, num_remain=23\n",
      "8200-th evaluation: score=0.6809, divergence=0.0708, diversity=1.2202, num_succ=0, num_remain=23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8300-th evaluation: score=0.6810, divergence=0.0709, diversity=1.2202, num_succ=0, num_remain=24\n",
      "8400-th evaluation: score=0.6811, divergence=0.0710, diversity=1.2202, num_succ=0, num_remain=23\n",
      "8500-th evaluation: score=0.6812, divergence=0.0712, diversity=1.2199, num_succ=0, num_remain=23\n",
      "8600-th evaluation: score=0.6813, divergence=0.0713, diversity=1.2199, num_succ=0, num_remain=23\n",
      "8700-th evaluation: score=0.6814, divergence=0.0714, diversity=1.2200, num_succ=0, num_remain=24\n",
      "8800-th evaluation: score=0.6814, divergence=0.0715, diversity=1.2198, num_succ=0, num_remain=23\n",
      "8900-th evaluation: score=0.6816, divergence=0.0719, diversity=1.2194, num_succ=0, num_remain=24\n",
      "9000-th evaluation: score=0.6817, divergence=0.0720, diversity=1.2193, num_succ=0, num_remain=23\n",
      "9100-th evaluation: score=0.6817, divergence=0.0720, diversity=1.2194, num_succ=0, num_remain=23\n",
      "9200-th evaluation: score=0.6818, divergence=0.0721, diversity=1.2194, num_succ=0, num_remain=23\n",
      "9300-th evaluation: score=0.6818, divergence=0.0721, diversity=1.2195, num_succ=0, num_remain=23\n",
      "9400-th evaluation: score=0.6818, divergence=0.0721, diversity=1.2194, num_succ=0, num_remain=23\n",
      "9500-th evaluation: score=0.6819, divergence=0.0721, diversity=1.2194, num_succ=0, num_remain=23\n",
      "9600-th evaluation: score=0.6819, divergence=0.0722, diversity=1.2194, num_succ=0, num_remain=23\n",
      "9700-th evaluation: score=0.6819, divergence=0.0722, diversity=1.2194, num_succ=0, num_remain=23\n",
      "9800-th evaluation: score=0.6820, divergence=0.0724, diversity=1.2192, num_succ=0, num_remain=23\n",
      "9900-th evaluation: score=0.6821, divergence=0.0725, diversity=1.2192, num_succ=0, num_remain=23\n",
      "[0.20876688 0.03474036 0.02228077 0.09027521 0.00771301 0.00261104\n",
      " 0.21050564 0.12833738 0.06919639 0.06560325 0.0028244  0.06409291\n",
      " 0.00435872 0.05843693 0.01193502 0.05731376 0.06545375 0.1981567\n",
      " 0.15550124 0.28907971 0.14577737 0.09993702 0.13253638 0.00290491\n",
      " 0.19901564 0.12792208 0.18860388 0.07851837 0.03304439 0.01195873\n",
      " 0.02294986 0.10826735 0.16392328 0.08020723 0.0079236  0.06447089\n",
      " 0.08787123 0.00954991 0.17510635 0.0454697  0.01041466 0.03379593\n",
      " 0.04904646 0.04966351 0.0322972  0.03720806 0.09462025 0.09254939\n",
      " 0.09066633 0.10860718 0.00540883 0.01124748 0.07636244 0.03069058\n",
      " 0.02423524 0.12063675 0.00679815 0.01625075 0.1105201  0.12156287\n",
      " 0.07537363 0.12326292 0.08417718 0.0431707  0.04453811 0.13581706\n",
      " 0.00118212 0.01862024 0.08595292 0.06510204 0.0464292  0.01886511\n",
      " 0.02724057 0.07979635 0.04943537 0.1404391  0.00458707 0.15712983\n",
      " 0.04836666 0.09655874 0.28405259 0.13126966 0.05873895 0.00302628\n",
      " 0.11484758 0.00298142 0.00667713 0.00584715 0.01570247 0.05657798\n",
      " 0.11744577 0.09797087 0.0914715  0.07005665 0.12961294 0.1646959\n",
      " 0.1568625  0.0958947  0.12634719 0.0444059 ]\n",
      "7\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "initial_evaluation: score=0.6717, divergence=0.0000, diversity=1.3434, num_succ=0, num_remain=7\n",
      "   0-th evaluation: score=0.6717, divergence=0.0000, diversity=1.3434, num_succ=0, num_remain=87\n",
      " 100-th evaluation: score=0.6768, divergence=0.0081, diversity=1.3374, num_succ=1, num_remain=34\n",
      " 200-th evaluation: score=0.6783, divergence=0.0111, diversity=1.3345, num_succ=1, num_remain=34\n",
      " 300-th evaluation: score=0.6793, divergence=0.0134, diversity=1.3318, num_succ=1, num_remain=25\n",
      " 400-th evaluation: score=0.6807, divergence=0.0161, diversity=1.3291, num_succ=1, num_remain=44\n",
      " 500-th evaluation: score=0.6814, divergence=0.0175, diversity=1.3277, num_succ=1, num_remain=23\n",
      " 600-th evaluation: score=0.6820, divergence=0.0191, diversity=1.3258, num_succ=1, num_remain=28\n",
      " 700-th evaluation: score=0.6829, divergence=0.0212, diversity=1.3234, num_succ=1, num_remain=29\n",
      " 800-th evaluation: score=0.6832, divergence=0.0217, diversity=1.3230, num_succ=1, num_remain=24\n",
      " 900-th evaluation: score=0.6833, divergence=0.0220, diversity=1.3227, num_succ=1, num_remain=24\n",
      "1000-th evaluation: score=0.6836, divergence=0.0224, diversity=1.3224, num_succ=1, num_remain=24\n",
      "1100-th evaluation: score=0.6837, divergence=0.0226, diversity=1.3223, num_succ=1, num_remain=25\n",
      "1200-th evaluation: score=0.6838, divergence=0.0228, diversity=1.3221, num_succ=1, num_remain=24\n",
      "1300-th evaluation: score=0.6839, divergence=0.0229, diversity=1.3220, num_succ=1, num_remain=25\n",
      "1400-th evaluation: score=0.6841, divergence=0.0234, diversity=1.3214, num_succ=1, num_remain=27\n",
      "1500-th evaluation: score=0.6843, divergence=0.0238, diversity=1.3210, num_succ=1, num_remain=26\n",
      "1600-th evaluation: score=0.6846, divergence=0.0249, diversity=1.3193, num_succ=1, num_remain=26\n",
      "1700-th evaluation: score=0.6851, divergence=0.0262, diversity=1.3178, num_succ=1, num_remain=26\n",
      "1800-th evaluation: score=0.6853, divergence=0.0267, diversity=1.3172, num_succ=1, num_remain=24\n",
      "1900-th evaluation: score=0.6856, divergence=0.0272, diversity=1.3168, num_succ=1, num_remain=24\n",
      "2000-th evaluation: score=0.6858, divergence=0.0275, diversity=1.3165, num_succ=1, num_remain=22\n",
      "2100-th evaluation: score=0.6862, divergence=0.0287, diversity=1.3150, num_succ=1, num_remain=21\n",
      "2200-th evaluation: score=0.6866, divergence=0.0300, diversity=1.3132, num_succ=1, num_remain=25\n",
      "2300-th evaluation: score=0.6870, divergence=0.0311, diversity=1.3119, num_succ=1, num_remain=21\n",
      "2400-th evaluation: score=0.6875, divergence=0.0323, diversity=1.3105, num_succ=1, num_remain=21\n",
      "2500-th evaluation: score=0.6879, divergence=0.0332, diversity=1.3093, num_succ=1, num_remain=22\n",
      "2600-th evaluation: score=0.6889, divergence=0.0358, diversity=1.3062, num_succ=1, num_remain=20\n",
      "2700-th evaluation: score=0.6896, divergence=0.0378, diversity=1.3036, num_succ=1, num_remain=20\n",
      "2800-th evaluation: score=0.6902, divergence=0.0394, diversity=1.3015, num_succ=1, num_remain=23\n",
      "2900-th evaluation: score=0.6907, divergence=0.0410, diversity=1.2995, num_succ=1, num_remain=21\n",
      "3000-th evaluation: score=0.6914, divergence=0.0425, diversity=1.2978, num_succ=1, num_remain=19\n",
      "3100-th evaluation: score=0.6919, divergence=0.0432, diversity=1.2973, num_succ=1, num_remain=20\n",
      "3200-th evaluation: score=0.6923, divergence=0.0439, diversity=1.2967, num_succ=1, num_remain=18\n",
      "3300-th evaluation: score=0.6930, divergence=0.0462, diversity=1.2936, num_succ=1, num_remain=19\n",
      "3400-th evaluation: score=0.6935, divergence=0.0479, diversity=1.2912, num_succ=1, num_remain=20\n",
      "3500-th evaluation: score=0.6942, divergence=0.0496, diversity=1.2892, num_succ=1, num_remain=22\n",
      "3600-th evaluation: score=0.6948, divergence=0.0513, diversity=1.2870, num_succ=1, num_remain=20\n",
      "3700-th evaluation: score=0.6953, divergence=0.0524, diversity=1.2857, num_succ=1, num_remain=19\n",
      "3800-th evaluation: score=0.6959, divergence=0.0546, diversity=1.2825, num_succ=1, num_remain=18\n",
      "3900-th evaluation: score=0.6966, divergence=0.0562, diversity=1.2808, num_succ=1, num_remain=19\n",
      "4000-th evaluation: score=0.6973, divergence=0.0580, diversity=1.2786, num_succ=1, num_remain=18\n",
      "4100-th evaluation: score=0.6981, divergence=0.0602, diversity=1.2758, num_succ=1, num_remain=17\n",
      "4200-th evaluation: score=0.6989, divergence=0.0621, diversity=1.2737, num_succ=2, num_remain=14\n",
      "4300-th evaluation: score=0.7000, divergence=0.0649, diversity=1.2702, num_succ=2, num_remain=19\n",
      "4400-th evaluation: score=0.7007, divergence=0.0668, diversity=1.2679, num_succ=2, num_remain=18\n",
      "4500-th evaluation: score=0.7019, divergence=0.0699, diversity=1.2639, num_succ=2, num_remain=22\n",
      "4600-th evaluation: score=0.7028, divergence=0.0727, diversity=1.2602, num_succ=2, num_remain=19\n",
      "4700-th evaluation: score=0.7033, divergence=0.0736, diversity=1.2594, num_succ=2, num_remain=20\n",
      "4800-th evaluation: score=0.7038, divergence=0.0746, diversity=1.2583, num_succ=2, num_remain=18\n",
      "4900-th evaluation: score=0.7046, divergence=0.0771, diversity=1.2550, num_succ=2, num_remain=27\n",
      "5000-th evaluation: score=0.7054, divergence=0.0796, diversity=1.2516, num_succ=2, num_remain=17\n",
      "5100-th evaluation: score=0.7059, divergence=0.0803, diversity=1.2513, num_succ=2, num_remain=16\n",
      "5200-th evaluation: score=0.7067, divergence=0.0825, diversity=1.2484, num_succ=2, num_remain=19\n",
      "5300-th evaluation: score=0.7072, divergence=0.0842, diversity=1.2459, num_succ=2, num_remain=20\n",
      "5400-th evaluation: score=0.7074, divergence=0.0846, diversity=1.2456, num_succ=2, num_remain=17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500-th evaluation: score=0.7079, divergence=0.0862, diversity=1.2435, num_succ=2, num_remain=18\n",
      "5600-th evaluation: score=0.7083, divergence=0.0873, diversity=1.2421, num_succ=2, num_remain=17\n",
      "5700-th evaluation: score=0.7085, divergence=0.0876, diversity=1.2418, num_succ=2, num_remain=16\n",
      "5800-th evaluation: score=0.7089, divergence=0.0891, diversity=1.2395, num_succ=2, num_remain=19\n",
      "5900-th evaluation: score=0.7091, divergence=0.0897, diversity=1.2388, num_succ=2, num_remain=17\n",
      "6000-th evaluation: score=0.7099, divergence=0.0922, diversity=1.2354, num_succ=2, num_remain=21\n",
      "6100-th evaluation: score=0.7103, divergence=0.0932, diversity=1.2342, num_succ=2, num_remain=17\n",
      "6200-th evaluation: score=0.7107, divergence=0.0943, diversity=1.2329, num_succ=2, num_remain=18\n",
      "6300-th evaluation: score=0.7121, divergence=0.0986, diversity=1.2270, num_succ=2, num_remain=17\n",
      "6400-th evaluation: score=0.7129, divergence=0.1013, diversity=1.2233, num_succ=2, num_remain=18\n",
      "6500-th evaluation: score=0.7140, divergence=0.1047, diversity=1.2185, num_succ=2, num_remain=22\n",
      "6600-th evaluation: score=0.7147, divergence=0.1070, diversity=1.2155, num_succ=2, num_remain=15\n",
      "6700-th evaluation: score=0.7163, divergence=0.1113, diversity=1.2099, num_succ=2, num_remain=19\n",
      "6800-th evaluation: score=0.7178, divergence=0.1156, diversity=1.2044, num_succ=2, num_remain=23\n",
      "6900-th evaluation: score=0.7188, divergence=0.1181, diversity=1.2013, num_succ=2, num_remain=17\n",
      "7000-th evaluation: score=0.7197, divergence=0.1208, diversity=1.1977, num_succ=2, num_remain=18\n",
      "7100-th evaluation: score=0.7222, divergence=0.1281, diversity=1.1881, num_succ=2, num_remain=21\n",
      "7200-th evaluation: score=0.7245, divergence=0.1348, diversity=1.1794, num_succ=2, num_remain=19\n",
      "7300-th evaluation: score=0.7263, divergence=0.1391, diversity=1.1745, num_succ=2, num_remain=15\n",
      "7400-th evaluation: score=0.7283, divergence=0.1448, diversity=1.1671, num_succ=2, num_remain=20\n",
      "7500-th evaluation: score=0.7302, divergence=0.1496, diversity=1.1610, num_succ=2, num_remain=20\n",
      "7600-th evaluation: score=0.7320, divergence=0.1550, diversity=1.1539, num_succ=2, num_remain=22\n",
      "7700-th evaluation: score=0.7355, divergence=0.1648, diversity=1.1413, num_succ=2, num_remain=23\n",
      "7800-th evaluation: score=0.7375, divergence=0.1708, diversity=1.1334, num_succ=2, num_remain=21\n",
      "7900-th evaluation: score=0.7407, divergence=0.1795, diversity=1.1225, num_succ=2, num_remain=24\n",
      "8000-th evaluation: score=0.7432, divergence=0.1868, diversity=1.1128, num_succ=2, num_remain=18\n",
      "8100-th evaluation: score=0.7467, divergence=0.1959, diversity=1.1015, num_succ=2, num_remain=22\n",
      "8200-th evaluation: score=0.7500, divergence=0.2053, diversity=1.0894, num_succ=2, num_remain=20\n",
      "8300-th evaluation: score=0.7540, divergence=0.2153, diversity=1.0774, num_succ=2, num_remain=19\n",
      "8400-th evaluation: score=0.7600, divergence=0.2306, diversity=1.0589, num_succ=2, num_remain=21\n",
      "8500-th evaluation: score=0.7650, divergence=0.2432, diversity=1.0437, num_succ=2, num_remain=22\n",
      "8600-th evaluation: score=0.7710, divergence=0.2572, diversity=1.0276, num_succ=2, num_remain=24\n",
      "8700-th evaluation: score=0.7761, divergence=0.2689, diversity=1.0146, num_succ=2, num_remain=29\n",
      "8800-th evaluation: score=0.7833, divergence=0.2857, diversity=0.9953, num_succ=2, num_remain=22\n",
      "8900-th evaluation: score=0.7923, divergence=0.3026, diversity=0.9794, num_succ=4, num_remain=23\n",
      "9000-th evaluation: score=0.7978, divergence=0.3153, diversity=0.9649, num_succ=4, num_remain=20\n",
      "9100-th evaluation: score=0.8018, divergence=0.3250, diversity=0.9536, num_succ=4, num_remain=18\n",
      "9200-th evaluation: score=0.8079, divergence=0.3383, diversity=0.9393, num_succ=4, num_remain=21\n",
      "9300-th evaluation: score=0.8145, divergence=0.3529, diversity=0.9232, num_succ=4, num_remain=21\n",
      "9400-th evaluation: score=0.8204, divergence=0.3656, diversity=0.9095, num_succ=4, num_remain=18\n",
      "9500-th evaluation: score=0.8250, divergence=0.3756, diversity=0.8988, num_succ=4, num_remain=19\n",
      "9600-th evaluation: score=0.8318, divergence=0.3895, diversity=0.8846, num_succ=4, num_remain=23\n",
      "9700-th evaluation: score=0.8355, divergence=0.3978, diversity=0.8753, num_succ=4, num_remain=16\n",
      "9800-th evaluation: score=0.8391, divergence=0.4056, diversity=0.8671, num_succ=4, num_remain=14\n",
      "9900-th evaluation: score=0.8439, divergence=0.4158, diversity=0.8562, num_succ=4, num_remain=18\n",
      "[0.05797789 0.04044198 0.04121263 0.04618078 0.06008678 0.07666366\n",
      " 0.03568307 0.03520173 0.09326813 0.08656036 0.08865704 0.06679994\n",
      " 0.11745855 0.08933157 0.10052583 0.14145052 0.1109277  0.09741666\n",
      " 0.04694751 0.06273705 0.02607479 0.09789114 0.10525056 0.06397437\n",
      " 0.20352249 0.08837237 0.05569047 0.06755838 0.04684421 0.10416256\n",
      " 0.12682386 0.07169777 0.08343365 0.26859203 0.06516715 0.04524835\n",
      " 0.00035051 0.03330867 0.07758734 0.06370139 0.12083573 0.0734425\n",
      " 0.07952    0.0846224  0.08429591 0.1130413  0.11070741 0.10393154\n",
      " 0.08020753 0.16515017 0.11333608 0.11133867 0.05680527 0.06731061\n",
      " 0.18923408 0.19224639 0.13502146 0.13035587 0.20588585 0.05362999\n",
      " 0.05559222 0.11865247 0.11581074 0.11372948 0.07101555 0.08051301\n",
      " 0.08619362 0.07590453 0.01251073 0.13448428 0.09967385 0.04749923\n",
      " 0.10249104 0.07427259 0.10391283 0.09692913 0.06351173 0.03960087\n",
      " 0.12877097 0.07031377 0.17236194 0.02976778 0.06789994 0.04582726\n",
      " 0.09618868 0.05770792 0.0503841  0.09221235 0.12109775 0.20831844\n",
      " 0.06460049 0.09602239 0.05369156 0.09419894 0.06720027 0.09585567\n",
      " 0.13120552 0.12921095 0.05985927 0.06260189]\n",
      "8\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "initial_evaluation: score=0.6803, divergence=0.0000, diversity=1.3606, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6803, divergence=0.0000, diversity=1.3606, num_succ=0, num_remain=86\n",
      " 100-th evaluation: score=0.6841, divergence=0.0053, diversity=1.3576, num_succ=0, num_remain=35\n",
      " 200-th evaluation: score=0.6851, divergence=0.0077, diversity=1.3549, num_succ=0, num_remain=36\n",
      " 300-th evaluation: score=0.6862, divergence=0.0101, diversity=1.3521, num_succ=0, num_remain=32\n",
      " 400-th evaluation: score=0.6873, divergence=0.0126, diversity=1.3494, num_succ=0, num_remain=32\n",
      " 500-th evaluation: score=0.6883, divergence=0.0150, diversity=1.3466, num_succ=0, num_remain=22\n",
      " 600-th evaluation: score=0.6894, divergence=0.0169, diversity=1.3449, num_succ=0, num_remain=22\n",
      " 700-th evaluation: score=0.6904, divergence=0.0193, diversity=1.3422, num_succ=0, num_remain=34\n",
      " 800-th evaluation: score=0.6910, divergence=0.0208, diversity=1.3404, num_succ=0, num_remain=23\n",
      " 900-th evaluation: score=0.6915, divergence=0.0220, diversity=1.3391, num_succ=0, num_remain=22\n",
      "1000-th evaluation: score=0.6927, divergence=0.0242, diversity=1.3372, num_succ=0, num_remain=35\n",
      "1100-th evaluation: score=0.6932, divergence=0.0254, diversity=1.3357, num_succ=0, num_remain=22\n",
      "1200-th evaluation: score=0.6936, divergence=0.0261, diversity=1.3348, num_succ=0, num_remain=22\n",
      "1300-th evaluation: score=0.6941, divergence=0.0277, diversity=1.3328, num_succ=0, num_remain=26\n",
      "1400-th evaluation: score=0.6946, divergence=0.0287, diversity=1.3318, num_succ=0, num_remain=20\n",
      "1500-th evaluation: score=0.6951, divergence=0.0299, diversity=1.3306, num_succ=0, num_remain=20\n",
      "1600-th evaluation: score=0.6955, divergence=0.0307, diversity=1.3296, num_succ=0, num_remain=23\n",
      "1700-th evaluation: score=0.6958, divergence=0.0315, diversity=1.3286, num_succ=0, num_remain=26\n",
      "1800-th evaluation: score=0.6961, divergence=0.0325, diversity=1.3273, num_succ=0, num_remain=20\n",
      "1900-th evaluation: score=0.6963, divergence=0.0331, diversity=1.3266, num_succ=0, num_remain=18\n",
      "2000-th evaluation: score=0.6967, divergence=0.0341, diversity=1.3253, num_succ=0, num_remain=20\n",
      "2100-th evaluation: score=0.6968, divergence=0.0343, diversity=1.3250, num_succ=0, num_remain=19\n",
      "2200-th evaluation: score=0.6970, divergence=0.0348, diversity=1.3244, num_succ=0, num_remain=22\n",
      "2300-th evaluation: score=0.6970, divergence=0.0349, diversity=1.3243, num_succ=0, num_remain=22\n",
      "2400-th evaluation: score=0.6970, divergence=0.0349, diversity=1.3242, num_succ=0, num_remain=18\n",
      "2500-th evaluation: score=0.6971, divergence=0.0350, diversity=1.3241, num_succ=0, num_remain=21\n",
      "2600-th evaluation: score=0.6971, divergence=0.0351, diversity=1.3240, num_succ=0, num_remain=18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700-th evaluation: score=0.6971, divergence=0.0353, diversity=1.3237, num_succ=0, num_remain=16\n",
      "2800-th evaluation: score=0.6972, divergence=0.0353, diversity=1.3237, num_succ=0, num_remain=16\n",
      "2900-th evaluation: score=0.6973, divergence=0.0355, diversity=1.3236, num_succ=0, num_remain=18\n",
      "3000-th evaluation: score=0.6973, divergence=0.0357, diversity=1.3234, num_succ=0, num_remain=18\n",
      "3100-th evaluation: score=0.6974, divergence=0.0357, diversity=1.3233, num_succ=0, num_remain=19\n",
      "3200-th evaluation: score=0.6974, divergence=0.0358, diversity=1.3231, num_succ=0, num_remain=20\n",
      "3300-th evaluation: score=0.6975, divergence=0.0361, diversity=1.3227, num_succ=0, num_remain=22\n",
      "3400-th evaluation: score=0.6976, divergence=0.0366, diversity=1.3220, num_succ=0, num_remain=24\n",
      "3500-th evaluation: score=0.6977, divergence=0.0369, diversity=1.3217, num_succ=0, num_remain=20\n",
      "3600-th evaluation: score=0.6979, divergence=0.0372, diversity=1.3214, num_succ=0, num_remain=17\n",
      "3700-th evaluation: score=0.6979, divergence=0.0373, diversity=1.3212, num_succ=0, num_remain=18\n",
      "3800-th evaluation: score=0.6981, divergence=0.0379, diversity=1.3204, num_succ=0, num_remain=21\n",
      "3900-th evaluation: score=0.6981, divergence=0.0381, diversity=1.3201, num_succ=0, num_remain=18\n",
      "4000-th evaluation: score=0.6982, divergence=0.0383, diversity=1.3197, num_succ=0, num_remain=19\n",
      "4100-th evaluation: score=0.6982, divergence=0.0386, diversity=1.3192, num_succ=0, num_remain=26\n",
      "4200-th evaluation: score=0.6982, divergence=0.0387, diversity=1.3191, num_succ=0, num_remain=25\n",
      "4300-th evaluation: score=0.6982, divergence=0.0387, diversity=1.3191, num_succ=0, num_remain=25\n",
      "4400-th evaluation: score=0.6983, divergence=0.0389, diversity=1.3188, num_succ=0, num_remain=27\n",
      "4500-th evaluation: score=0.6983, divergence=0.0389, diversity=1.3188, num_succ=0, num_remain=27\n",
      "4600-th evaluation: score=0.6983, divergence=0.0389, diversity=1.3188, num_succ=0, num_remain=27\n",
      "4700-th evaluation: score=0.6983, divergence=0.0390, diversity=1.3187, num_succ=0, num_remain=30\n",
      "4800-th evaluation: score=0.6983, divergence=0.0390, diversity=1.3186, num_succ=0, num_remain=24\n",
      "4900-th evaluation: score=0.6983, divergence=0.0390, diversity=1.3186, num_succ=0, num_remain=24\n",
      "5000-th evaluation: score=0.6983, divergence=0.0390, diversity=1.3186, num_succ=0, num_remain=24\n",
      "5100-th evaluation: score=0.6983, divergence=0.0390, diversity=1.3186, num_succ=0, num_remain=24\n",
      "5200-th evaluation: score=0.6983, divergence=0.0390, diversity=1.3186, num_succ=0, num_remain=24\n",
      "5300-th evaluation: score=0.6984, divergence=0.0391, diversity=1.3185, num_succ=0, num_remain=19\n",
      "5400-th evaluation: score=0.6984, divergence=0.0391, diversity=1.3185, num_succ=0, num_remain=19\n",
      "5500-th evaluation: score=0.6984, divergence=0.0391, diversity=1.3185, num_succ=0, num_remain=19\n",
      "5600-th evaluation: score=0.6984, divergence=0.0391, diversity=1.3185, num_succ=0, num_remain=19\n",
      "5700-th evaluation: score=0.6984, divergence=0.0391, diversity=1.3185, num_succ=0, num_remain=19\n",
      "5800-th evaluation: score=0.6984, divergence=0.0391, diversity=1.3185, num_succ=0, num_remain=19\n",
      "5900-th evaluation: score=0.6984, divergence=0.0392, diversity=1.3185, num_succ=0, num_remain=20\n",
      "6000-th evaluation: score=0.6984, divergence=0.0392, diversity=1.3185, num_succ=0, num_remain=20\n",
      "6100-th evaluation: score=0.6984, divergence=0.0392, diversity=1.3185, num_succ=0, num_remain=20\n",
      "6200-th evaluation: score=0.6984, divergence=0.0392, diversity=1.3184, num_succ=0, num_remain=23\n",
      "6300-th evaluation: score=0.6984, divergence=0.0392, diversity=1.3184, num_succ=0, num_remain=23\n",
      "6400-th evaluation: score=0.6984, divergence=0.0393, diversity=1.3183, num_succ=0, num_remain=23\n",
      "6500-th evaluation: score=0.6985, divergence=0.0395, diversity=1.3180, num_succ=0, num_remain=21\n",
      "6600-th evaluation: score=0.6985, divergence=0.0396, diversity=1.3178, num_succ=0, num_remain=23\n",
      "6700-th evaluation: score=0.6985, divergence=0.0396, diversity=1.3177, num_succ=0, num_remain=22\n",
      "6800-th evaluation: score=0.6985, divergence=0.0396, diversity=1.3177, num_succ=0, num_remain=22\n",
      "6900-th evaluation: score=0.6985, divergence=0.0396, diversity=1.3177, num_succ=0, num_remain=24\n",
      "7000-th evaluation: score=0.6985, divergence=0.0396, diversity=1.3177, num_succ=0, num_remain=24\n",
      "7100-th evaluation: score=0.6985, divergence=0.0397, diversity=1.3176, num_succ=0, num_remain=22\n",
      "7200-th evaluation: score=0.6985, divergence=0.0398, diversity=1.3176, num_succ=0, num_remain=24\n",
      "7300-th evaluation: score=0.6986, divergence=0.0398, diversity=1.3175, num_succ=0, num_remain=24\n",
      "7400-th evaluation: score=0.6986, divergence=0.0398, diversity=1.3175, num_succ=0, num_remain=21\n",
      "7500-th evaluation: score=0.6986, divergence=0.0398, diversity=1.3175, num_succ=0, num_remain=21\n",
      "7600-th evaluation: score=0.6986, divergence=0.0399, diversity=1.3175, num_succ=0, num_remain=23\n",
      "7700-th evaluation: score=0.6986, divergence=0.0399, diversity=1.3175, num_succ=0, num_remain=23\n",
      "7800-th evaluation: score=0.6986, divergence=0.0399, diversity=1.3175, num_succ=0, num_remain=23\n",
      "7900-th evaluation: score=0.6986, divergence=0.0399, diversity=1.3175, num_succ=0, num_remain=23\n",
      "8000-th evaluation: score=0.6986, divergence=0.0399, diversity=1.3174, num_succ=0, num_remain=20\n",
      "8100-th evaluation: score=0.6986, divergence=0.0399, diversity=1.3174, num_succ=0, num_remain=20\n",
      "8200-th evaluation: score=0.6986, divergence=0.0399, diversity=1.3174, num_succ=0, num_remain=20\n",
      "8300-th evaluation: score=0.6986, divergence=0.0400, diversity=1.3173, num_succ=0, num_remain=18\n",
      "8400-th evaluation: score=0.6986, divergence=0.0400, diversity=1.3173, num_succ=0, num_remain=18\n",
      "8500-th evaluation: score=0.6986, divergence=0.0400, diversity=1.3173, num_succ=0, num_remain=17\n",
      "8600-th evaluation: score=0.6986, divergence=0.0400, diversity=1.3173, num_succ=0, num_remain=17\n",
      "8700-th evaluation: score=0.6986, divergence=0.0400, diversity=1.3173, num_succ=0, num_remain=17\n",
      "8800-th evaluation: score=0.6986, divergence=0.0400, diversity=1.3173, num_succ=0, num_remain=17\n",
      "8900-th evaluation: score=0.6987, divergence=0.0400, diversity=1.3173, num_succ=0, num_remain=17\n",
      "9000-th evaluation: score=0.6987, divergence=0.0401, diversity=1.3172, num_succ=0, num_remain=18\n",
      "9100-th evaluation: score=0.6987, divergence=0.0401, diversity=1.3172, num_succ=0, num_remain=18\n",
      "9200-th evaluation: score=0.6987, divergence=0.0401, diversity=1.3172, num_succ=0, num_remain=17\n",
      "9300-th evaluation: score=0.6987, divergence=0.0401, diversity=1.3172, num_succ=0, num_remain=20\n",
      "9400-th evaluation: score=0.6987, divergence=0.0402, diversity=1.3171, num_succ=0, num_remain=22\n",
      "9500-th evaluation: score=0.6987, divergence=0.0403, diversity=1.3169, num_succ=0, num_remain=18\n",
      "9600-th evaluation: score=0.6987, divergence=0.0403, diversity=1.3169, num_succ=0, num_remain=18\n",
      "9700-th evaluation: score=0.6987, divergence=0.0403, diversity=1.3168, num_succ=0, num_remain=20\n",
      "9800-th evaluation: score=0.6987, divergence=0.0403, diversity=1.3168, num_succ=0, num_remain=20\n",
      "9900-th evaluation: score=0.6987, divergence=0.0403, diversity=1.3168, num_succ=0, num_remain=20\n",
      "[0.10240173 0.03320217 0.03843279 0.04668783 0.15210242 0.08543912\n",
      " 0.04035826 0.17099505 0.15064064 0.0234411  0.01784645 0.01089391\n",
      " 0.04621401 0.10164592 0.06131493 0.02248638 0.09071167 0.1833792\n",
      " 0.0188695  0.02364161 0.12182095 0.03933513 0.26924199 0.05764504\n",
      " 0.02529554 0.02170609 0.17583572 0.08617301 0.0475401  0.0605254\n",
      " 0.17253775 0.07186035 0.12424655 0.11281249 0.1220862  0.02205083\n",
      " 0.10104104 0.10112842 0.10061897 0.07349075 0.01859469 0.0475307\n",
      " 0.03891298 0.05750791 0.15441656 0.02527537 0.05960655 0.06427214\n",
      " 0.04587876 0.07364646 0.15023084 0.21245345 0.15512405 0.113737\n",
      " 0.14727068 0.00077781 0.12910643 0.01897084 0.12456513 0.14679646\n",
      " 0.1802894  0.07369812 0.0555397  0.11911734 0.08505476 0.17082746\n",
      " 0.2336033  0.01408855 0.06987412 0.11146169 0.08101064 0.1212289\n",
      " 0.03034246 0.05355395 0.09913821 0.10450778 0.10698186 0.01466042\n",
      " 0.12752665 0.08586805 0.08941716 0.07980956 0.10719489 0.03968091\n",
      " 0.05728372 0.03770616 0.08934755 0.08880741 0.0107394  0.06098653\n",
      " 0.08670646 0.17253624 0.00202625 0.01138406 0.01318429 0.12563634\n",
      " 0.028262   0.02335037 0.01726947 0.09472718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "initial_evaluation: score=0.4123, divergence=0.0000, diversity=0.8246, num_succ=0, num_remain=8\n",
      "   0-th evaluation: score=0.4128, divergence=0.0005, diversity=0.8247, num_succ=0, num_remain=87\n",
      " 100-th evaluation: score=0.4452, divergence=0.0325, diversity=0.8254, num_succ=10, num_remain=22\n",
      " 200-th evaluation: score=0.4538, divergence=0.0405, diversity=0.8266, num_succ=13, num_remain=13\n",
      " 300-th evaluation: score=0.4589, divergence=0.0448, diversity=0.8282, num_succ=13, num_remain=8\n",
      " 400-th evaluation: score=0.4601, divergence=0.0461, diversity=0.8281, num_succ=15, num_remain=4\n",
      " 500-th evaluation: score=0.4602, divergence=0.0462, diversity=0.8282, num_succ=15, num_remain=5\n",
      " 600-th evaluation: score=0.4604, divergence=0.0464, diversity=0.8280, num_succ=15, num_remain=4\n",
      " 700-th evaluation: score=0.4620, divergence=0.0483, diversity=0.8275, num_succ=15, num_remain=5\n",
      " 800-th evaluation: score=0.4622, divergence=0.0485, diversity=0.8273, num_succ=15, num_remain=3\n",
      " 900-th evaluation: score=0.4622, divergence=0.0486, diversity=0.8273, num_succ=15, num_remain=3\n",
      "1000-th evaluation: score=0.4622, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "1100-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "1200-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "1300-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "1400-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "1500-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "1600-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "1700-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "1800-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "1900-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "2000-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "2100-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "2200-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "2300-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "2400-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "2500-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "2600-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "2700-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "2800-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "2900-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "3000-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "3100-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "3200-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "3300-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "3400-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "3500-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "3600-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "3700-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "3800-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "3900-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "4000-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "4100-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "4200-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "4300-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "4400-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "4500-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "4600-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "4700-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "4800-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "4900-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "5000-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "5100-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "5200-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "5300-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "5400-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "5500-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "5600-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "5700-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "5800-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "5900-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "6000-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "6100-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "6200-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "6300-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "6400-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "6500-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "6600-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "6700-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "6800-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "6900-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "7000-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "7100-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "7200-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "7300-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "7400-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "7500-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "7600-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "7700-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "7800-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "7900-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "8000-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "8100-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "8200-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8300-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "8400-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "8500-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "8600-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "8700-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "8800-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "8900-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "9000-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "9100-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "9200-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "9300-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "9400-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "9500-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "9600-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "9700-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "9800-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "9900-th evaluation: score=0.4623, divergence=0.0486, diversity=0.8274, num_succ=15, num_remain=3\n",
      "[2.43264176e-01 7.46763330e-03 6.98164219e-04 4.19722853e-03\n",
      " 1.14878120e-02 1.62362605e-02 2.87259453e-01 6.63936969e-04\n",
      " 2.66024580e-02 3.16490420e-01 1.85052584e-01 7.23969057e-04\n",
      " 1.16202230e-01 9.03891495e-02 1.62522093e-02 5.77437003e-03\n",
      " 1.75517696e-02 1.23068109e-01 1.13810086e-02 3.29805537e-02\n",
      " 2.36598105e-03 1.99641635e-02 3.77349159e-02 6.46436272e-02\n",
      " 2.92078506e-03 1.38471626e-02 4.23683178e-03 3.04210364e-03\n",
      " 4.36549757e-03 3.45507064e-02 5.61350195e-02 2.73638799e-03\n",
      " 1.90902039e-03 1.24325557e-02 8.56039650e-04 5.19560694e-02\n",
      " 8.60322536e-03 6.04797299e-02 1.34169745e-01 5.70537793e-03\n",
      " 2.51364207e-03 3.69833500e-03 1.69935608e-03 1.53766368e-02\n",
      " 2.01387046e-02 5.18924533e-02 9.15892537e-03 1.55115746e-03\n",
      " 4.21927016e-03 4.10727000e-03 3.38376686e-02 3.91194171e-03\n",
      " 3.17094863e-03 1.26418617e-02 1.79451142e-03 1.20386736e-03\n",
      " 1.12505508e-02 6.21876876e-02 3.09163459e-02 3.35570410e-03\n",
      " 1.30482878e-02 1.03291031e-03 6.12936575e-03 9.73311885e-02\n",
      " 6.08205688e-03 2.34716503e-03 7.52641099e-04 1.15456220e-01\n",
      " 5.33282058e-03 2.20434242e-03 6.82266468e-01 6.95099895e-03\n",
      " 9.77501587e-03 1.49363418e-03 7.44577087e-03 3.74421027e-03\n",
      " 3.70834871e-01 3.41734899e-04 5.93511266e-04 1.88110099e-02\n",
      " 6.18857351e-02 8.14769829e-03 4.24901740e-03 8.84120331e-03\n",
      " 1.46557142e-02 1.29077948e-03 1.60814315e-03 1.65417969e-02\n",
      " 8.01025169e-05 3.91923516e-02 2.54249331e-03 1.19006894e-03\n",
      " 2.96558513e-03 1.98251041e-02 1.71388922e-02 1.78359812e-02\n",
      " 1.06588316e-03 1.23820213e-02 1.48646617e-03 7.21488925e-02]\n",
      "10\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "initial_evaluation: score=0.5361, divergence=0.0000, diversity=1.0722, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.5370, divergence=0.0008, diversity=1.0724, num_succ=0, num_remain=88\n",
      " 100-th evaluation: score=0.5713, divergence=0.0358, diversity=1.0710, num_succ=4, num_remain=38\n",
      " 200-th evaluation: score=0.5816, divergence=0.0462, diversity=1.0707, num_succ=5, num_remain=25\n",
      " 300-th evaluation: score=0.5858, divergence=0.0518, diversity=1.0679, num_succ=5, num_remain=22\n",
      " 400-th evaluation: score=0.5912, divergence=0.0570, diversity=1.0684, num_succ=5, num_remain=21\n",
      " 500-th evaluation: score=0.5951, divergence=0.0609, diversity=1.0684, num_succ=5, num_remain=22\n",
      " 600-th evaluation: score=0.5974, divergence=0.0630, diversity=1.0688, num_succ=5, num_remain=22\n",
      " 700-th evaluation: score=0.6015, divergence=0.0679, diversity=1.0671, num_succ=5, num_remain=22\n",
      " 800-th evaluation: score=0.6045, divergence=0.0718, diversity=1.0655, num_succ=5, num_remain=21\n",
      " 900-th evaluation: score=0.6070, divergence=0.0749, diversity=1.0641, num_succ=5, num_remain=21\n",
      "1000-th evaluation: score=0.6088, divergence=0.0773, diversity=1.0629, num_succ=5, num_remain=19\n",
      "1100-th evaluation: score=0.6122, divergence=0.0807, diversity=1.0631, num_succ=6, num_remain=20\n",
      "1200-th evaluation: score=0.6139, divergence=0.0822, diversity=1.0633, num_succ=6, num_remain=18\n",
      "1300-th evaluation: score=0.6155, divergence=0.0834, diversity=1.0642, num_succ=6, num_remain=20\n",
      "1400-th evaluation: score=0.6168, divergence=0.0850, diversity=1.0635, num_succ=6, num_remain=18\n",
      "1500-th evaluation: score=0.6182, divergence=0.0864, diversity=1.0636, num_succ=6, num_remain=19\n",
      "1600-th evaluation: score=0.6227, divergence=0.0922, diversity=1.0610, num_succ=6, num_remain=23\n",
      "1700-th evaluation: score=0.6256, divergence=0.0960, diversity=1.0592, num_succ=6, num_remain=22\n",
      "1800-th evaluation: score=0.6294, divergence=0.1008, diversity=1.0573, num_succ=6, num_remain=21\n",
      "1900-th evaluation: score=0.6330, divergence=0.1060, diversity=1.0541, num_succ=7, num_remain=23\n",
      "2000-th evaluation: score=0.6359, divergence=0.1104, diversity=1.0512, num_succ=7, num_remain=22\n",
      "2100-th evaluation: score=0.6388, divergence=0.1134, diversity=1.0508, num_succ=7, num_remain=22\n",
      "2200-th evaluation: score=0.6443, divergence=0.1199, diversity=1.0488, num_succ=7, num_remain=23\n",
      "2300-th evaluation: score=0.6472, divergence=0.1234, diversity=1.0475, num_succ=7, num_remain=20\n",
      "2400-th evaluation: score=0.6511, divergence=0.1290, diversity=1.0442, num_succ=7, num_remain=19\n",
      "2500-th evaluation: score=0.6543, divergence=0.1334, diversity=1.0419, num_succ=8, num_remain=21\n",
      "2600-th evaluation: score=0.6572, divergence=0.1359, diversity=1.0424, num_succ=8, num_remain=22\n",
      "2700-th evaluation: score=0.6601, divergence=0.1393, diversity=1.0417, num_succ=9, num_remain=20\n",
      "2800-th evaluation: score=0.6638, divergence=0.1447, diversity=1.0382, num_succ=10, num_remain=22\n",
      "2900-th evaluation: score=0.6673, divergence=0.1494, diversity=1.0358, num_succ=10, num_remain=19\n",
      "3000-th evaluation: score=0.6691, divergence=0.1518, diversity=1.0346, num_succ=11, num_remain=21\n",
      "3100-th evaluation: score=0.6704, divergence=0.1526, diversity=1.0356, num_succ=11, num_remain=18\n",
      "3200-th evaluation: score=0.6711, divergence=0.1534, diversity=1.0355, num_succ=11, num_remain=18\n",
      "3300-th evaluation: score=0.6717, divergence=0.1537, diversity=1.0360, num_succ=11, num_remain=18\n",
      "3400-th evaluation: score=0.6735, divergence=0.1556, diversity=1.0357, num_succ=11, num_remain=20\n",
      "3500-th evaluation: score=0.6751, divergence=0.1584, diversity=1.0334, num_succ=11, num_remain=22\n",
      "3600-th evaluation: score=0.6770, divergence=0.1611, diversity=1.0318, num_succ=11, num_remain=24\n",
      "3700-th evaluation: score=0.6780, divergence=0.1629, diversity=1.0300, num_succ=11, num_remain=23\n",
      "3800-th evaluation: score=0.6838, divergence=0.1695, diversity=1.0285, num_succ=11, num_remain=25\n",
      "3900-th evaluation: score=0.6860, divergence=0.1709, diversity=1.0302, num_succ=11, num_remain=24\n",
      "4000-th evaluation: score=0.6879, divergence=0.1727, diversity=1.0304, num_succ=11, num_remain=24\n",
      "4100-th evaluation: score=0.6888, divergence=0.1733, diversity=1.0310, num_succ=11, num_remain=21\n",
      "4200-th evaluation: score=0.6896, divergence=0.1738, diversity=1.0315, num_succ=12, num_remain=21\n",
      "4300-th evaluation: score=0.6907, divergence=0.1749, diversity=1.0315, num_succ=12, num_remain=22\n",
      "4400-th evaluation: score=0.6916, divergence=0.1757, diversity=1.0317, num_succ=12, num_remain=22\n",
      "4500-th evaluation: score=0.6921, divergence=0.1761, diversity=1.0320, num_succ=12, num_remain=22\n",
      "4600-th evaluation: score=0.6928, divergence=0.1765, diversity=1.0324, num_succ=12, num_remain=21\n",
      "4700-th evaluation: score=0.6939, divergence=0.1779, diversity=1.0319, num_succ=12, num_remain=19\n",
      "4800-th evaluation: score=0.6945, divergence=0.1788, diversity=1.0314, num_succ=12, num_remain=19\n",
      "4900-th evaluation: score=0.6952, divergence=0.1793, diversity=1.0319, num_succ=12, num_remain=18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000-th evaluation: score=0.6962, divergence=0.1803, diversity=1.0319, num_succ=12, num_remain=20\n",
      "5100-th evaluation: score=0.6981, divergence=0.1815, diversity=1.0332, num_succ=12, num_remain=21\n",
      "5200-th evaluation: score=0.6996, divergence=0.1832, diversity=1.0329, num_succ=13, num_remain=19\n",
      "5300-th evaluation: score=0.7006, divergence=0.1842, diversity=1.0327, num_succ=13, num_remain=20\n",
      "5400-th evaluation: score=0.7014, divergence=0.1847, diversity=1.0334, num_succ=13, num_remain=19\n",
      "5500-th evaluation: score=0.7018, divergence=0.1850, diversity=1.0337, num_succ=13, num_remain=19\n",
      "5600-th evaluation: score=0.7025, divergence=0.1857, diversity=1.0337, num_succ=13, num_remain=20\n",
      "5700-th evaluation: score=0.7028, divergence=0.1858, diversity=1.0341, num_succ=13, num_remain=19\n",
      "5800-th evaluation: score=0.7033, divergence=0.1862, diversity=1.0343, num_succ=13, num_remain=19\n",
      "5900-th evaluation: score=0.7036, divergence=0.1864, diversity=1.0346, num_succ=13, num_remain=19\n",
      "6000-th evaluation: score=0.7040, divergence=0.1866, diversity=1.0348, num_succ=13, num_remain=19\n",
      "6100-th evaluation: score=0.7047, divergence=0.1872, diversity=1.0350, num_succ=13, num_remain=19\n",
      "6200-th evaluation: score=0.7050, divergence=0.1875, diversity=1.0349, num_succ=13, num_remain=19\n",
      "6300-th evaluation: score=0.7052, divergence=0.1877, diversity=1.0349, num_succ=13, num_remain=19\n",
      "6400-th evaluation: score=0.7054, divergence=0.1879, diversity=1.0350, num_succ=13, num_remain=19\n",
      "6500-th evaluation: score=0.7056, divergence=0.1880, diversity=1.0352, num_succ=13, num_remain=19\n",
      "6600-th evaluation: score=0.7059, divergence=0.1882, diversity=1.0354, num_succ=13, num_remain=19\n",
      "6700-th evaluation: score=0.7061, divergence=0.1884, diversity=1.0353, num_succ=13, num_remain=20\n",
      "6800-th evaluation: score=0.7065, divergence=0.1888, diversity=1.0354, num_succ=13, num_remain=19\n",
      "6900-th evaluation: score=0.7068, divergence=0.1890, diversity=1.0355, num_succ=13, num_remain=19\n",
      "7000-th evaluation: score=0.7071, divergence=0.1892, diversity=1.0356, num_succ=13, num_remain=20\n",
      "7100-th evaluation: score=0.7075, divergence=0.1897, diversity=1.0356, num_succ=13, num_remain=19\n",
      "7200-th evaluation: score=0.7077, divergence=0.1900, diversity=1.0355, num_succ=13, num_remain=19\n",
      "7300-th evaluation: score=0.7082, divergence=0.1908, diversity=1.0349, num_succ=13, num_remain=20\n",
      "7400-th evaluation: score=0.7086, divergence=0.1912, diversity=1.0349, num_succ=13, num_remain=19\n",
      "7500-th evaluation: score=0.7094, divergence=0.1922, diversity=1.0343, num_succ=13, num_remain=18\n",
      "7600-th evaluation: score=0.7097, divergence=0.1925, diversity=1.0344, num_succ=13, num_remain=18\n",
      "7700-th evaluation: score=0.7100, divergence=0.1929, diversity=1.0342, num_succ=13, num_remain=18\n",
      "7800-th evaluation: score=0.7106, divergence=0.1936, diversity=1.0339, num_succ=13, num_remain=18\n",
      "7900-th evaluation: score=0.7109, divergence=0.1940, diversity=1.0338, num_succ=13, num_remain=18\n",
      "8000-th evaluation: score=0.7116, divergence=0.1952, diversity=1.0328, num_succ=13, num_remain=18\n",
      "8100-th evaluation: score=0.7118, divergence=0.1954, diversity=1.0327, num_succ=13, num_remain=17\n",
      "8200-th evaluation: score=0.7120, divergence=0.1956, diversity=1.0328, num_succ=13, num_remain=17\n",
      "8300-th evaluation: score=0.7121, divergence=0.1957, diversity=1.0330, num_succ=13, num_remain=17\n",
      "8400-th evaluation: score=0.7122, divergence=0.1957, diversity=1.0331, num_succ=13, num_remain=17\n",
      "8500-th evaluation: score=0.7125, divergence=0.1959, diversity=1.0333, num_succ=13, num_remain=17\n",
      "8600-th evaluation: score=0.7127, divergence=0.1960, diversity=1.0335, num_succ=13, num_remain=17\n",
      "8700-th evaluation: score=0.7127, divergence=0.1960, diversity=1.0335, num_succ=13, num_remain=17\n",
      "8800-th evaluation: score=0.7128, divergence=0.1960, diversity=1.0336, num_succ=13, num_remain=17\n",
      "8900-th evaluation: score=0.7130, divergence=0.1962, diversity=1.0336, num_succ=13, num_remain=17\n",
      "9000-th evaluation: score=0.7131, divergence=0.1963, diversity=1.0336, num_succ=13, num_remain=17\n",
      "9100-th evaluation: score=0.7132, divergence=0.1963, diversity=1.0337, num_succ=13, num_remain=17\n",
      "9200-th evaluation: score=0.7133, divergence=0.1964, diversity=1.0338, num_succ=13, num_remain=17\n",
      "9300-th evaluation: score=0.7133, divergence=0.1964, diversity=1.0338, num_succ=13, num_remain=17\n",
      "9400-th evaluation: score=0.7134, divergence=0.1965, diversity=1.0339, num_succ=13, num_remain=17\n",
      "9500-th evaluation: score=0.7135, divergence=0.1965, diversity=1.0340, num_succ=13, num_remain=17\n",
      "9600-th evaluation: score=0.7136, divergence=0.1967, diversity=1.0340, num_succ=13, num_remain=17\n",
      "9700-th evaluation: score=0.7137, divergence=0.1967, diversity=1.0340, num_succ=13, num_remain=17\n",
      "9800-th evaluation: score=0.7138, divergence=0.1968, diversity=1.0341, num_succ=13, num_remain=17\n",
      "9900-th evaluation: score=0.7139, divergence=0.1969, diversity=1.0341, num_succ=13, num_remain=17\n",
      "[0.01214822 0.20925982 0.17754769 0.00875979 0.02159598 0.01926125\n",
      " 0.08096617 0.02904793 0.15897147 0.04324084 0.02489281 0.12052666\n",
      " 0.02514111 0.0127985  0.0067822  0.03297283 0.00043513 0.01030924\n",
      " 0.07929743 0.09615036 0.00104296 0.04924417 0.04824128 0.00512074\n",
      " 0.05723705 0.04039702 0.00883806 0.01825995 0.03429661 0.01771793\n",
      " 0.00064495 0.01854545 0.01628575 0.00422042 0.11680667 0.02616115\n",
      " 0.24668682 0.013735   0.07946962 0.42061803 0.01055178 0.0430525\n",
      " 0.00643125 0.00448862 0.04185032 0.05625954 0.11808273 0.00863408\n",
      " 0.02101129 0.0660643  0.01334651 0.2154432  0.01519861 0.07695686\n",
      " 0.02532318 0.14173948 0.03333271 0.02115206 0.00488361 0.16646348\n",
      " 0.11005258 0.01122815 0.06846282 0.09754117 0.06621552 0.15745849\n",
      " 0.14760284 0.02509873 0.24446539 0.01594908 0.01142521 0.0580397\n",
      " 0.23255489 0.02529053 0.06055809 0.04620091 0.02639404 0.31713617\n",
      " 0.14731727 0.00349662 0.02903193 0.15711079 0.02174713 0.04498201\n",
      " 0.02845185 0.02048859 0.06450246 0.08274259 0.01975124 0.15913126\n",
      " 0.13694921 0.00063976 0.10977876 0.00952525 0.11254034 0.03176734\n",
      " 0.07413935 0.03083581 0.12219511 0.00505695]\n",
      "11\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "initial_evaluation: score=0.5638, divergence=0.0000, diversity=1.1276, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.5643, divergence=0.0006, diversity=1.1274, num_succ=0, num_remain=89\n",
      " 100-th evaluation: score=0.5881, divergence=0.0276, diversity=1.1211, num_succ=1, num_remain=33\n",
      " 200-th evaluation: score=0.6020, divergence=0.0474, diversity=1.1093, num_succ=2, num_remain=40\n",
      " 300-th evaluation: score=0.6136, divergence=0.0633, diversity=1.1005, num_succ=2, num_remain=43\n",
      " 400-th evaluation: score=0.6250, divergence=0.0817, diversity=1.0867, num_succ=4, num_remain=41\n",
      " 500-th evaluation: score=0.6364, divergence=0.0966, diversity=1.0797, num_succ=4, num_remain=42\n",
      " 600-th evaluation: score=0.6477, divergence=0.1087, diversity=1.0781, num_succ=4, num_remain=34\n",
      " 700-th evaluation: score=0.6525, divergence=0.1141, diversity=1.0768, num_succ=4, num_remain=33\n",
      " 800-th evaluation: score=0.6579, divergence=0.1228, diversity=1.0701, num_succ=5, num_remain=32\n",
      " 900-th evaluation: score=0.6620, divergence=0.1284, diversity=1.0673, num_succ=5, num_remain=31\n",
      "1000-th evaluation: score=0.6706, divergence=0.1421, diversity=1.0571, num_succ=5, num_remain=32\n",
      "1100-th evaluation: score=0.6744, divergence=0.1474, diversity=1.0539, num_succ=6, num_remain=27\n",
      "1200-th evaluation: score=0.6761, divergence=0.1492, diversity=1.0539, num_succ=6, num_remain=25\n",
      "1300-th evaluation: score=0.6781, divergence=0.1513, diversity=1.0535, num_succ=6, num_remain=25\n",
      "1400-th evaluation: score=0.6798, divergence=0.1535, diversity=1.0526, num_succ=6, num_remain=24\n",
      "1500-th evaluation: score=0.6809, divergence=0.1550, diversity=1.0519, num_succ=6, num_remain=24\n",
      "1600-th evaluation: score=0.6825, divergence=0.1573, diversity=1.0504, num_succ=6, num_remain=25\n",
      "1700-th evaluation: score=0.6839, divergence=0.1591, diversity=1.0497, num_succ=6, num_remain=26\n",
      "1800-th evaluation: score=0.6881, divergence=0.1664, diversity=1.0434, num_succ=7, num_remain=29\n",
      "1900-th evaluation: score=0.6907, divergence=0.1710, diversity=1.0393, num_succ=7, num_remain=24\n",
      "2000-th evaluation: score=0.6934, divergence=0.1760, diversity=1.0348, num_succ=7, num_remain=26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100-th evaluation: score=0.6955, divergence=0.1783, diversity=1.0343, num_succ=7, num_remain=21\n",
      "2200-th evaluation: score=0.6987, divergence=0.1843, diversity=1.0289, num_succ=8, num_remain=27\n",
      "2300-th evaluation: score=0.7013, divergence=0.1878, diversity=1.0270, num_succ=10, num_remain=22\n",
      "2400-th evaluation: score=0.7062, divergence=0.1964, diversity=1.0196, num_succ=10, num_remain=24\n",
      "2500-th evaluation: score=0.7079, divergence=0.1984, diversity=1.0190, num_succ=10, num_remain=19\n",
      "2600-th evaluation: score=0.7096, divergence=0.2003, diversity=1.0186, num_succ=10, num_remain=20\n",
      "2700-th evaluation: score=0.7117, divergence=0.2033, diversity=1.0170, num_succ=10, num_remain=22\n",
      "2800-th evaluation: score=0.7123, divergence=0.2038, diversity=1.0169, num_succ=10, num_remain=20\n",
      "2900-th evaluation: score=0.7135, divergence=0.2052, diversity=1.0167, num_succ=10, num_remain=18\n",
      "3000-th evaluation: score=0.7142, divergence=0.2062, diversity=1.0159, num_succ=10, num_remain=19\n",
      "3100-th evaluation: score=0.7151, divergence=0.2075, diversity=1.0152, num_succ=10, num_remain=17\n",
      "3200-th evaluation: score=0.7158, divergence=0.2081, diversity=1.0152, num_succ=10, num_remain=18\n",
      "3300-th evaluation: score=0.7166, divergence=0.2092, diversity=1.0148, num_succ=10, num_remain=16\n",
      "3400-th evaluation: score=0.7172, divergence=0.2098, diversity=1.0148, num_succ=10, num_remain=16\n",
      "3500-th evaluation: score=0.7184, divergence=0.2109, diversity=1.0149, num_succ=11, num_remain=16\n",
      "3600-th evaluation: score=0.7187, divergence=0.2111, diversity=1.0153, num_succ=11, num_remain=16\n",
      "3700-th evaluation: score=0.7191, divergence=0.2114, diversity=1.0154, num_succ=11, num_remain=16\n",
      "3800-th evaluation: score=0.7197, divergence=0.2119, diversity=1.0156, num_succ=11, num_remain=17\n",
      "3900-th evaluation: score=0.7200, divergence=0.2121, diversity=1.0159, num_succ=11, num_remain=16\n",
      "4000-th evaluation: score=0.7204, divergence=0.2125, diversity=1.0158, num_succ=11, num_remain=16\n",
      "4100-th evaluation: score=0.7210, divergence=0.2132, diversity=1.0155, num_succ=11, num_remain=16\n",
      "4200-th evaluation: score=0.7223, divergence=0.2146, diversity=1.0154, num_succ=11, num_remain=16\n",
      "4300-th evaluation: score=0.7225, divergence=0.2148, diversity=1.0154, num_succ=11, num_remain=16\n",
      "4400-th evaluation: score=0.7227, divergence=0.2149, diversity=1.0155, num_succ=11, num_remain=16\n",
      "4500-th evaluation: score=0.7228, divergence=0.2150, diversity=1.0157, num_succ=11, num_remain=16\n",
      "4600-th evaluation: score=0.7232, divergence=0.2153, diversity=1.0158, num_succ=11, num_remain=16\n",
      "4700-th evaluation: score=0.7235, divergence=0.2156, diversity=1.0158, num_succ=11, num_remain=16\n",
      "4800-th evaluation: score=0.7236, divergence=0.2156, diversity=1.0159, num_succ=11, num_remain=16\n",
      "4900-th evaluation: score=0.7237, divergence=0.2157, diversity=1.0160, num_succ=11, num_remain=16\n",
      "5000-th evaluation: score=0.7239, divergence=0.2158, diversity=1.0161, num_succ=11, num_remain=16\n",
      "5100-th evaluation: score=0.7245, divergence=0.2166, diversity=1.0158, num_succ=11, num_remain=16\n",
      "5200-th evaluation: score=0.7248, divergence=0.2170, diversity=1.0157, num_succ=11, num_remain=16\n",
      "5300-th evaluation: score=0.7250, divergence=0.2172, diversity=1.0157, num_succ=11, num_remain=16\n",
      "5400-th evaluation: score=0.7252, divergence=0.2173, diversity=1.0158, num_succ=11, num_remain=15\n",
      "5500-th evaluation: score=0.7254, divergence=0.2174, diversity=1.0160, num_succ=11, num_remain=15\n",
      "5600-th evaluation: score=0.7255, divergence=0.2175, diversity=1.0161, num_succ=11, num_remain=15\n",
      "5700-th evaluation: score=0.7258, divergence=0.2179, diversity=1.0159, num_succ=11, num_remain=15\n",
      "5800-th evaluation: score=0.7259, divergence=0.2179, diversity=1.0160, num_succ=11, num_remain=15\n",
      "5900-th evaluation: score=0.7260, divergence=0.2180, diversity=1.0161, num_succ=11, num_remain=15\n",
      "6000-th evaluation: score=0.7263, divergence=0.2182, diversity=1.0162, num_succ=11, num_remain=15\n",
      "6100-th evaluation: score=0.7264, divergence=0.2183, diversity=1.0163, num_succ=11, num_remain=15\n",
      "6200-th evaluation: score=0.7265, divergence=0.2183, diversity=1.0164, num_succ=11, num_remain=15\n",
      "6300-th evaluation: score=0.7267, divergence=0.2184, diversity=1.0165, num_succ=11, num_remain=15\n",
      "6400-th evaluation: score=0.7268, divergence=0.2185, diversity=1.0166, num_succ=11, num_remain=15\n",
      "6500-th evaluation: score=0.7268, divergence=0.2185, diversity=1.0167, num_succ=11, num_remain=15\n",
      "6600-th evaluation: score=0.7269, divergence=0.2185, diversity=1.0167, num_succ=11, num_remain=15\n",
      "6700-th evaluation: score=0.7270, divergence=0.2186, diversity=1.0168, num_succ=11, num_remain=15\n",
      "6800-th evaluation: score=0.7270, divergence=0.2186, diversity=1.0168, num_succ=11, num_remain=15\n",
      "6900-th evaluation: score=0.7271, divergence=0.2187, diversity=1.0169, num_succ=11, num_remain=15\n",
      "7000-th evaluation: score=0.7271, divergence=0.2187, diversity=1.0169, num_succ=11, num_remain=15\n",
      "7100-th evaluation: score=0.7272, divergence=0.2188, diversity=1.0169, num_succ=11, num_remain=15\n",
      "7200-th evaluation: score=0.7273, divergence=0.2188, diversity=1.0170, num_succ=11, num_remain=15\n",
      "7300-th evaluation: score=0.7274, divergence=0.2188, diversity=1.0171, num_succ=11, num_remain=15\n",
      "7400-th evaluation: score=0.7274, divergence=0.2189, diversity=1.0171, num_succ=11, num_remain=15\n",
      "7500-th evaluation: score=0.7275, divergence=0.2189, diversity=1.0171, num_succ=11, num_remain=15\n",
      "7600-th evaluation: score=0.7275, divergence=0.2189, diversity=1.0172, num_succ=11, num_remain=15\n",
      "7700-th evaluation: score=0.7275, divergence=0.2189, diversity=1.0172, num_succ=11, num_remain=15\n",
      "7800-th evaluation: score=0.7276, divergence=0.2189, diversity=1.0172, num_succ=11, num_remain=15\n",
      "7900-th evaluation: score=0.7276, divergence=0.2190, diversity=1.0173, num_succ=11, num_remain=15\n",
      "8000-th evaluation: score=0.7277, divergence=0.2190, diversity=1.0173, num_succ=11, num_remain=15\n",
      "8100-th evaluation: score=0.7277, divergence=0.2190, diversity=1.0174, num_succ=11, num_remain=15\n",
      "8200-th evaluation: score=0.7278, divergence=0.2191, diversity=1.0174, num_succ=11, num_remain=15\n",
      "8300-th evaluation: score=0.7278, divergence=0.2191, diversity=1.0174, num_succ=11, num_remain=15\n",
      "8400-th evaluation: score=0.7278, divergence=0.2191, diversity=1.0175, num_succ=11, num_remain=15\n",
      "8500-th evaluation: score=0.7279, divergence=0.2191, diversity=1.0175, num_succ=11, num_remain=15\n",
      "8600-th evaluation: score=0.7282, divergence=0.2196, diversity=1.0173, num_succ=11, num_remain=16\n",
      "8700-th evaluation: score=0.7283, divergence=0.2196, diversity=1.0174, num_succ=11, num_remain=15\n",
      "8800-th evaluation: score=0.7283, divergence=0.2196, diversity=1.0174, num_succ=11, num_remain=15\n",
      "8900-th evaluation: score=0.7284, divergence=0.2197, diversity=1.0173, num_succ=11, num_remain=15\n",
      "9000-th evaluation: score=0.7284, divergence=0.2197, diversity=1.0173, num_succ=11, num_remain=15\n",
      "9100-th evaluation: score=0.7285, divergence=0.2198, diversity=1.0175, num_succ=11, num_remain=15\n",
      "9200-th evaluation: score=0.7286, divergence=0.2198, diversity=1.0175, num_succ=11, num_remain=15\n",
      "9300-th evaluation: score=0.7286, divergence=0.2198, diversity=1.0175, num_succ=11, num_remain=15\n",
      "9400-th evaluation: score=0.7286, divergence=0.2198, diversity=1.0175, num_succ=11, num_remain=15\n",
      "9500-th evaluation: score=0.7287, divergence=0.2200, diversity=1.0174, num_succ=11, num_remain=15\n",
      "9600-th evaluation: score=0.7287, divergence=0.2200, diversity=1.0174, num_succ=11, num_remain=15\n",
      "9700-th evaluation: score=0.7287, divergence=0.2200, diversity=1.0174, num_succ=11, num_remain=15\n",
      "9800-th evaluation: score=0.7287, divergence=0.2200, diversity=1.0175, num_succ=11, num_remain=15\n",
      "9900-th evaluation: score=0.7288, divergence=0.2201, diversity=1.0174, num_succ=11, num_remain=15\n",
      "[0.0587508  0.02072255 0.08832803 0.24297534 0.35444076 0.12210011\n",
      " 0.04926815 0.02843296 0.01518149 0.10405414 0.05535382 0.0056751\n",
      " 0.06606596 0.11890025 0.02349632 0.02041231 0.03579334 0.00128909\n",
      " 0.17058779 0.00647771 0.03564933 0.09575945 0.05460653 0.00417597\n",
      " 0.07016334 0.22402021 0.04123359 0.02554521 0.11248803 0.09656634\n",
      " 0.02947944 0.08669098 0.08439473 0.02155485 0.2042905  0.08509366\n",
      " 0.03368411 0.11092502 0.00572881 0.03667294 0.07583242 0.0159855\n",
      " 0.0569698  0.00957783 0.05334071 0.14162125 0.01883051 0.04365164\n",
      " 0.0772474  0.0278339  0.02965804 0.08769907 0.05573863 0.03613374\n",
      " 0.04862026 0.10630577 0.12389549 0.01410919 0.09465129 0.01903346\n",
      " 0.02170402 0.03083369 0.01634015 0.03494498 0.25488413 0.02071118\n",
      " 0.06182637 0.13553044 0.2665744  0.06393847 0.10894416 0.07511556\n",
      " 0.11331472 0.05880337 0.23390212 0.12165175 0.14004761 0.0379421\n",
      " 0.10609728 0.0399346  0.13430509 0.10954904 0.00962358 0.03201522\n",
      " 0.11032583 0.235547   0.06331914 0.05134212 0.13845337 0.01926563\n",
      " 0.03055463 0.06809686 0.11239004 0.00750586 0.04001132 0.00512754\n",
      " 0.00112368 0.00772994 0.0374841  0.08265742]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\t generating inputs for pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "initial_evaluation: score=0.6104, divergence=0.0000, diversity=1.2207, num_succ=0, num_remain=7\n",
      "   0-th evaluation: score=0.6105, divergence=0.0002, diversity=1.2207, num_succ=0, num_remain=92\n",
      " 100-th evaluation: score=0.6221, divergence=0.0134, diversity=1.2175, num_succ=0, num_remain=32\n",
      " 200-th evaluation: score=0.6264, divergence=0.0184, diversity=1.2160, num_succ=0, num_remain=26\n",
      " 300-th evaluation: score=0.6295, divergence=0.0221, diversity=1.2147, num_succ=0, num_remain=31\n",
      " 400-th evaluation: score=0.6320, divergence=0.0254, diversity=1.2131, num_succ=0, num_remain=28\n",
      " 500-th evaluation: score=0.6340, divergence=0.0279, diversity=1.2122, num_succ=0, num_remain=30\n",
      " 600-th evaluation: score=0.6364, divergence=0.0314, diversity=1.2101, num_succ=0, num_remain=30\n",
      " 700-th evaluation: score=0.6388, divergence=0.0351, diversity=1.2074, num_succ=0, num_remain=30\n",
      " 800-th evaluation: score=0.6411, divergence=0.0384, diversity=1.2055, num_succ=0, num_remain=30\n",
      " 900-th evaluation: score=0.6432, divergence=0.0412, diversity=1.2041, num_succ=0, num_remain=29\n",
      "1000-th evaluation: score=0.6458, divergence=0.0447, diversity=1.2023, num_succ=1, num_remain=38\n",
      "1100-th evaluation: score=0.6473, divergence=0.0469, diversity=1.2009, num_succ=1, num_remain=32\n",
      "1200-th evaluation: score=0.6491, divergence=0.0488, diversity=1.2005, num_succ=1, num_remain=28\n",
      "1300-th evaluation: score=0.6505, divergence=0.0514, diversity=1.1981, num_succ=1, num_remain=33\n",
      "1400-th evaluation: score=0.6520, divergence=0.0543, diversity=1.1954, num_succ=1, num_remain=30\n",
      "1500-th evaluation: score=0.6541, divergence=0.0575, diversity=1.1931, num_succ=1, num_remain=32\n",
      "1600-th evaluation: score=0.6549, divergence=0.0588, diversity=1.1922, num_succ=1, num_remain=29\n",
      "1700-th evaluation: score=0.6559, divergence=0.0599, diversity=1.1920, num_succ=1, num_remain=30\n",
      "1800-th evaluation: score=0.6564, divergence=0.0603, diversity=1.1922, num_succ=1, num_remain=27\n",
      "1900-th evaluation: score=0.6575, divergence=0.0622, diversity=1.1906, num_succ=1, num_remain=34\n",
      "2000-th evaluation: score=0.6582, divergence=0.0636, diversity=1.1892, num_succ=1, num_remain=33\n",
      "2100-th evaluation: score=0.6593, divergence=0.0655, diversity=1.1875, num_succ=1, num_remain=34\n",
      "2200-th evaluation: score=0.6604, divergence=0.0673, diversity=1.1863, num_succ=1, num_remain=32\n",
      "2300-th evaluation: score=0.6611, divergence=0.0682, diversity=1.1857, num_succ=2, num_remain=33\n",
      "2400-th evaluation: score=0.6621, divergence=0.0698, diversity=1.1846, num_succ=2, num_remain=29\n",
      "2500-th evaluation: score=0.6634, divergence=0.0714, diversity=1.1840, num_succ=2, num_remain=27\n",
      "2600-th evaluation: score=0.6642, divergence=0.0724, diversity=1.1836, num_succ=2, num_remain=34\n",
      "2700-th evaluation: score=0.6648, divergence=0.0734, diversity=1.1829, num_succ=2, num_remain=24\n",
      "2800-th evaluation: score=0.6659, divergence=0.0754, diversity=1.1809, num_succ=2, num_remain=31\n",
      "2900-th evaluation: score=0.6671, divergence=0.0771, diversity=1.1801, num_succ=2, num_remain=26\n",
      "3000-th evaluation: score=0.6682, divergence=0.0783, diversity=1.1798, num_succ=2, num_remain=31\n",
      "3100-th evaluation: score=0.6689, divergence=0.0793, diversity=1.1794, num_succ=2, num_remain=25\n",
      "3200-th evaluation: score=0.6697, divergence=0.0810, diversity=1.1774, num_succ=2, num_remain=30\n",
      "3300-th evaluation: score=0.6702, divergence=0.0820, diversity=1.1765, num_succ=2, num_remain=28\n",
      "3400-th evaluation: score=0.6706, divergence=0.0830, diversity=1.1751, num_succ=2, num_remain=29\n",
      "3500-th evaluation: score=0.6710, divergence=0.0837, diversity=1.1746, num_succ=2, num_remain=27\n",
      "3600-th evaluation: score=0.6713, divergence=0.0840, diversity=1.1745, num_succ=2, num_remain=28\n",
      "3700-th evaluation: score=0.6725, divergence=0.0861, diversity=1.1729, num_succ=2, num_remain=27\n",
      "3800-th evaluation: score=0.6731, divergence=0.0871, diversity=1.1719, num_succ=2, num_remain=26\n",
      "3900-th evaluation: score=0.6743, divergence=0.0881, diversity=1.1723, num_succ=2, num_remain=29\n",
      "4000-th evaluation: score=0.6748, divergence=0.0888, diversity=1.1720, num_succ=2, num_remain=28\n",
      "4100-th evaluation: score=0.6751, divergence=0.0894, diversity=1.1714, num_succ=2, num_remain=30\n",
      "4200-th evaluation: score=0.6757, divergence=0.0904, diversity=1.1706, num_succ=2, num_remain=29\n",
      "4300-th evaluation: score=0.6760, divergence=0.0908, diversity=1.1705, num_succ=2, num_remain=29\n",
      "4400-th evaluation: score=0.6763, divergence=0.0912, diversity=1.1702, num_succ=2, num_remain=30\n",
      "4500-th evaluation: score=0.6766, divergence=0.0919, diversity=1.1693, num_succ=2, num_remain=28\n",
      "4600-th evaluation: score=0.6772, divergence=0.0931, diversity=1.1681, num_succ=2, num_remain=28\n",
      "4700-th evaluation: score=0.6780, divergence=0.0943, diversity=1.1675, num_succ=2, num_remain=30\n",
      "4800-th evaluation: score=0.6785, divergence=0.0951, diversity=1.1668, num_succ=2, num_remain=34\n",
      "4900-th evaluation: score=0.6794, divergence=0.0974, diversity=1.1641, num_succ=2, num_remain=31\n",
      "5000-th evaluation: score=0.6797, divergence=0.0981, diversity=1.1632, num_succ=2, num_remain=30\n",
      "5100-th evaluation: score=0.6801, divergence=0.0990, diversity=1.1624, num_succ=2, num_remain=30\n",
      "5200-th evaluation: score=0.6814, divergence=0.1016, diversity=1.1596, num_succ=2, num_remain=30\n",
      "5300-th evaluation: score=0.6836, divergence=0.1039, diversity=1.1594, num_succ=2, num_remain=34\n",
      "5400-th evaluation: score=0.6845, divergence=0.1050, diversity=1.1589, num_succ=2, num_remain=32\n",
      "5500-th evaluation: score=0.6855, divergence=0.1066, diversity=1.1578, num_succ=2, num_remain=31\n",
      "5600-th evaluation: score=0.6866, divergence=0.1082, diversity=1.1568, num_succ=2, num_remain=31\n",
      "5700-th evaluation: score=0.6874, divergence=0.1094, diversity=1.1560, num_succ=2, num_remain=29\n",
      "5800-th evaluation: score=0.6879, divergence=0.1104, diversity=1.1551, num_succ=2, num_remain=29\n",
      "5900-th evaluation: score=0.6887, divergence=0.1114, diversity=1.1546, num_succ=2, num_remain=34\n",
      "6000-th evaluation: score=0.6893, divergence=0.1124, diversity=1.1538, num_succ=2, num_remain=29\n",
      "6100-th evaluation: score=0.6902, divergence=0.1137, diversity=1.1530, num_succ=2, num_remain=28\n",
      "6200-th evaluation: score=0.6909, divergence=0.1143, diversity=1.1532, num_succ=2, num_remain=29\n",
      "6300-th evaluation: score=0.6923, divergence=0.1155, diversity=1.1537, num_succ=2, num_remain=29\n",
      "6400-th evaluation: score=0.6935, divergence=0.1164, diversity=1.1542, num_succ=2, num_remain=32\n",
      "6500-th evaluation: score=0.6949, divergence=0.1174, diversity=1.1551, num_succ=2, num_remain=28\n",
      "6600-th evaluation: score=0.6957, divergence=0.1191, diversity=1.1532, num_succ=2, num_remain=28\n",
      "6700-th evaluation: score=0.6968, divergence=0.1204, diversity=1.1527, num_succ=2, num_remain=32\n",
      "6800-th evaluation: score=0.6977, divergence=0.1220, diversity=1.1514, num_succ=2, num_remain=32\n",
      "6900-th evaluation: score=0.6984, divergence=0.1235, diversity=1.1496, num_succ=2, num_remain=31\n",
      "7000-th evaluation: score=0.6989, divergence=0.1241, diversity=1.1496, num_succ=2, num_remain=29\n",
      "7100-th evaluation: score=0.6993, divergence=0.1250, diversity=1.1487, num_succ=2, num_remain=29\n",
      "7200-th evaluation: score=0.7004, divergence=0.1266, diversity=1.1476, num_succ=2, num_remain=33\n",
      "7300-th evaluation: score=0.7010, divergence=0.1279, diversity=1.1463, num_succ=2, num_remain=31\n",
      "7400-th evaluation: score=0.7021, divergence=0.1299, diversity=1.1444, num_succ=2, num_remain=31\n",
      "7500-th evaluation: score=0.7031, divergence=0.1320, diversity=1.1422, num_succ=2, num_remain=34\n",
      "7600-th evaluation: score=0.7047, divergence=0.1350, diversity=1.1392, num_succ=2, num_remain=33\n",
      "7700-th evaluation: score=0.7056, divergence=0.1367, diversity=1.1378, num_succ=3, num_remain=32\n",
      "7800-th evaluation: score=0.7068, divergence=0.1391, diversity=1.1353, num_succ=3, num_remain=32\n",
      "7900-th evaluation: score=0.7079, divergence=0.1411, diversity=1.1335, num_succ=3, num_remain=33\n",
      "8000-th evaluation: score=0.7092, divergence=0.1432, diversity=1.1320, num_succ=3, num_remain=30\n",
      "8100-th evaluation: score=0.7107, divergence=0.1467, diversity=1.1279, num_succ=3, num_remain=28\n",
      "8200-th evaluation: score=0.7117, divergence=0.1486, diversity=1.1260, num_succ=3, num_remain=31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8300-th evaluation: score=0.7128, divergence=0.1503, diversity=1.1248, num_succ=3, num_remain=29\n",
      "8400-th evaluation: score=0.7144, divergence=0.1536, diversity=1.1215, num_succ=3, num_remain=36\n",
      "8500-th evaluation: score=0.7158, divergence=0.1562, diversity=1.1191, num_succ=3, num_remain=35\n",
      "8600-th evaluation: score=0.7170, divergence=0.1587, diversity=1.1167, num_succ=3, num_remain=34\n",
      "8700-th evaluation: score=0.7180, divergence=0.1608, diversity=1.1146, num_succ=3, num_remain=32\n",
      "8800-th evaluation: score=0.7189, divergence=0.1623, diversity=1.1133, num_succ=3, num_remain=29\n",
      "8900-th evaluation: score=0.7198, divergence=0.1642, diversity=1.1113, num_succ=3, num_remain=35\n",
      "9000-th evaluation: score=0.7213, divergence=0.1670, diversity=1.1087, num_succ=3, num_remain=33\n",
      "9100-th evaluation: score=0.7221, divergence=0.1682, diversity=1.1078, num_succ=3, num_remain=32\n",
      "9200-th evaluation: score=0.7233, divergence=0.1707, diversity=1.1051, num_succ=3, num_remain=32\n",
      "9300-th evaluation: score=0.7245, divergence=0.1725, diversity=1.1040, num_succ=3, num_remain=27\n",
      "9400-th evaluation: score=0.7251, divergence=0.1733, diversity=1.1035, num_succ=3, num_remain=28\n",
      "9500-th evaluation: score=0.7257, divergence=0.1742, diversity=1.1030, num_succ=3, num_remain=28\n",
      "9600-th evaluation: score=0.7267, divergence=0.1759, diversity=1.1016, num_succ=3, num_remain=28\n",
      "9700-th evaluation: score=0.7278, divergence=0.1780, diversity=1.0997, num_succ=3, num_remain=29\n",
      "9800-th evaluation: score=0.7286, divergence=0.1794, diversity=1.0985, num_succ=3, num_remain=28\n",
      "9900-th evaluation: score=0.7293, divergence=0.1804, diversity=1.0979, num_succ=3, num_remain=27\n",
      "[0.05554079 0.08236093 0.07281013 0.07728448 0.05709365 0.00086115\n",
      " 0.03747828 0.09181417 0.15028355 0.02940979 0.07616433 0.01095707\n",
      " 0.00993759 0.04731045 0.12066597 0.15080277 0.05132725 0.04118754\n",
      " 0.09255036 0.14582704 0.08980232 0.24312505 0.0866369  0.00893076\n",
      " 0.17567712 0.11712438 0.00425604 0.00756581 0.01943242 0.03540998\n",
      " 0.02213945 0.05512912 0.03075781 0.13785404 0.12976756 0.09733786\n",
      " 0.00923018 0.04198915 0.05523464 0.02250765 0.10607204 0.14985965\n",
      " 0.07747229 0.11793699 0.08797706 0.10261932 0.11511708 0.0946256\n",
      " 0.04815035 0.13112849 0.00821256 0.12804408 0.19587735 0.03465227\n",
      " 0.07220114 0.16650264 0.05695032 0.02509325 0.10732431 0.01902112\n",
      " 0.08563695 0.14715492 0.29003195 0.09976052 0.00653447 0.08186216\n",
      " 0.09140426 0.046188   0.0107989  0.11344791 0.05105464 0.00556166\n",
      " 0.01768742 0.16121563 0.05191216 0.02599082 0.004998   0.01935916\n",
      " 0.09364963 0.0130793  0.05928167 0.04259659 0.23835251 0.05534219\n",
      " 0.05270795 0.00505696 0.07903562 0.0645933  0.11497706 0.20118813\n",
      " 0.00818041 0.17024892 0.20151025 0.14637002 0.03335333 0.00780767\n",
      " 0.12424734 0.1753886  0.04963784 0.0065082 ]\n",
      "13\t generating inputs for pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "initial_evaluation: score=0.6635, divergence=0.0000, diversity=1.3270, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6637, divergence=0.0002, diversity=1.3270, num_succ=0, num_remain=90\n",
      " 100-th evaluation: score=0.6688, divergence=0.0058, diversity=1.3260, num_succ=0, num_remain=39\n",
      " 200-th evaluation: score=0.6701, divergence=0.0076, diversity=1.3249, num_succ=0, num_remain=43\n",
      " 300-th evaluation: score=0.6712, divergence=0.0096, diversity=1.3232, num_succ=0, num_remain=40\n",
      " 400-th evaluation: score=0.6727, divergence=0.0119, diversity=1.3216, num_succ=0, num_remain=37\n",
      " 500-th evaluation: score=0.6737, divergence=0.0135, diversity=1.3203, num_succ=0, num_remain=42\n",
      " 600-th evaluation: score=0.6748, divergence=0.0159, diversity=1.3180, num_succ=0, num_remain=39\n",
      " 700-th evaluation: score=0.6758, divergence=0.0177, diversity=1.3160, num_succ=0, num_remain=38\n",
      " 800-th evaluation: score=0.6772, divergence=0.0206, diversity=1.3133, num_succ=0, num_remain=37\n",
      " 900-th evaluation: score=0.6783, divergence=0.0224, diversity=1.3116, num_succ=0, num_remain=30\n",
      "1000-th evaluation: score=0.6791, divergence=0.0245, diversity=1.3092, num_succ=0, num_remain=42\n",
      "1100-th evaluation: score=0.6801, divergence=0.0267, diversity=1.3067, num_succ=0, num_remain=35\n",
      "1200-th evaluation: score=0.6806, divergence=0.0277, diversity=1.3058, num_succ=0, num_remain=32\n",
      "1300-th evaluation: score=0.6809, divergence=0.0282, diversity=1.3053, num_succ=0, num_remain=33\n",
      "1400-th evaluation: score=0.6813, divergence=0.0291, diversity=1.3045, num_succ=0, num_remain=33\n",
      "1500-th evaluation: score=0.6818, divergence=0.0305, diversity=1.3026, num_succ=0, num_remain=33\n",
      "1600-th evaluation: score=0.6824, divergence=0.0318, diversity=1.3011, num_succ=0, num_remain=29\n",
      "1700-th evaluation: score=0.6827, divergence=0.0324, diversity=1.3007, num_succ=0, num_remain=32\n",
      "1800-th evaluation: score=0.6836, divergence=0.0343, diversity=1.2986, num_succ=0, num_remain=31\n",
      "1900-th evaluation: score=0.6841, divergence=0.0349, diversity=1.2983, num_succ=0, num_remain=29\n",
      "2000-th evaluation: score=0.6847, divergence=0.0364, diversity=1.2967, num_succ=0, num_remain=33\n",
      "2100-th evaluation: score=0.6851, divergence=0.0371, diversity=1.2959, num_succ=0, num_remain=29\n",
      "2200-th evaluation: score=0.6853, divergence=0.0375, diversity=1.2956, num_succ=0, num_remain=28\n",
      "2300-th evaluation: score=0.6856, divergence=0.0379, diversity=1.2955, num_succ=0, num_remain=28\n",
      "2400-th evaluation: score=0.6857, divergence=0.0381, diversity=1.2953, num_succ=0, num_remain=26\n",
      "2500-th evaluation: score=0.6859, divergence=0.0385, diversity=1.2949, num_succ=0, num_remain=24\n",
      "2600-th evaluation: score=0.6862, divergence=0.0388, diversity=1.2948, num_succ=0, num_remain=28\n",
      "2700-th evaluation: score=0.6864, divergence=0.0391, diversity=1.2946, num_succ=0, num_remain=24\n",
      "2800-th evaluation: score=0.6867, divergence=0.0399, diversity=1.2937, num_succ=0, num_remain=24\n",
      "2900-th evaluation: score=0.6869, divergence=0.0404, diversity=1.2931, num_succ=0, num_remain=29\n",
      "3000-th evaluation: score=0.6873, divergence=0.0409, diversity=1.2927, num_succ=0, num_remain=23\n",
      "3100-th evaluation: score=0.6876, divergence=0.0416, diversity=1.2920, num_succ=0, num_remain=29\n",
      "3200-th evaluation: score=0.6879, divergence=0.0421, diversity=1.2915, num_succ=0, num_remain=23\n",
      "3300-th evaluation: score=0.6882, divergence=0.0428, diversity=1.2908, num_succ=0, num_remain=31\n",
      "3400-th evaluation: score=0.6884, divergence=0.0434, diversity=1.2900, num_succ=0, num_remain=29\n",
      "3500-th evaluation: score=0.6889, divergence=0.0443, diversity=1.2891, num_succ=0, num_remain=33\n",
      "3600-th evaluation: score=0.6891, divergence=0.0446, diversity=1.2888, num_succ=0, num_remain=31\n",
      "3700-th evaluation: score=0.6892, divergence=0.0448, diversity=1.2887, num_succ=0, num_remain=28\n",
      "3800-th evaluation: score=0.6893, divergence=0.0449, diversity=1.2887, num_succ=0, num_remain=29\n",
      "3900-th evaluation: score=0.6895, divergence=0.0456, diversity=1.2877, num_succ=0, num_remain=32\n",
      "4000-th evaluation: score=0.6896, divergence=0.0460, diversity=1.2872, num_succ=0, num_remain=28\n",
      "4100-th evaluation: score=0.6898, divergence=0.0463, diversity=1.2869, num_succ=0, num_remain=28\n",
      "4200-th evaluation: score=0.6901, divergence=0.0473, diversity=1.2856, num_succ=0, num_remain=29\n",
      "4300-th evaluation: score=0.6902, divergence=0.0476, diversity=1.2852, num_succ=0, num_remain=26\n",
      "4400-th evaluation: score=0.6904, divergence=0.0479, diversity=1.2851, num_succ=0, num_remain=28\n",
      "4500-th evaluation: score=0.6906, divergence=0.0483, diversity=1.2847, num_succ=0, num_remain=27\n",
      "4600-th evaluation: score=0.6907, divergence=0.0485, diversity=1.2845, num_succ=0, num_remain=29\n",
      "4700-th evaluation: score=0.6908, divergence=0.0486, diversity=1.2843, num_succ=0, num_remain=28\n",
      "4800-th evaluation: score=0.6911, divergence=0.0496, diversity=1.2830, num_succ=0, num_remain=26\n",
      "4900-th evaluation: score=0.6915, divergence=0.0505, diversity=1.2820, num_succ=0, num_remain=26\n",
      "5000-th evaluation: score=0.6917, divergence=0.0510, diversity=1.2815, num_succ=0, num_remain=25\n",
      "5100-th evaluation: score=0.6921, divergence=0.0519, diversity=1.2802, num_succ=0, num_remain=26\n",
      "5200-th evaluation: score=0.6923, divergence=0.0528, diversity=1.2790, num_succ=0, num_remain=28\n",
      "5300-th evaluation: score=0.6928, divergence=0.0543, diversity=1.2770, num_succ=0, num_remain=23\n",
      "5400-th evaluation: score=0.6931, divergence=0.0546, diversity=1.2769, num_succ=0, num_remain=22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500-th evaluation: score=0.6934, divergence=0.0549, diversity=1.2769, num_succ=0, num_remain=24\n",
      "5600-th evaluation: score=0.6936, divergence=0.0552, diversity=1.2768, num_succ=0, num_remain=23\n",
      "5700-th evaluation: score=0.6938, divergence=0.0555, diversity=1.2766, num_succ=0, num_remain=21\n",
      "5800-th evaluation: score=0.6941, divergence=0.0558, diversity=1.2765, num_succ=0, num_remain=23\n",
      "5900-th evaluation: score=0.6941, divergence=0.0559, diversity=1.2765, num_succ=0, num_remain=21\n",
      "6000-th evaluation: score=0.6945, divergence=0.0563, diversity=1.2765, num_succ=0, num_remain=30\n",
      "6100-th evaluation: score=0.6946, divergence=0.0564, diversity=1.2763, num_succ=0, num_remain=26\n",
      "6200-th evaluation: score=0.6948, divergence=0.0570, diversity=1.2757, num_succ=0, num_remain=29\n",
      "6300-th evaluation: score=0.6952, divergence=0.0575, diversity=1.2755, num_succ=0, num_remain=24\n",
      "6400-th evaluation: score=0.6954, divergence=0.0577, diversity=1.2755, num_succ=0, num_remain=22\n",
      "6500-th evaluation: score=0.6955, divergence=0.0578, diversity=1.2754, num_succ=0, num_remain=22\n",
      "6600-th evaluation: score=0.6957, divergence=0.0581, diversity=1.2752, num_succ=0, num_remain=23\n",
      "6700-th evaluation: score=0.6962, divergence=0.0595, diversity=1.2733, num_succ=0, num_remain=36\n",
      "6800-th evaluation: score=0.6963, divergence=0.0601, diversity=1.2724, num_succ=0, num_remain=35\n",
      "6900-th evaluation: score=0.6972, divergence=0.0631, diversity=1.2682, num_succ=0, num_remain=33\n",
      "7000-th evaluation: score=0.6980, divergence=0.0646, diversity=1.2668, num_succ=0, num_remain=34\n",
      "7100-th evaluation: score=0.6985, divergence=0.0662, diversity=1.2646, num_succ=0, num_remain=38\n",
      "7200-th evaluation: score=0.6988, divergence=0.0670, diversity=1.2636, num_succ=0, num_remain=35\n",
      "7300-th evaluation: score=0.6994, divergence=0.0693, diversity=1.2603, num_succ=0, num_remain=36\n",
      "7400-th evaluation: score=0.6998, divergence=0.0703, diversity=1.2590, num_succ=0, num_remain=36\n",
      "7500-th evaluation: score=0.7000, divergence=0.0707, diversity=1.2586, num_succ=0, num_remain=33\n",
      "7600-th evaluation: score=0.7002, divergence=0.0712, diversity=1.2579, num_succ=0, num_remain=35\n",
      "7700-th evaluation: score=0.7004, divergence=0.0723, diversity=1.2563, num_succ=0, num_remain=33\n",
      "7800-th evaluation: score=0.7009, divergence=0.0738, diversity=1.2543, num_succ=0, num_remain=31\n",
      "7900-th evaluation: score=0.7014, divergence=0.0754, diversity=1.2520, num_succ=0, num_remain=28\n",
      "8000-th evaluation: score=0.7019, divergence=0.0771, diversity=1.2497, num_succ=0, num_remain=34\n",
      "8100-th evaluation: score=0.7023, divergence=0.0781, diversity=1.2484, num_succ=0, num_remain=29\n",
      "8200-th evaluation: score=0.7028, divergence=0.0798, diversity=1.2461, num_succ=0, num_remain=30\n",
      "8300-th evaluation: score=0.7032, divergence=0.0810, diversity=1.2445, num_succ=0, num_remain=27\n",
      "8400-th evaluation: score=0.7037, divergence=0.0818, diversity=1.2437, num_succ=0, num_remain=26\n",
      "8500-th evaluation: score=0.7039, divergence=0.0823, diversity=1.2432, num_succ=0, num_remain=28\n",
      "8600-th evaluation: score=0.7042, divergence=0.0833, diversity=1.2419, num_succ=0, num_remain=30\n",
      "8700-th evaluation: score=0.7045, divergence=0.0843, diversity=1.2405, num_succ=0, num_remain=33\n",
      "8800-th evaluation: score=0.7047, divergence=0.0846, diversity=1.2402, num_succ=0, num_remain=27\n",
      "8900-th evaluation: score=0.7050, divergence=0.0854, diversity=1.2392, num_succ=0, num_remain=30\n",
      "9000-th evaluation: score=0.7053, divergence=0.0862, diversity=1.2382, num_succ=0, num_remain=29\n",
      "9100-th evaluation: score=0.7062, divergence=0.0881, diversity=1.2362, num_succ=0, num_remain=33\n",
      "9200-th evaluation: score=0.7065, divergence=0.0895, diversity=1.2340, num_succ=0, num_remain=32\n",
      "9300-th evaluation: score=0.7072, divergence=0.0910, diversity=1.2325, num_succ=0, num_remain=26\n",
      "9400-th evaluation: score=0.7081, divergence=0.0935, diversity=1.2292, num_succ=0, num_remain=33\n",
      "9500-th evaluation: score=0.7086, divergence=0.0950, diversity=1.2273, num_succ=0, num_remain=32\n",
      "9600-th evaluation: score=0.7093, divergence=0.0970, diversity=1.2246, num_succ=0, num_remain=33\n",
      "9700-th evaluation: score=0.7103, divergence=0.0998, diversity=1.2210, num_succ=0, num_remain=37\n",
      "9800-th evaluation: score=0.7109, divergence=0.1018, diversity=1.2183, num_succ=0, num_remain=34\n",
      "9900-th evaluation: score=0.7115, divergence=0.1032, diversity=1.2165, num_succ=0, num_remain=40\n",
      "[0.00215898 0.0569409  0.10246119 0.0597606  0.0668798  0.20017735\n",
      " 0.04588257 0.13786906 0.07476069 0.00417094 0.18673556 0.14550835\n",
      " 0.03427615 0.03431267 0.02449017 0.2064458  0.15866234 0.06789306\n",
      " 0.02416954 0.10092222 0.22112178 0.03697242 0.06750812 0.08398273\n",
      " 0.07536507 0.07539911 0.05675528 0.04331833 0.09361649 0.08403972\n",
      " 0.08165391 0.01342047 0.04941374 0.11417271 0.03739097 0.04730493\n",
      " 0.13018763 0.0299255  0.02434279 0.05010325 0.02987888 0.02574966\n",
      " 0.06070991 0.14066198 0.07983553 0.03177842 0.07822166 0.01885345\n",
      " 0.06837869 0.2548715  0.06616783 0.09067698 0.05021709 0.04035216\n",
      " 0.05846857 0.07332853 0.06097205 0.12137306 0.00264603 0.11154814\n",
      " 0.14149197 0.00967924 0.05883048 0.06751352 0.12831652 0.07821803\n",
      " 0.11837023 0.0794486  0.08885021 0.04477771 0.0335811  0.00158147\n",
      " 0.00733572 0.17045075 0.14665542 0.10569043 0.08931708 0.04683493\n",
      " 0.09192517 0.07167138 0.0523593  0.20221986 0.09255413 0.12155448\n",
      " 0.13296442 0.05857758 0.07815571 0.04630254 0.17706378 0.15596855\n",
      " 0.06513261 0.04890793 0.09634716 0.19326913 0.09048241 0.14732467\n",
      " 0.14810194 0.0757871  0.14237597 0.11170462]\n",
      "14\t generating inputs for pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "initial_evaluation: score=0.6722, divergence=0.0000, diversity=1.3443, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6722, divergence=0.0001, diversity=1.3443, num_succ=0, num_remain=80\n",
      " 100-th evaluation: score=0.6751, divergence=0.0037, diversity=1.3427, num_succ=0, num_remain=32\n",
      " 200-th evaluation: score=0.6761, divergence=0.0053, diversity=1.3415, num_succ=0, num_remain=37\n",
      " 300-th evaluation: score=0.6765, divergence=0.0061, diversity=1.3410, num_succ=0, num_remain=30\n",
      " 400-th evaluation: score=0.6772, divergence=0.0073, diversity=1.3399, num_succ=0, num_remain=35\n",
      " 500-th evaluation: score=0.6776, divergence=0.0081, diversity=1.3391, num_succ=0, num_remain=27\n",
      " 600-th evaluation: score=0.6779, divergence=0.0090, diversity=1.3379, num_succ=0, num_remain=36\n",
      " 700-th evaluation: score=0.6789, divergence=0.0110, diversity=1.3359, num_succ=0, num_remain=35\n",
      " 800-th evaluation: score=0.6792, divergence=0.0118, diversity=1.3349, num_succ=0, num_remain=32\n",
      " 900-th evaluation: score=0.6803, divergence=0.0140, diversity=1.3328, num_succ=0, num_remain=33\n",
      "1000-th evaluation: score=0.6807, divergence=0.0148, diversity=1.3319, num_succ=0, num_remain=20\n",
      "1100-th evaluation: score=0.6811, divergence=0.0152, diversity=1.3316, num_succ=0, num_remain=20\n",
      "1200-th evaluation: score=0.6814, divergence=0.0159, diversity=1.3311, num_succ=0, num_remain=20\n",
      "1300-th evaluation: score=0.6816, divergence=0.0161, diversity=1.3310, num_succ=0, num_remain=19\n",
      "1400-th evaluation: score=0.6817, divergence=0.0164, diversity=1.3306, num_succ=0, num_remain=19\n",
      "1500-th evaluation: score=0.6820, divergence=0.0169, diversity=1.3302, num_succ=0, num_remain=21\n",
      "1600-th evaluation: score=0.6822, divergence=0.0173, diversity=1.3297, num_succ=0, num_remain=18\n",
      "1700-th evaluation: score=0.6826, divergence=0.0182, diversity=1.3287, num_succ=0, num_remain=20\n",
      "1800-th evaluation: score=0.6827, divergence=0.0185, diversity=1.3285, num_succ=0, num_remain=16\n",
      "1900-th evaluation: score=0.6829, divergence=0.0190, diversity=1.3279, num_succ=0, num_remain=20\n",
      "2000-th evaluation: score=0.6832, divergence=0.0197, diversity=1.3270, num_succ=0, num_remain=22\n",
      "2100-th evaluation: score=0.6836, divergence=0.0204, diversity=1.3263, num_succ=0, num_remain=25\n",
      "2200-th evaluation: score=0.6841, divergence=0.0219, diversity=1.3244, num_succ=0, num_remain=24\n",
      "2300-th evaluation: score=0.6843, divergence=0.0222, diversity=1.3242, num_succ=0, num_remain=18\n",
      "2400-th evaluation: score=0.6844, divergence=0.0224, diversity=1.3240, num_succ=0, num_remain=22\n",
      "2500-th evaluation: score=0.6849, divergence=0.0238, diversity=1.3222, num_succ=0, num_remain=23\n",
      "2600-th evaluation: score=0.6852, divergence=0.0247, diversity=1.3210, num_succ=0, num_remain=29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700-th evaluation: score=0.6857, divergence=0.0262, diversity=1.3190, num_succ=0, num_remain=28\n",
      "2800-th evaluation: score=0.6859, divergence=0.0267, diversity=1.3184, num_succ=0, num_remain=30\n",
      "2900-th evaluation: score=0.6862, divergence=0.0276, diversity=1.3173, num_succ=0, num_remain=27\n",
      "3000-th evaluation: score=0.6864, divergence=0.0281, diversity=1.3166, num_succ=0, num_remain=30\n",
      "3100-th evaluation: score=0.6868, divergence=0.0293, diversity=1.3150, num_succ=0, num_remain=26\n",
      "3200-th evaluation: score=0.6871, divergence=0.0302, diversity=1.3138, num_succ=0, num_remain=29\n",
      "3300-th evaluation: score=0.6872, divergence=0.0306, diversity=1.3133, num_succ=0, num_remain=24\n",
      "3400-th evaluation: score=0.6873, divergence=0.0307, diversity=1.3131, num_succ=0, num_remain=24\n",
      "3500-th evaluation: score=0.6875, divergence=0.0313, diversity=1.3123, num_succ=0, num_remain=29\n",
      "3600-th evaluation: score=0.6876, divergence=0.0318, diversity=1.3116, num_succ=0, num_remain=26\n",
      "3700-th evaluation: score=0.6878, divergence=0.0324, diversity=1.3106, num_succ=0, num_remain=34\n",
      "3800-th evaluation: score=0.6879, divergence=0.0330, diversity=1.3099, num_succ=0, num_remain=35\n",
      "3900-th evaluation: score=0.6885, divergence=0.0346, diversity=1.3078, num_succ=0, num_remain=28\n",
      "4000-th evaluation: score=0.6895, divergence=0.0379, diversity=1.3033, num_succ=0, num_remain=33\n",
      "4100-th evaluation: score=0.6904, divergence=0.0410, diversity=1.2988, num_succ=0, num_remain=29\n",
      "4200-th evaluation: score=0.6913, divergence=0.0440, diversity=1.2948, num_succ=0, num_remain=32\n",
      "4300-th evaluation: score=0.6923, divergence=0.0469, diversity=1.2908, num_succ=0, num_remain=38\n",
      "4400-th evaluation: score=0.6946, divergence=0.0537, diversity=1.2818, num_succ=0, num_remain=39\n",
      "4500-th evaluation: score=0.6956, divergence=0.0566, diversity=1.2782, num_succ=0, num_remain=23\n",
      "4600-th evaluation: score=0.6967, divergence=0.0594, diversity=1.2746, num_succ=0, num_remain=25\n",
      "4700-th evaluation: score=0.6986, divergence=0.0650, diversity=1.2671, num_succ=0, num_remain=27\n",
      "4800-th evaluation: score=0.7011, divergence=0.0722, diversity=1.2578, num_succ=0, num_remain=34\n",
      "4900-th evaluation: score=0.7037, divergence=0.0789, diversity=1.2497, num_succ=0, num_remain=26\n",
      "5000-th evaluation: score=0.7062, divergence=0.0851, diversity=1.2422, num_succ=0, num_remain=27\n",
      "5100-th evaluation: score=0.7084, divergence=0.0914, diversity=1.2342, num_succ=0, num_remain=24\n",
      "5200-th evaluation: score=0.7105, divergence=0.0965, diversity=1.2279, num_succ=0, num_remain=21\n",
      "5300-th evaluation: score=0.7126, divergence=0.1030, diversity=1.2193, num_succ=0, num_remain=36\n",
      "5400-th evaluation: score=0.7151, divergence=0.1092, diversity=1.2118, num_succ=0, num_remain=33\n",
      "5500-th evaluation: score=0.7187, divergence=0.1190, diversity=1.1993, num_succ=0, num_remain=32\n",
      "5600-th evaluation: score=0.7225, divergence=0.1286, diversity=1.1878, num_succ=0, num_remain=29\n",
      "5700-th evaluation: score=0.7256, divergence=0.1364, diversity=1.1784, num_succ=0, num_remain=29\n",
      "5800-th evaluation: score=0.7287, divergence=0.1444, diversity=1.1686, num_succ=0, num_remain=34\n",
      "5900-th evaluation: score=0.7320, divergence=0.1528, diversity=1.1584, num_succ=0, num_remain=33\n",
      "6000-th evaluation: score=0.7367, divergence=0.1658, diversity=1.1417, num_succ=0, num_remain=33\n",
      "6100-th evaluation: score=0.7416, divergence=0.1786, diversity=1.1262, num_succ=0, num_remain=33\n",
      "6200-th evaluation: score=0.7459, divergence=0.1894, diversity=1.1129, num_succ=0, num_remain=34\n",
      "6300-th evaluation: score=0.7514, divergence=0.2038, diversity=1.0952, num_succ=0, num_remain=38\n",
      "6400-th evaluation: score=0.7579, divergence=0.2215, diversity=1.0727, num_succ=0, num_remain=40\n",
      "6500-th evaluation: score=0.7632, divergence=0.2366, diversity=1.0532, num_succ=0, num_remain=36\n",
      "6600-th evaluation: score=0.7705, divergence=0.2555, diversity=1.0301, num_succ=0, num_remain=37\n",
      "6700-th evaluation: score=0.7774, divergence=0.2718, diversity=1.0112, num_succ=0, num_remain=36\n",
      "6800-th evaluation: score=0.7842, divergence=0.2891, diversity=0.9902, num_succ=0, num_remain=35\n",
      "6900-th evaluation: score=0.7895, divergence=0.3033, diversity=0.9725, num_succ=0, num_remain=37\n",
      "7000-th evaluation: score=0.7947, divergence=0.3162, diversity=0.9569, num_succ=0, num_remain=35\n",
      "7100-th evaluation: score=0.8001, divergence=0.3305, diversity=0.9392, num_succ=0, num_remain=28\n",
      "7200-th evaluation: score=0.8048, divergence=0.3422, diversity=0.9253, num_succ=0, num_remain=28\n",
      "7300-th evaluation: score=0.8101, divergence=0.3543, diversity=0.9116, num_succ=0, num_remain=33\n",
      "7400-th evaluation: score=0.8148, divergence=0.3654, diversity=0.8987, num_succ=0, num_remain=23\n",
      "7500-th evaluation: score=0.8207, divergence=0.3790, diversity=0.8835, num_succ=0, num_remain=26\n",
      "7600-th evaluation: score=0.8257, divergence=0.3904, diversity=0.8706, num_succ=0, num_remain=28\n",
      "7700-th evaluation: score=0.8299, divergence=0.3995, diversity=0.8608, num_succ=0, num_remain=22\n",
      "7800-th evaluation: score=0.8346, divergence=0.4096, diversity=0.8500, num_succ=0, num_remain=25\n",
      "7900-th evaluation: score=0.8388, divergence=0.4189, diversity=0.8399, num_succ=1, num_remain=20\n",
      "8000-th evaluation: score=0.8424, divergence=0.4267, diversity=0.8313, num_succ=1, num_remain=18\n",
      "8100-th evaluation: score=0.8453, divergence=0.4331, diversity=0.8245, num_succ=1, num_remain=15\n",
      "8200-th evaluation: score=0.8490, divergence=0.4410, diversity=0.8159, num_succ=1, num_remain=22\n",
      "8300-th evaluation: score=0.8522, divergence=0.4473, diversity=0.8098, num_succ=1, num_remain=18\n",
      "8400-th evaluation: score=0.8555, divergence=0.4544, diversity=0.8022, num_succ=1, num_remain=23\n",
      "8500-th evaluation: score=0.8579, divergence=0.4596, diversity=0.7966, num_succ=1, num_remain=15\n",
      "8600-th evaluation: score=0.8617, divergence=0.4675, diversity=0.7885, num_succ=2, num_remain=15\n",
      "8700-th evaluation: score=0.8657, divergence=0.4761, diversity=0.7793, num_succ=2, num_remain=17\n",
      "8800-th evaluation: score=0.8693, divergence=0.4834, diversity=0.7718, num_succ=2, num_remain=19\n",
      "8900-th evaluation: score=0.8731, divergence=0.4906, diversity=0.7650, num_succ=2, num_remain=22\n",
      "9000-th evaluation: score=0.8766, divergence=0.4981, diversity=0.7569, num_succ=2, num_remain=16\n",
      "9100-th evaluation: score=0.8789, divergence=0.5030, diversity=0.7519, num_succ=2, num_remain=16\n",
      "9200-th evaluation: score=0.8809, divergence=0.5064, diversity=0.7490, num_succ=2, num_remain=13\n",
      "9300-th evaluation: score=0.8851, divergence=0.5147, diversity=0.7408, num_succ=2, num_remain=17\n",
      "9400-th evaluation: score=0.8885, divergence=0.5214, diversity=0.7341, num_succ=2, num_remain=17\n",
      "9500-th evaluation: score=0.8923, divergence=0.5295, diversity=0.7256, num_succ=2, num_remain=18\n",
      "9600-th evaluation: score=0.8951, divergence=0.5351, diversity=0.7200, num_succ=2, num_remain=12\n",
      "9700-th evaluation: score=0.8981, divergence=0.5414, diversity=0.7133, num_succ=2, num_remain=14\n",
      "9800-th evaluation: score=0.9001, divergence=0.5446, diversity=0.7109, num_succ=2, num_remain=12\n",
      "9900-th evaluation: score=0.9036, divergence=0.5517, diversity=0.7039, num_succ=2, num_remain=18\n",
      "[0.03458575 0.0815635  0.0602124  0.08930282 0.07077811 0.11036042\n",
      " 0.14107452 0.09339043 0.08996416 0.10736883 0.11005137 0.1072619\n",
      " 0.10703046 0.06614141 0.07391446 0.0796325  0.05162061 0.06976228\n",
      " 0.13441804 0.11876385 0.18305953 0.06941237 0.07430454 0.05509211\n",
      " 0.1245746  0.05706547 0.10547054 0.123401   0.0506233  0.1399387\n",
      " 0.19292398 0.07047657 0.09046717 0.19007172 0.08141479 0.12704336\n",
      " 0.03976929 0.11690644 0.08355677 0.04777463 0.0528004  0.07689265\n",
      " 0.10500355 0.21191045 0.06214852 0.0374474  0.1728679  0.06083661\n",
      " 0.13267638 0.06998137 0.04964174 0.1123661  0.05652183 0.02516095\n",
      " 0.08937379 0.02917117 0.09536249 0.05372414 0.04564472 0.09291784\n",
      " 0.10395868 0.08336465 0.07222321 0.03156473 0.12272519 0.06922562\n",
      " 0.1120627  0.05668944 0.11491779 0.11973727 0.01949941 0.15253081\n",
      " 0.13722051 0.09669554 0.05664321 0.06607692 0.05006968 0.0515758\n",
      " 0.0696638  0.07024391 0.08075373 0.05718436 0.13033276 0.14460028\n",
      " 0.08797627 0.09710499 0.12824201 0.14714702 0.15195774 0.15156144\n",
      " 0.04442962 0.15555535 0.07094628 0.14839574 0.0561391  0.08311859\n",
      " 0.0524551  0.08063467 0.10067862 0.0812534 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\t generating inputs for pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "initial_evaluation: score=0.4269, divergence=0.0000, diversity=0.8539, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.4277, divergence=0.0008, diversity=0.8538, num_succ=1, num_remain=82\n",
      " 100-th evaluation: score=0.4542, divergence=0.0261, diversity=0.8562, num_succ=7, num_remain=29\n",
      " 200-th evaluation: score=0.4661, divergence=0.0373, diversity=0.8578, num_succ=8, num_remain=24\n",
      " 300-th evaluation: score=0.4766, divergence=0.0465, diversity=0.8603, num_succ=9, num_remain=20\n",
      " 400-th evaluation: score=0.4826, divergence=0.0516, diversity=0.8620, num_succ=10, num_remain=20\n",
      " 500-th evaluation: score=0.4869, divergence=0.0562, diversity=0.8615, num_succ=11, num_remain=16\n",
      " 600-th evaluation: score=0.4896, divergence=0.0587, diversity=0.8618, num_succ=11, num_remain=14\n",
      " 700-th evaluation: score=0.4919, divergence=0.0617, diversity=0.8604, num_succ=11, num_remain=12\n",
      " 800-th evaluation: score=0.4938, divergence=0.0637, diversity=0.8602, num_succ=12, num_remain=11\n",
      " 900-th evaluation: score=0.4951, divergence=0.0650, diversity=0.8601, num_succ=12, num_remain=10\n",
      "1000-th evaluation: score=0.4964, divergence=0.0666, diversity=0.8595, num_succ=12, num_remain=15\n",
      "1100-th evaluation: score=0.5001, divergence=0.0701, diversity=0.8599, num_succ=12, num_remain=14\n",
      "1200-th evaluation: score=0.5024, divergence=0.0726, diversity=0.8597, num_succ=13, num_remain=12\n",
      "1300-th evaluation: score=0.5069, divergence=0.0767, diversity=0.8604, num_succ=13, num_remain=24\n",
      "1400-th evaluation: score=0.5109, divergence=0.0798, diversity=0.8622, num_succ=13, num_remain=16\n",
      "1500-th evaluation: score=0.5170, divergence=0.0851, diversity=0.8638, num_succ=14, num_remain=17\n",
      "1600-th evaluation: score=0.5229, divergence=0.0894, diversity=0.8669, num_succ=15, num_remain=22\n",
      "1700-th evaluation: score=0.5261, divergence=0.0921, diversity=0.8679, num_succ=16, num_remain=21\n",
      "1800-th evaluation: score=0.5298, divergence=0.0953, diversity=0.8689, num_succ=16, num_remain=22\n",
      "1900-th evaluation: score=0.5343, divergence=0.0997, diversity=0.8691, num_succ=16, num_remain=22\n",
      "2000-th evaluation: score=0.5391, divergence=0.1030, diversity=0.8721, num_succ=16, num_remain=22\n",
      "2100-th evaluation: score=0.5429, divergence=0.1067, diversity=0.8725, num_succ=17, num_remain=15\n",
      "2200-th evaluation: score=0.5453, divergence=0.1086, diversity=0.8734, num_succ=17, num_remain=16\n",
      "2300-th evaluation: score=0.5478, divergence=0.1107, diversity=0.8741, num_succ=17, num_remain=17\n",
      "2400-th evaluation: score=0.5507, divergence=0.1134, diversity=0.8746, num_succ=17, num_remain=15\n",
      "2500-th evaluation: score=0.5533, divergence=0.1157, diversity=0.8752, num_succ=17, num_remain=16\n",
      "2600-th evaluation: score=0.5550, divergence=0.1172, diversity=0.8755, num_succ=17, num_remain=14\n",
      "2700-th evaluation: score=0.5572, divergence=0.1195, diversity=0.8754, num_succ=18, num_remain=14\n",
      "2800-th evaluation: score=0.5594, divergence=0.1218, diversity=0.8752, num_succ=19, num_remain=12\n",
      "2900-th evaluation: score=0.5618, divergence=0.1241, diversity=0.8754, num_succ=20, num_remain=12\n",
      "3000-th evaluation: score=0.5629, divergence=0.1251, diversity=0.8757, num_succ=20, num_remain=12\n",
      "3100-th evaluation: score=0.5640, divergence=0.1257, diversity=0.8767, num_succ=20, num_remain=14\n",
      "3200-th evaluation: score=0.5649, divergence=0.1264, diversity=0.8770, num_succ=20, num_remain=11\n",
      "3300-th evaluation: score=0.5666, divergence=0.1278, diversity=0.8774, num_succ=20, num_remain=12\n",
      "3400-th evaluation: score=0.5676, divergence=0.1287, diversity=0.8779, num_succ=20, num_remain=9\n",
      "3500-th evaluation: score=0.5689, divergence=0.1301, diversity=0.8776, num_succ=20, num_remain=11\n",
      "3600-th evaluation: score=0.5705, divergence=0.1316, diversity=0.8777, num_succ=20, num_remain=9\n",
      "3700-th evaluation: score=0.5711, divergence=0.1323, diversity=0.8776, num_succ=20, num_remain=8\n",
      "3800-th evaluation: score=0.5717, divergence=0.1327, diversity=0.8779, num_succ=20, num_remain=8\n",
      "3900-th evaluation: score=0.5722, divergence=0.1334, diversity=0.8777, num_succ=20, num_remain=8\n",
      "4000-th evaluation: score=0.5727, divergence=0.1338, diversity=0.8779, num_succ=20, num_remain=8\n",
      "4100-th evaluation: score=0.5735, divergence=0.1346, diversity=0.8778, num_succ=20, num_remain=10\n",
      "4200-th evaluation: score=0.5741, divergence=0.1351, diversity=0.8780, num_succ=21, num_remain=9\n",
      "4300-th evaluation: score=0.5753, divergence=0.1361, diversity=0.8783, num_succ=21, num_remain=8\n",
      "4400-th evaluation: score=0.5761, divergence=0.1371, diversity=0.8781, num_succ=21, num_remain=10\n",
      "4500-th evaluation: score=0.5772, divergence=0.1380, diversity=0.8784, num_succ=21, num_remain=8\n",
      "4600-th evaluation: score=0.5776, divergence=0.1384, diversity=0.8784, num_succ=21, num_remain=7\n",
      "4700-th evaluation: score=0.5781, divergence=0.1388, diversity=0.8785, num_succ=21, num_remain=9\n",
      "4800-th evaluation: score=0.5784, divergence=0.1391, diversity=0.8787, num_succ=21, num_remain=7\n",
      "4900-th evaluation: score=0.5791, divergence=0.1396, diversity=0.8790, num_succ=21, num_remain=7\n",
      "5000-th evaluation: score=0.5794, divergence=0.1397, diversity=0.8793, num_succ=21, num_remain=7\n",
      "5100-th evaluation: score=0.5795, divergence=0.1399, diversity=0.8794, num_succ=21, num_remain=7\n",
      "5200-th evaluation: score=0.5797, divergence=0.1400, diversity=0.8795, num_succ=21, num_remain=7\n",
      "5300-th evaluation: score=0.5798, divergence=0.1400, diversity=0.8796, num_succ=21, num_remain=7\n",
      "5400-th evaluation: score=0.5799, divergence=0.1401, diversity=0.8797, num_succ=21, num_remain=7\n",
      "5500-th evaluation: score=0.5801, divergence=0.1402, diversity=0.8798, num_succ=21, num_remain=7\n",
      "5600-th evaluation: score=0.5802, divergence=0.1402, diversity=0.8799, num_succ=21, num_remain=7\n",
      "5700-th evaluation: score=0.5804, divergence=0.1404, diversity=0.8800, num_succ=21, num_remain=8\n",
      "5800-th evaluation: score=0.5805, divergence=0.1405, diversity=0.8800, num_succ=21, num_remain=7\n",
      "5900-th evaluation: score=0.5806, divergence=0.1405, diversity=0.8801, num_succ=21, num_remain=7\n",
      "6000-th evaluation: score=0.5807, divergence=0.1406, diversity=0.8802, num_succ=21, num_remain=7\n",
      "6100-th evaluation: score=0.5808, divergence=0.1406, diversity=0.8802, num_succ=21, num_remain=7\n",
      "6200-th evaluation: score=0.5809, divergence=0.1408, diversity=0.8803, num_succ=21, num_remain=7\n",
      "6300-th evaluation: score=0.5810, divergence=0.1409, diversity=0.8802, num_succ=21, num_remain=7\n",
      "6400-th evaluation: score=0.5811, divergence=0.1410, diversity=0.8803, num_succ=21, num_remain=7\n",
      "6500-th evaluation: score=0.5812, divergence=0.1410, diversity=0.8803, num_succ=21, num_remain=7\n",
      "6600-th evaluation: score=0.5812, divergence=0.1410, diversity=0.8803, num_succ=21, num_remain=7\n",
      "6700-th evaluation: score=0.5812, divergence=0.1410, diversity=0.8804, num_succ=21, num_remain=7\n",
      "6800-th evaluation: score=0.5813, divergence=0.1411, diversity=0.8804, num_succ=21, num_remain=7\n",
      "6900-th evaluation: score=0.5816, divergence=0.1414, diversity=0.8805, num_succ=21, num_remain=7\n",
      "7000-th evaluation: score=0.5817, divergence=0.1414, diversity=0.8805, num_succ=21, num_remain=7\n",
      "7100-th evaluation: score=0.5817, divergence=0.1414, diversity=0.8806, num_succ=21, num_remain=7\n",
      "7200-th evaluation: score=0.5818, divergence=0.1415, diversity=0.8806, num_succ=21, num_remain=7\n",
      "7300-th evaluation: score=0.5818, divergence=0.1415, diversity=0.8807, num_succ=21, num_remain=7\n",
      "7400-th evaluation: score=0.5818, divergence=0.1415, diversity=0.8807, num_succ=21, num_remain=7\n",
      "7500-th evaluation: score=0.5819, divergence=0.1415, diversity=0.8808, num_succ=21, num_remain=7\n",
      "7600-th evaluation: score=0.5820, divergence=0.1416, diversity=0.8808, num_succ=21, num_remain=7\n",
      "7700-th evaluation: score=0.5820, divergence=0.1416, diversity=0.8808, num_succ=21, num_remain=7\n",
      "7800-th evaluation: score=0.5820, divergence=0.1416, diversity=0.8808, num_succ=21, num_remain=7\n",
      "7900-th evaluation: score=0.5821, divergence=0.1416, diversity=0.8809, num_succ=21, num_remain=7\n",
      "8000-th evaluation: score=0.5821, divergence=0.1416, diversity=0.8809, num_succ=21, num_remain=7\n",
      "8100-th evaluation: score=0.5821, divergence=0.1416, diversity=0.8809, num_succ=21, num_remain=7\n",
      "8200-th evaluation: score=0.5821, divergence=0.1417, diversity=0.8809, num_succ=21, num_remain=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8300-th evaluation: score=0.5821, divergence=0.1417, diversity=0.8809, num_succ=21, num_remain=7\n",
      "8400-th evaluation: score=0.5821, divergence=0.1417, diversity=0.8809, num_succ=21, num_remain=7\n",
      "8500-th evaluation: score=0.5822, divergence=0.1417, diversity=0.8809, num_succ=21, num_remain=7\n",
      "8600-th evaluation: score=0.5822, divergence=0.1417, diversity=0.8810, num_succ=21, num_remain=7\n",
      "8700-th evaluation: score=0.5822, divergence=0.1417, diversity=0.8810, num_succ=21, num_remain=7\n",
      "8800-th evaluation: score=0.5822, divergence=0.1417, diversity=0.8810, num_succ=21, num_remain=7\n",
      "8900-th evaluation: score=0.5824, divergence=0.1418, diversity=0.8811, num_succ=21, num_remain=7\n",
      "9000-th evaluation: score=0.5824, divergence=0.1418, diversity=0.8811, num_succ=21, num_remain=7\n",
      "9100-th evaluation: score=0.5824, divergence=0.1419, diversity=0.8811, num_succ=21, num_remain=7\n",
      "9200-th evaluation: score=0.5824, divergence=0.1419, diversity=0.8811, num_succ=21, num_remain=7\n",
      "9300-th evaluation: score=0.5824, divergence=0.1419, diversity=0.8811, num_succ=21, num_remain=7\n",
      "9400-th evaluation: score=0.5825, divergence=0.1419, diversity=0.8811, num_succ=21, num_remain=7\n",
      "9500-th evaluation: score=0.5825, divergence=0.1419, diversity=0.8812, num_succ=21, num_remain=7\n",
      "9600-th evaluation: score=0.5825, divergence=0.1419, diversity=0.8812, num_succ=21, num_remain=7\n",
      "9700-th evaluation: score=0.5825, divergence=0.1419, diversity=0.8812, num_succ=21, num_remain=7\n",
      "9800-th evaluation: score=0.5825, divergence=0.1419, diversity=0.8812, num_succ=21, num_remain=7\n",
      "9900-th evaluation: score=0.5825, divergence=0.1419, diversity=0.8812, num_succ=21, num_remain=7\n",
      "[7.33614523e-03 2.31695645e-01 3.54226941e-02 8.34180135e-02\n",
      " 2.63961574e-03 5.17634304e-03 3.69057412e-02 1.23637133e-02\n",
      " 1.21168950e-02 3.13396476e-03 8.50397177e-03 9.98203118e-03\n",
      " 2.78692291e-02 1.47153269e-02 2.87422133e-02 2.82002677e-03\n",
      " 9.60611787e-02 1.04919132e-02 1.28382542e-02 6.42240469e-03\n",
      " 4.94691037e-03 2.56380320e-03 2.67196432e-04 2.32673513e-01\n",
      " 3.16014289e-02 3.32819876e-03 1.41739513e-02 1.13690300e-03\n",
      " 3.78636582e-02 5.58476169e-04 1.26102465e-02 1.33676024e-01\n",
      " 4.27325615e-01 1.54149968e-01 5.02357793e-03 3.17792748e-02\n",
      " 1.94818262e-02 6.21833787e-03 1.57755624e-02 5.50758111e-02\n",
      " 1.23603359e-01 3.18352222e-01 1.83966525e-02 2.54157246e-03\n",
      " 1.32612083e-02 1.99264981e-01 5.75810448e-02 4.64519928e-02\n",
      " 1.90236734e-02 1.26653959e-02 1.87931007e-02 1.83566086e-02\n",
      " 8.61897312e-03 3.59767669e-01 2.51163221e-02 4.63733302e-02\n",
      " 1.12198276e-02 1.74031948e-01 6.31497035e-02 2.24355225e-02\n",
      " 7.46133567e-02 4.40909739e-03 2.10125982e-01 1.06607814e-02\n",
      " 2.07844623e-01 1.43056257e-01 1.45280044e-01 1.86878895e-01\n",
      " 1.93380247e-01 4.77959552e-02 1.42175578e-02 2.15224945e-03\n",
      " 5.47588805e-03 1.28211536e-02 3.80801230e-03 1.93849230e-02\n",
      " 2.20909460e-02 1.28619385e-01 1.49584543e-01 9.10374582e-02\n",
      " 8.49614826e-02 5.02329292e-03 7.06512968e-02 1.77887271e-02\n",
      " 9.18941969e-03 9.35472521e-03 1.08527353e-02 6.68489846e-04\n",
      " 1.32753448e-01 5.56637857e-02 3.49155197e-02 1.64863761e-02\n",
      " 2.00764986e-02 5.70304064e-03 2.97676776e-02 1.48431537e-02\n",
      " 2.29502497e-02 1.34366317e-02 3.00286038e-02 1.10467698e-01]\n",
      "16\t generating inputs for pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "initial_evaluation: score=0.5220, divergence=0.0000, diversity=1.0441, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.5231, divergence=0.0010, diversity=1.0443, num_succ=0, num_remain=90\n",
      " 100-th evaluation: score=0.5534, divergence=0.0296, diversity=1.0476, num_succ=2, num_remain=39\n",
      " 200-th evaluation: score=0.5683, divergence=0.0444, diversity=1.0477, num_succ=2, num_remain=36\n",
      " 300-th evaluation: score=0.5771, divergence=0.0518, diversity=1.0506, num_succ=2, num_remain=36\n",
      " 400-th evaluation: score=0.5843, divergence=0.0583, diversity=1.0520, num_succ=2, num_remain=33\n",
      " 500-th evaluation: score=0.5896, divergence=0.0628, diversity=1.0534, num_succ=2, num_remain=30\n",
      " 600-th evaluation: score=0.5940, divergence=0.0670, diversity=1.0538, num_succ=3, num_remain=28\n",
      " 700-th evaluation: score=0.5956, divergence=0.0684, diversity=1.0545, num_succ=4, num_remain=26\n",
      " 800-th evaluation: score=0.5988, divergence=0.0711, diversity=1.0554, num_succ=4, num_remain=27\n",
      " 900-th evaluation: score=0.6024, divergence=0.0743, diversity=1.0562, num_succ=4, num_remain=29\n",
      "1000-th evaluation: score=0.6047, divergence=0.0764, diversity=1.0566, num_succ=4, num_remain=26\n",
      "1100-th evaluation: score=0.6065, divergence=0.0778, diversity=1.0574, num_succ=4, num_remain=25\n",
      "1200-th evaluation: score=0.6088, divergence=0.0801, diversity=1.0575, num_succ=4, num_remain=25\n",
      "1300-th evaluation: score=0.6111, divergence=0.0821, diversity=1.0580, num_succ=5, num_remain=26\n",
      "1400-th evaluation: score=0.6126, divergence=0.0838, diversity=1.0577, num_succ=5, num_remain=25\n",
      "1500-th evaluation: score=0.6139, divergence=0.0851, diversity=1.0577, num_succ=5, num_remain=25\n",
      "1600-th evaluation: score=0.6150, divergence=0.0861, diversity=1.0577, num_succ=5, num_remain=25\n",
      "1700-th evaluation: score=0.6173, divergence=0.0886, diversity=1.0574, num_succ=5, num_remain=28\n",
      "1800-th evaluation: score=0.6241, divergence=0.0947, diversity=1.0588, num_succ=6, num_remain=33\n",
      "1900-th evaluation: score=0.6304, divergence=0.1005, diversity=1.0597, num_succ=7, num_remain=33\n",
      "2000-th evaluation: score=0.6348, divergence=0.1050, diversity=1.0597, num_succ=7, num_remain=30\n",
      "2100-th evaluation: score=0.6395, divergence=0.1101, diversity=1.0588, num_succ=7, num_remain=33\n",
      "2200-th evaluation: score=0.6422, divergence=0.1126, diversity=1.0591, num_succ=7, num_remain=28\n",
      "2300-th evaluation: score=0.6451, divergence=0.1152, diversity=1.0599, num_succ=7, num_remain=29\n",
      "2400-th evaluation: score=0.6468, divergence=0.1167, diversity=1.0601, num_succ=7, num_remain=27\n",
      "2500-th evaluation: score=0.6478, divergence=0.1173, diversity=1.0610, num_succ=7, num_remain=28\n",
      "2600-th evaluation: score=0.6501, divergence=0.1192, diversity=1.0618, num_succ=7, num_remain=26\n",
      "2700-th evaluation: score=0.6517, divergence=0.1206, diversity=1.0622, num_succ=7, num_remain=26\n",
      "2800-th evaluation: score=0.6525, divergence=0.1212, diversity=1.0626, num_succ=7, num_remain=25\n",
      "2900-th evaluation: score=0.6536, divergence=0.1223, diversity=1.0626, num_succ=7, num_remain=25\n",
      "3000-th evaluation: score=0.6541, divergence=0.1227, diversity=1.0628, num_succ=7, num_remain=25\n",
      "3100-th evaluation: score=0.6552, divergence=0.1235, diversity=1.0633, num_succ=7, num_remain=27\n",
      "3200-th evaluation: score=0.6559, divergence=0.1242, diversity=1.0635, num_succ=7, num_remain=26\n",
      "3300-th evaluation: score=0.6574, divergence=0.1254, diversity=1.0640, num_succ=8, num_remain=27\n",
      "3400-th evaluation: score=0.6580, divergence=0.1259, diversity=1.0643, num_succ=8, num_remain=25\n",
      "3500-th evaluation: score=0.6587, divergence=0.1264, diversity=1.0645, num_succ=8, num_remain=24\n",
      "3600-th evaluation: score=0.6598, divergence=0.1275, diversity=1.0646, num_succ=8, num_remain=24\n",
      "3700-th evaluation: score=0.6602, divergence=0.1278, diversity=1.0649, num_succ=8, num_remain=23\n",
      "3800-th evaluation: score=0.6606, divergence=0.1280, diversity=1.0652, num_succ=8, num_remain=24\n",
      "3900-th evaluation: score=0.6614, divergence=0.1288, diversity=1.0651, num_succ=8, num_remain=23\n",
      "4000-th evaluation: score=0.6617, divergence=0.1290, diversity=1.0654, num_succ=8, num_remain=23\n",
      "4100-th evaluation: score=0.6621, divergence=0.1292, diversity=1.0657, num_succ=8, num_remain=23\n",
      "4200-th evaluation: score=0.6624, divergence=0.1294, diversity=1.0659, num_succ=8, num_remain=23\n",
      "4300-th evaluation: score=0.6627, divergence=0.1296, diversity=1.0661, num_succ=8, num_remain=23\n",
      "4400-th evaluation: score=0.6630, divergence=0.1299, diversity=1.0663, num_succ=8, num_remain=23\n",
      "4500-th evaluation: score=0.6633, divergence=0.1300, diversity=1.0666, num_succ=8, num_remain=23\n",
      "4600-th evaluation: score=0.6635, divergence=0.1302, diversity=1.0666, num_succ=8, num_remain=23\n",
      "4700-th evaluation: score=0.6636, divergence=0.1303, diversity=1.0666, num_succ=8, num_remain=23\n",
      "4800-th evaluation: score=0.6639, divergence=0.1307, diversity=1.0665, num_succ=8, num_remain=23\n",
      "4900-th evaluation: score=0.6645, divergence=0.1314, diversity=1.0662, num_succ=8, num_remain=23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000-th evaluation: score=0.6647, divergence=0.1316, diversity=1.0662, num_succ=8, num_remain=23\n",
      "5100-th evaluation: score=0.6648, divergence=0.1317, diversity=1.0663, num_succ=8, num_remain=23\n",
      "5200-th evaluation: score=0.6654, divergence=0.1325, diversity=1.0659, num_succ=8, num_remain=23\n",
      "5300-th evaluation: score=0.6666, divergence=0.1336, diversity=1.0660, num_succ=8, num_remain=23\n",
      "5400-th evaluation: score=0.6668, divergence=0.1338, diversity=1.0659, num_succ=8, num_remain=24\n",
      "5500-th evaluation: score=0.6674, divergence=0.1347, diversity=1.0655, num_succ=8, num_remain=31\n",
      "5600-th evaluation: score=0.6681, divergence=0.1353, diversity=1.0655, num_succ=8, num_remain=23\n",
      "5700-th evaluation: score=0.6684, divergence=0.1356, diversity=1.0656, num_succ=8, num_remain=22\n",
      "5800-th evaluation: score=0.6685, divergence=0.1357, diversity=1.0657, num_succ=8, num_remain=22\n",
      "5900-th evaluation: score=0.6688, divergence=0.1360, diversity=1.0657, num_succ=8, num_remain=22\n",
      "6000-th evaluation: score=0.6695, divergence=0.1367, diversity=1.0657, num_succ=8, num_remain=22\n",
      "6100-th evaluation: score=0.6702, divergence=0.1374, diversity=1.0657, num_succ=8, num_remain=23\n",
      "6200-th evaluation: score=0.6709, divergence=0.1381, diversity=1.0655, num_succ=8, num_remain=22\n",
      "6300-th evaluation: score=0.6716, divergence=0.1389, diversity=1.0654, num_succ=8, num_remain=23\n",
      "6400-th evaluation: score=0.6725, divergence=0.1399, diversity=1.0652, num_succ=8, num_remain=21\n",
      "6500-th evaluation: score=0.6727, divergence=0.1401, diversity=1.0653, num_succ=8, num_remain=21\n",
      "6600-th evaluation: score=0.6729, divergence=0.1402, diversity=1.0655, num_succ=8, num_remain=21\n",
      "6700-th evaluation: score=0.6730, divergence=0.1402, diversity=1.0656, num_succ=8, num_remain=21\n",
      "6800-th evaluation: score=0.6732, divergence=0.1405, diversity=1.0655, num_succ=8, num_remain=22\n",
      "6900-th evaluation: score=0.6734, divergence=0.1406, diversity=1.0656, num_succ=8, num_remain=21\n",
      "7000-th evaluation: score=0.6735, divergence=0.1406, diversity=1.0656, num_succ=8, num_remain=21\n",
      "7100-th evaluation: score=0.6735, divergence=0.1407, diversity=1.0657, num_succ=8, num_remain=21\n",
      "7200-th evaluation: score=0.6738, divergence=0.1409, diversity=1.0658, num_succ=9, num_remain=21\n",
      "7300-th evaluation: score=0.6738, divergence=0.1409, diversity=1.0659, num_succ=9, num_remain=21\n",
      "7400-th evaluation: score=0.6740, divergence=0.1410, diversity=1.0660, num_succ=9, num_remain=21\n",
      "7500-th evaluation: score=0.6740, divergence=0.1410, diversity=1.0661, num_succ=9, num_remain=21\n",
      "7600-th evaluation: score=0.6743, divergence=0.1412, diversity=1.0662, num_succ=9, num_remain=21\n",
      "7700-th evaluation: score=0.6744, divergence=0.1413, diversity=1.0662, num_succ=9, num_remain=21\n",
      "7800-th evaluation: score=0.6744, divergence=0.1413, diversity=1.0663, num_succ=9, num_remain=21\n",
      "7900-th evaluation: score=0.6748, divergence=0.1416, diversity=1.0663, num_succ=9, num_remain=22\n",
      "8000-th evaluation: score=0.6748, divergence=0.1417, diversity=1.0663, num_succ=9, num_remain=21\n",
      "8100-th evaluation: score=0.6749, divergence=0.1417, diversity=1.0664, num_succ=9, num_remain=21\n",
      "8200-th evaluation: score=0.6750, divergence=0.1417, diversity=1.0665, num_succ=9, num_remain=21\n",
      "8300-th evaluation: score=0.6751, divergence=0.1418, diversity=1.0666, num_succ=9, num_remain=21\n",
      "8400-th evaluation: score=0.6752, divergence=0.1419, diversity=1.0667, num_succ=9, num_remain=21\n",
      "8500-th evaluation: score=0.6753, divergence=0.1419, diversity=1.0667, num_succ=9, num_remain=21\n",
      "8600-th evaluation: score=0.6753, divergence=0.1420, diversity=1.0668, num_succ=9, num_remain=21\n",
      "8700-th evaluation: score=0.6754, divergence=0.1421, diversity=1.0667, num_succ=9, num_remain=21\n",
      "8800-th evaluation: score=0.6755, divergence=0.1421, diversity=1.0668, num_succ=9, num_remain=21\n",
      "8900-th evaluation: score=0.6755, divergence=0.1421, diversity=1.0668, num_succ=9, num_remain=21\n",
      "9000-th evaluation: score=0.6756, divergence=0.1422, diversity=1.0669, num_succ=9, num_remain=21\n",
      "9100-th evaluation: score=0.6757, divergence=0.1422, diversity=1.0669, num_succ=9, num_remain=21\n",
      "9200-th evaluation: score=0.6757, divergence=0.1422, diversity=1.0669, num_succ=9, num_remain=22\n",
      "9300-th evaluation: score=0.6758, divergence=0.1423, diversity=1.0670, num_succ=9, num_remain=21\n",
      "9400-th evaluation: score=0.6758, divergence=0.1423, diversity=1.0670, num_succ=9, num_remain=21\n",
      "9500-th evaluation: score=0.6758, divergence=0.1423, diversity=1.0671, num_succ=9, num_remain=21\n",
      "9600-th evaluation: score=0.6759, divergence=0.1423, diversity=1.0671, num_succ=9, num_remain=21\n",
      "9700-th evaluation: score=0.6759, divergence=0.1424, diversity=1.0671, num_succ=9, num_remain=21\n",
      "9800-th evaluation: score=0.6759, divergence=0.1424, diversity=1.0671, num_succ=9, num_remain=21\n",
      "9900-th evaluation: score=0.6760, divergence=0.1424, diversity=1.0671, num_succ=9, num_remain=21\n",
      "[3.72807803e-02 2.13703288e-02 9.78603168e-03 4.23289158e-03\n",
      " 7.85326953e-02 2.30470301e-05 1.68263620e-02 6.38987865e-03\n",
      " 6.82514510e-03 1.02234476e-02 8.54802404e-02 2.51079958e-01\n",
      " 2.37207079e-01 6.86953153e-02 6.10316404e-03 2.07535282e-01\n",
      " 1.40428062e-02 1.21940284e-02 1.23766134e-02 1.97046136e-03\n",
      " 1.83756478e-02 1.64095809e-01 7.89557814e-03 2.35509838e-01\n",
      " 3.37037141e-02 5.80426914e-03 3.84272805e-02 2.90680368e-02\n",
      " 1.49602929e-01 8.87972215e-02 2.62382675e-02 4.36502391e-02\n",
      " 1.73276886e-01 3.92570930e-02 1.72944675e-02 1.39432741e-01\n",
      " 1.23429385e-02 7.31092395e-03 3.19231220e-03 1.64495371e-01\n",
      " 1.91582916e-02 3.02934582e-01 2.00466531e-01 1.15161113e-02\n",
      " 1.49848565e-01 2.28082007e-04 3.90280557e-02 1.00427613e-01\n",
      " 6.54607303e-03 5.38992414e-02 1.72882221e-01 1.08311010e-01\n",
      " 6.32790244e-03 4.72702946e-03 4.26008230e-02 2.53070839e-01\n",
      " 5.98100284e-03 1.58010677e-02 7.60862470e-03 2.61495424e-02\n",
      " 3.71629180e-02 9.47579238e-03 1.37754368e-02 1.83705369e-01\n",
      " 1.89337323e-01 2.02099765e-02 7.62714592e-02 5.51296901e-02\n",
      " 8.61863393e-03 8.99156592e-03 5.52866009e-03 7.69508092e-03\n",
      " 2.31839987e-02 3.81636129e-02 2.56057997e-01 2.22225912e-02\n",
      " 1.13150170e-02 2.03599613e-02 1.73914322e-02 1.92751985e-02\n",
      " 8.24616765e-02 3.14323277e-03 2.52157198e-02 7.54951445e-03\n",
      " 2.46896982e-02 9.25032556e-02 5.20671816e-03 6.97767345e-02\n",
      " 2.42775982e-02 1.17937146e-01 2.84655182e-01 3.66340305e-03\n",
      " 4.62601659e-02 1.70447475e-01 1.84518583e-01 7.09239511e-02\n",
      " 4.80049336e-02 2.43952216e-03 3.05503310e-02 5.94398429e-03]\n",
      "17\t generating inputs for pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "initial_evaluation: score=0.5287, divergence=0.0000, diversity=1.0574, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.5293, divergence=0.0006, diversity=1.0575, num_succ=0, num_remain=87\n",
      " 100-th evaluation: score=0.5466, divergence=0.0181, diversity=1.0571, num_succ=2, num_remain=29\n",
      " 200-th evaluation: score=0.5568, divergence=0.0285, diversity=1.0567, num_succ=4, num_remain=35\n",
      " 300-th evaluation: score=0.5623, divergence=0.0353, diversity=1.0540, num_succ=4, num_remain=31\n",
      " 400-th evaluation: score=0.5665, divergence=0.0407, diversity=1.0517, num_succ=4, num_remain=33\n",
      " 500-th evaluation: score=0.5728, divergence=0.0486, diversity=1.0484, num_succ=5, num_remain=30\n",
      " 600-th evaluation: score=0.5756, divergence=0.0515, diversity=1.0483, num_succ=5, num_remain=32\n",
      " 700-th evaluation: score=0.5783, divergence=0.0543, diversity=1.0481, num_succ=5, num_remain=32\n",
      " 800-th evaluation: score=0.5828, divergence=0.0597, diversity=1.0464, num_succ=5, num_remain=27\n",
      " 900-th evaluation: score=0.5861, divergence=0.0635, diversity=1.0451, num_succ=6, num_remain=29\n",
      "1000-th evaluation: score=0.5895, divergence=0.0676, diversity=1.0439, num_succ=6, num_remain=28\n",
      "1100-th evaluation: score=0.5919, divergence=0.0703, diversity=1.0431, num_succ=6, num_remain=28\n",
      "1200-th evaluation: score=0.5943, divergence=0.0731, diversity=1.0424, num_succ=6, num_remain=29\n",
      "1300-th evaluation: score=0.5961, divergence=0.0752, diversity=1.0418, num_succ=6, num_remain=28\n",
      "1400-th evaluation: score=0.5986, divergence=0.0779, diversity=1.0415, num_succ=6, num_remain=26\n",
      "1500-th evaluation: score=0.6019, divergence=0.0814, diversity=1.0410, num_succ=6, num_remain=24\n",
      "1600-th evaluation: score=0.6041, divergence=0.0837, diversity=1.0407, num_succ=6, num_remain=23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700-th evaluation: score=0.6060, divergence=0.0862, diversity=1.0395, num_succ=6, num_remain=24\n",
      "1800-th evaluation: score=0.6076, divergence=0.0884, diversity=1.0384, num_succ=6, num_remain=25\n",
      "1900-th evaluation: score=0.6094, divergence=0.0901, diversity=1.0386, num_succ=7, num_remain=20\n",
      "2000-th evaluation: score=0.6111, divergence=0.0917, diversity=1.0389, num_succ=7, num_remain=22\n",
      "2100-th evaluation: score=0.6138, divergence=0.0949, diversity=1.0377, num_succ=8, num_remain=23\n",
      "2200-th evaluation: score=0.6154, divergence=0.0967, diversity=1.0375, num_succ=8, num_remain=25\n",
      "2300-th evaluation: score=0.6169, divergence=0.0981, diversity=1.0376, num_succ=9, num_remain=24\n",
      "2400-th evaluation: score=0.6178, divergence=0.0988, diversity=1.0379, num_succ=9, num_remain=21\n",
      "2500-th evaluation: score=0.6188, divergence=0.0996, diversity=1.0384, num_succ=9, num_remain=20\n",
      "2600-th evaluation: score=0.6200, divergence=0.1009, diversity=1.0382, num_succ=9, num_remain=20\n",
      "2700-th evaluation: score=0.6208, divergence=0.1017, diversity=1.0380, num_succ=9, num_remain=18\n",
      "2800-th evaluation: score=0.6220, divergence=0.1027, diversity=1.0385, num_succ=9, num_remain=18\n",
      "2900-th evaluation: score=0.6231, divergence=0.1038, diversity=1.0385, num_succ=9, num_remain=20\n",
      "3000-th evaluation: score=0.6239, divergence=0.1047, diversity=1.0383, num_succ=9, num_remain=18\n",
      "3100-th evaluation: score=0.6245, divergence=0.1053, diversity=1.0384, num_succ=9, num_remain=16\n",
      "3200-th evaluation: score=0.6251, divergence=0.1058, diversity=1.0385, num_succ=9, num_remain=16\n",
      "3300-th evaluation: score=0.6254, divergence=0.1060, diversity=1.0388, num_succ=9, num_remain=16\n",
      "3400-th evaluation: score=0.6257, divergence=0.1062, diversity=1.0390, num_succ=9, num_remain=16\n",
      "3500-th evaluation: score=0.6263, divergence=0.1067, diversity=1.0392, num_succ=9, num_remain=16\n",
      "3600-th evaluation: score=0.6266, divergence=0.1070, diversity=1.0391, num_succ=9, num_remain=16\n",
      "3700-th evaluation: score=0.6270, divergence=0.1074, diversity=1.0391, num_succ=9, num_remain=16\n",
      "3800-th evaluation: score=0.6273, divergence=0.1078, diversity=1.0391, num_succ=9, num_remain=16\n",
      "3900-th evaluation: score=0.6275, divergence=0.1081, diversity=1.0387, num_succ=9, num_remain=16\n",
      "4000-th evaluation: score=0.6285, divergence=0.1096, diversity=1.0377, num_succ=9, num_remain=20\n",
      "4100-th evaluation: score=0.6302, divergence=0.1123, diversity=1.0358, num_succ=11, num_remain=19\n",
      "4200-th evaluation: score=0.6337, divergence=0.1166, diversity=1.0344, num_succ=11, num_remain=20\n",
      "4300-th evaluation: score=0.6355, divergence=0.1187, diversity=1.0335, num_succ=11, num_remain=19\n",
      "4400-th evaluation: score=0.6371, divergence=0.1213, diversity=1.0317, num_succ=11, num_remain=24\n",
      "4500-th evaluation: score=0.6405, divergence=0.1259, diversity=1.0290, num_succ=11, num_remain=24\n",
      "4600-th evaluation: score=0.6421, divergence=0.1283, diversity=1.0276, num_succ=11, num_remain=24\n",
      "4700-th evaluation: score=0.6443, divergence=0.1311, diversity=1.0265, num_succ=11, num_remain=24\n",
      "4800-th evaluation: score=0.6458, divergence=0.1331, diversity=1.0253, num_succ=11, num_remain=24\n",
      "4900-th evaluation: score=0.6486, divergence=0.1365, diversity=1.0243, num_succ=11, num_remain=23\n",
      "5000-th evaluation: score=0.6512, divergence=0.1391, diversity=1.0243, num_succ=11, num_remain=20\n",
      "5100-th evaluation: score=0.6522, divergence=0.1406, diversity=1.0233, num_succ=11, num_remain=21\n",
      "5200-th evaluation: score=0.6530, divergence=0.1412, diversity=1.0236, num_succ=11, num_remain=20\n",
      "5300-th evaluation: score=0.6537, divergence=0.1419, diversity=1.0236, num_succ=11, num_remain=18\n",
      "5400-th evaluation: score=0.6542, divergence=0.1422, diversity=1.0240, num_succ=11, num_remain=19\n",
      "5500-th evaluation: score=0.6546, divergence=0.1426, diversity=1.0240, num_succ=11, num_remain=18\n",
      "5600-th evaluation: score=0.6555, divergence=0.1435, diversity=1.0242, num_succ=11, num_remain=18\n",
      "5700-th evaluation: score=0.6568, divergence=0.1446, diversity=1.0243, num_succ=11, num_remain=19\n",
      "5800-th evaluation: score=0.6572, divergence=0.1449, diversity=1.0246, num_succ=11, num_remain=18\n",
      "5900-th evaluation: score=0.6575, divergence=0.1451, diversity=1.0248, num_succ=11, num_remain=18\n",
      "6000-th evaluation: score=0.6585, divergence=0.1458, diversity=1.0253, num_succ=11, num_remain=18\n",
      "6100-th evaluation: score=0.6588, divergence=0.1461, diversity=1.0255, num_succ=11, num_remain=17\n",
      "6200-th evaluation: score=0.6591, divergence=0.1463, diversity=1.0255, num_succ=11, num_remain=17\n",
      "6300-th evaluation: score=0.6593, divergence=0.1465, diversity=1.0256, num_succ=11, num_remain=17\n",
      "6400-th evaluation: score=0.6595, divergence=0.1467, diversity=1.0256, num_succ=11, num_remain=17\n",
      "6500-th evaluation: score=0.6597, divergence=0.1468, diversity=1.0257, num_succ=11, num_remain=17\n",
      "6600-th evaluation: score=0.6599, divergence=0.1469, diversity=1.0259, num_succ=11, num_remain=17\n",
      "6700-th evaluation: score=0.6601, divergence=0.1472, diversity=1.0258, num_succ=11, num_remain=17\n",
      "6800-th evaluation: score=0.6603, divergence=0.1473, diversity=1.0259, num_succ=11, num_remain=17\n",
      "6900-th evaluation: score=0.6605, divergence=0.1475, diversity=1.0258, num_succ=11, num_remain=17\n",
      "7000-th evaluation: score=0.6606, divergence=0.1476, diversity=1.0260, num_succ=11, num_remain=16\n",
      "7100-th evaluation: score=0.6608, divergence=0.1479, diversity=1.0259, num_succ=11, num_remain=18\n",
      "7200-th evaluation: score=0.6609, divergence=0.1480, diversity=1.0258, num_succ=11, num_remain=16\n",
      "7300-th evaluation: score=0.6613, divergence=0.1484, diversity=1.0257, num_succ=11, num_remain=18\n",
      "7400-th evaluation: score=0.6616, divergence=0.1487, diversity=1.0258, num_succ=11, num_remain=17\n",
      "7500-th evaluation: score=0.6618, divergence=0.1490, diversity=1.0256, num_succ=11, num_remain=17\n",
      "7600-th evaluation: score=0.6621, divergence=0.1493, diversity=1.0255, num_succ=11, num_remain=17\n",
      "7700-th evaluation: score=0.6624, divergence=0.1502, diversity=1.0246, num_succ=11, num_remain=16\n",
      "7800-th evaluation: score=0.6626, divergence=0.1503, diversity=1.0247, num_succ=11, num_remain=16\n",
      "7900-th evaluation: score=0.6629, divergence=0.1505, diversity=1.0248, num_succ=11, num_remain=17\n",
      "8000-th evaluation: score=0.6630, divergence=0.1506, diversity=1.0248, num_succ=11, num_remain=16\n",
      "8100-th evaluation: score=0.6631, divergence=0.1506, diversity=1.0249, num_succ=11, num_remain=16\n",
      "8200-th evaluation: score=0.6633, divergence=0.1509, diversity=1.0248, num_succ=11, num_remain=16\n",
      "8300-th evaluation: score=0.6633, divergence=0.1509, diversity=1.0248, num_succ=11, num_remain=16\n",
      "8400-th evaluation: score=0.6634, divergence=0.1510, diversity=1.0248, num_succ=11, num_remain=16\n",
      "8500-th evaluation: score=0.6635, divergence=0.1510, diversity=1.0249, num_succ=11, num_remain=16\n",
      "8600-th evaluation: score=0.6636, divergence=0.1511, diversity=1.0248, num_succ=11, num_remain=16\n",
      "8700-th evaluation: score=0.6636, divergence=0.1512, diversity=1.0249, num_succ=11, num_remain=16\n",
      "8800-th evaluation: score=0.6637, divergence=0.1512, diversity=1.0249, num_succ=11, num_remain=16\n",
      "8900-th evaluation: score=0.6637, divergence=0.1512, diversity=1.0250, num_succ=11, num_remain=16\n",
      "9000-th evaluation: score=0.6637, divergence=0.1513, diversity=1.0249, num_succ=11, num_remain=16\n",
      "9100-th evaluation: score=0.6638, divergence=0.1513, diversity=1.0250, num_succ=11, num_remain=16\n",
      "9200-th evaluation: score=0.6638, divergence=0.1513, diversity=1.0250, num_succ=11, num_remain=16\n",
      "9300-th evaluation: score=0.6638, divergence=0.1513, diversity=1.0250, num_succ=11, num_remain=16\n",
      "9400-th evaluation: score=0.6639, divergence=0.1514, diversity=1.0250, num_succ=11, num_remain=15\n",
      "9500-th evaluation: score=0.6639, divergence=0.1514, diversity=1.0251, num_succ=11, num_remain=16\n",
      "9600-th evaluation: score=0.6639, divergence=0.1514, diversity=1.0251, num_succ=11, num_remain=16\n",
      "9700-th evaluation: score=0.6640, divergence=0.1514, diversity=1.0251, num_succ=11, num_remain=15\n",
      "9800-th evaluation: score=0.6640, divergence=0.1514, diversity=1.0251, num_succ=11, num_remain=15\n",
      "9900-th evaluation: score=0.6640, divergence=0.1514, diversity=1.0252, num_succ=11, num_remain=15\n",
      "[1.31375950e-02 6.95851658e-03 6.02823161e-05 9.86735934e-02\n",
      " 8.52924239e-02 2.73534066e-02 6.71538418e-02 8.28933570e-03\n",
      " 1.36478693e-01 1.21438302e-01 2.44721752e-03 3.50474426e-03\n",
      " 1.38574092e-03 1.21593475e-02 1.24734739e-01 3.41826124e-02\n",
      " 7.47886300e-02 1.10066481e-02 7.00204023e-02 2.69650982e-02\n",
      " 1.40459677e-02 5.63945299e-03 3.67139054e-03 2.94872595e-01\n",
      " 1.45764803e-01 8.62027715e-03 8.72413013e-02 1.04124958e-01\n",
      " 2.25595424e-01 2.24793791e-03 1.64569124e-01 5.04216903e-02\n",
      " 1.02447022e-01 5.80678579e-02 1.68085624e-01 1.63291816e-01\n",
      " 4.56687917e-03 2.33269898e-01 1.01814387e-01 1.62088897e-02\n",
      " 6.50195092e-02 4.14486534e-02 1.38710926e-01 2.08195935e-02\n",
      " 4.36195692e-03 1.51280400e-02 2.81963245e-03 4.31231100e-02\n",
      " 6.30904751e-03 2.04848902e-02 2.20632054e-01 2.93286164e-03\n",
      " 1.08606915e-02 1.37533963e-02 1.35124551e-02 4.42336776e-03\n",
      " 3.07031660e-02 2.55532412e-01 2.84271089e-02 8.16382435e-02\n",
      " 1.19850837e-02 1.07713966e-01 1.61623378e-02 1.39186883e-01\n",
      " 2.88235239e-01 2.86392726e-03 2.73254754e-02 1.04168030e-02\n",
      " 1.76386433e-02 3.87904008e-03 2.90067031e-02 8.59458428e-02\n",
      " 5.43095705e-03 1.51372563e-02 5.10659869e-03 9.16949513e-03\n",
      " 1.02396238e-02 2.75106484e-02 2.18353646e-02 1.12274450e-01\n",
      " 1.10745856e-01 1.09941308e-01 7.14265508e-04 9.51805106e-02\n",
      " 5.20920089e-03 1.33337712e-02 2.17954899e-01 7.15036670e-03\n",
      " 1.25766592e-01 4.60601095e-02 2.07713488e-02 8.06607483e-03\n",
      " 8.60419560e-03 3.38182853e-03 4.08712692e-01 5.41341781e-02\n",
      " 1.68442522e-02 1.03649000e-01 6.69449697e-02 4.09515359e-03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "initial_evaluation: score=0.6719, divergence=0.0000, diversity=1.3438, num_succ=0, num_remain=9\n",
      "   0-th evaluation: score=0.6720, divergence=0.0001, diversity=1.3437, num_succ=0, num_remain=94\n",
      " 100-th evaluation: score=0.6770, divergence=0.0076, diversity=1.3388, num_succ=0, num_remain=32\n",
      " 200-th evaluation: score=0.6778, divergence=0.0094, diversity=1.3368, num_succ=0, num_remain=32\n",
      " 300-th evaluation: score=0.6786, divergence=0.0117, diversity=1.3339, num_succ=0, num_remain=37\n",
      " 400-th evaluation: score=0.6795, divergence=0.0136, diversity=1.3318, num_succ=0, num_remain=33\n",
      " 500-th evaluation: score=0.6805, divergence=0.0161, diversity=1.3286, num_succ=0, num_remain=35\n",
      " 600-th evaluation: score=0.6809, divergence=0.0172, diversity=1.3274, num_succ=0, num_remain=27\n",
      " 700-th evaluation: score=0.6812, divergence=0.0183, diversity=1.3258, num_succ=0, num_remain=30\n",
      " 800-th evaluation: score=0.6820, divergence=0.0211, diversity=1.3220, num_succ=0, num_remain=27\n",
      " 900-th evaluation: score=0.6832, divergence=0.0233, diversity=1.3197, num_succ=0, num_remain=27\n",
      "1000-th evaluation: score=0.6841, divergence=0.0263, diversity=1.3158, num_succ=0, num_remain=27\n",
      "1100-th evaluation: score=0.6854, divergence=0.0298, diversity=1.3113, num_succ=0, num_remain=23\n",
      "1200-th evaluation: score=0.6874, divergence=0.0344, diversity=1.3060, num_succ=0, num_remain=39\n",
      "1300-th evaluation: score=0.6908, divergence=0.0427, diversity=1.2963, num_succ=0, num_remain=41\n",
      "1400-th evaluation: score=0.6933, divergence=0.0483, diversity=1.2899, num_succ=0, num_remain=33\n",
      "1500-th evaluation: score=0.6953, divergence=0.0541, diversity=1.2825, num_succ=0, num_remain=32\n",
      "1600-th evaluation: score=0.6976, divergence=0.0605, diversity=1.2743, num_succ=0, num_remain=33\n",
      "1700-th evaluation: score=0.7002, divergence=0.0666, diversity=1.2673, num_succ=0, num_remain=27\n",
      "1800-th evaluation: score=0.7020, divergence=0.0712, diversity=1.2615, num_succ=0, num_remain=23\n",
      "1900-th evaluation: score=0.7027, divergence=0.0726, diversity=1.2603, num_succ=0, num_remain=21\n",
      "2000-th evaluation: score=0.7037, divergence=0.0753, diversity=1.2569, num_succ=0, num_remain=23\n",
      "2100-th evaluation: score=0.7049, divergence=0.0781, diversity=1.2535, num_succ=0, num_remain=21\n",
      "2200-th evaluation: score=0.7056, divergence=0.0800, diversity=1.2513, num_succ=0, num_remain=20\n",
      "2300-th evaluation: score=0.7077, divergence=0.0853, diversity=1.2448, num_succ=0, num_remain=32\n",
      "2400-th evaluation: score=0.7098, divergence=0.0904, diversity=1.2389, num_succ=0, num_remain=19\n",
      "2500-th evaluation: score=0.7112, divergence=0.0940, diversity=1.2345, num_succ=0, num_remain=24\n",
      "2600-th evaluation: score=0.7148, divergence=0.1029, diversity=1.2239, num_succ=0, num_remain=38\n",
      "2700-th evaluation: score=0.7173, divergence=0.1098, diversity=1.2151, num_succ=0, num_remain=27\n",
      "2800-th evaluation: score=0.7219, divergence=0.1204, diversity=1.2031, num_succ=0, num_remain=29\n",
      "2900-th evaluation: score=0.7262, divergence=0.1312, diversity=1.1899, num_succ=0, num_remain=29\n",
      "3000-th evaluation: score=0.7295, divergence=0.1386, diversity=1.1819, num_succ=0, num_remain=29\n",
      "3100-th evaluation: score=0.7319, divergence=0.1435, diversity=1.1768, num_succ=0, num_remain=30\n",
      "3200-th evaluation: score=0.7353, divergence=0.1520, diversity=1.1665, num_succ=0, num_remain=32\n",
      "3300-th evaluation: score=0.7380, divergence=0.1590, diversity=1.1579, num_succ=0, num_remain=22\n",
      "3400-th evaluation: score=0.7408, divergence=0.1660, diversity=1.1495, num_succ=0, num_remain=21\n",
      "3500-th evaluation: score=0.7440, divergence=0.1711, diversity=1.1458, num_succ=0, num_remain=23\n",
      "3600-th evaluation: score=0.7473, divergence=0.1790, diversity=1.1366, num_succ=0, num_remain=24\n",
      "3700-th evaluation: score=0.7505, divergence=0.1873, diversity=1.1265, num_succ=0, num_remain=24\n",
      "3800-th evaluation: score=0.7533, divergence=0.1951, diversity=1.1164, num_succ=0, num_remain=27\n",
      "3900-th evaluation: score=0.7571, divergence=0.2043, diversity=1.1056, num_succ=0, num_remain=24\n",
      "4000-th evaluation: score=0.7617, divergence=0.2152, diversity=1.0929, num_succ=0, num_remain=22\n",
      "4100-th evaluation: score=0.7638, divergence=0.2195, diversity=1.0885, num_succ=0, num_remain=15\n",
      "4200-th evaluation: score=0.7661, divergence=0.2255, diversity=1.0812, num_succ=0, num_remain=19\n",
      "4300-th evaluation: score=0.7700, divergence=0.2342, diversity=1.0716, num_succ=0, num_remain=24\n",
      "4400-th evaluation: score=0.7718, divergence=0.2387, diversity=1.0662, num_succ=0, num_remain=23\n",
      "4500-th evaluation: score=0.7744, divergence=0.2444, diversity=1.0599, num_succ=0, num_remain=20\n",
      "4600-th evaluation: score=0.7769, divergence=0.2507, diversity=1.0525, num_succ=0, num_remain=22\n",
      "4700-th evaluation: score=0.7804, divergence=0.2596, diversity=1.0417, num_succ=0, num_remain=18\n",
      "4800-th evaluation: score=0.7831, divergence=0.2654, diversity=1.0356, num_succ=0, num_remain=20\n",
      "4900-th evaluation: score=0.7855, divergence=0.2714, diversity=1.0282, num_succ=0, num_remain=21\n",
      "5000-th evaluation: score=0.7890, divergence=0.2795, diversity=1.0191, num_succ=0, num_remain=24\n",
      "5100-th evaluation: score=0.7930, divergence=0.2896, diversity=1.0067, num_succ=0, num_remain=28\n",
      "5200-th evaluation: score=0.7959, divergence=0.2958, diversity=1.0003, num_succ=0, num_remain=24\n",
      "5300-th evaluation: score=0.7990, divergence=0.3028, diversity=0.9924, num_succ=0, num_remain=22\n",
      "5400-th evaluation: score=0.8014, divergence=0.3083, diversity=0.9862, num_succ=0, num_remain=22\n",
      "5500-th evaluation: score=0.8054, divergence=0.3169, diversity=0.9770, num_succ=0, num_remain=26\n",
      "5600-th evaluation: score=0.8086, divergence=0.3242, diversity=0.9689, num_succ=0, num_remain=26\n",
      "5700-th evaluation: score=0.8101, divergence=0.3286, diversity=0.9631, num_succ=0, num_remain=24\n",
      "5800-th evaluation: score=0.8121, divergence=0.3320, diversity=0.9603, num_succ=0, num_remain=19\n",
      "5900-th evaluation: score=0.8136, divergence=0.3357, diversity=0.9558, num_succ=0, num_remain=21\n",
      "6000-th evaluation: score=0.8159, divergence=0.3422, diversity=0.9474, num_succ=0, num_remain=30\n",
      "6100-th evaluation: score=0.8197, divergence=0.3506, diversity=0.9381, num_succ=0, num_remain=24\n",
      "6200-th evaluation: score=0.8225, divergence=0.3568, diversity=0.9314, num_succ=0, num_remain=30\n",
      "6300-th evaluation: score=0.8260, divergence=0.3656, diversity=0.9208, num_succ=0, num_remain=36\n",
      "6400-th evaluation: score=0.8304, divergence=0.3756, diversity=0.9096, num_succ=0, num_remain=34\n",
      "6500-th evaluation: score=0.8360, divergence=0.3867, diversity=0.8986, num_succ=0, num_remain=30\n",
      "6600-th evaluation: score=0.8384, divergence=0.3919, diversity=0.8930, num_succ=0, num_remain=29\n",
      "6700-th evaluation: score=0.8408, divergence=0.3976, diversity=0.8865, num_succ=0, num_remain=33\n",
      "6800-th evaluation: score=0.8433, divergence=0.4028, diversity=0.8810, num_succ=1, num_remain=27\n",
      "6900-th evaluation: score=0.8457, divergence=0.4086, diversity=0.8742, num_succ=1, num_remain=31\n",
      "7000-th evaluation: score=0.8476, divergence=0.4136, diversity=0.8680, num_succ=1, num_remain=26\n",
      "7100-th evaluation: score=0.8489, divergence=0.4160, diversity=0.8658, num_succ=1, num_remain=26\n",
      "7200-th evaluation: score=0.8499, divergence=0.4182, diversity=0.8633, num_succ=1, num_remain=29\n",
      "7300-th evaluation: score=0.8508, divergence=0.4192, diversity=0.8631, num_succ=1, num_remain=27\n",
      "7400-th evaluation: score=0.8525, divergence=0.4229, diversity=0.8591, num_succ=1, num_remain=23\n",
      "7500-th evaluation: score=0.8544, divergence=0.4264, diversity=0.8558, num_succ=1, num_remain=22\n",
      "7600-th evaluation: score=0.8555, divergence=0.4280, diversity=0.8552, num_succ=1, num_remain=23\n",
      "7700-th evaluation: score=0.8577, divergence=0.4328, diversity=0.8497, num_succ=1, num_remain=24\n",
      "7800-th evaluation: score=0.8592, divergence=0.4355, diversity=0.8475, num_succ=1, num_remain=24\n",
      "7900-th evaluation: score=0.8612, divergence=0.4391, diversity=0.8442, num_succ=1, num_remain=28\n",
      "8000-th evaluation: score=0.8629, divergence=0.4432, diversity=0.8395, num_succ=1, num_remain=23\n",
      "8100-th evaluation: score=0.8644, divergence=0.4464, diversity=0.8360, num_succ=1, num_remain=23\n",
      "8200-th evaluation: score=0.8661, divergence=0.4496, diversity=0.8331, num_succ=1, num_remain=24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8300-th evaluation: score=0.8680, divergence=0.4534, diversity=0.8291, num_succ=1, num_remain=21\n",
      "8400-th evaluation: score=0.8695, divergence=0.4566, diversity=0.8257, num_succ=1, num_remain=22\n",
      "8500-th evaluation: score=0.8710, divergence=0.4595, diversity=0.8230, num_succ=1, num_remain=22\n",
      "8600-th evaluation: score=0.8724, divergence=0.4623, diversity=0.8200, num_succ=2, num_remain=25\n",
      "8700-th evaluation: score=0.8744, divergence=0.4660, diversity=0.8167, num_succ=2, num_remain=24\n",
      "8800-th evaluation: score=0.8768, divergence=0.4711, diversity=0.8114, num_succ=2, num_remain=26\n",
      "8900-th evaluation: score=0.8784, divergence=0.4739, diversity=0.8091, num_succ=2, num_remain=22\n",
      "9000-th evaluation: score=0.8800, divergence=0.4765, diversity=0.8070, num_succ=2, num_remain=22\n",
      "9100-th evaluation: score=0.8819, divergence=0.4808, diversity=0.8022, num_succ=2, num_remain=19\n",
      "9200-th evaluation: score=0.8842, divergence=0.4856, diversity=0.7973, num_succ=2, num_remain=19\n",
      "9300-th evaluation: score=0.8856, divergence=0.4871, diversity=0.7968, num_succ=2, num_remain=18\n",
      "9400-th evaluation: score=0.8876, divergence=0.4904, diversity=0.7942, num_succ=2, num_remain=24\n",
      "9500-th evaluation: score=0.8889, divergence=0.4934, diversity=0.7911, num_succ=2, num_remain=22\n",
      "9600-th evaluation: score=0.8909, divergence=0.4971, diversity=0.7875, num_succ=2, num_remain=23\n",
      "9700-th evaluation: score=0.8920, divergence=0.4992, diversity=0.7857, num_succ=2, num_remain=19\n",
      "9800-th evaluation: score=0.8932, divergence=0.5015, diversity=0.7834, num_succ=2, num_remain=24\n",
      "9900-th evaluation: score=0.8953, divergence=0.5048, diversity=0.7810, num_succ=2, num_remain=21\n",
      "[0.09242287 0.14066676 0.10073681 0.03425282 0.11997336 0.04283686\n",
      " 0.05820986 0.0914989  0.07178769 0.08142314 0.06411453 0.14669188\n",
      " 0.05725897 0.25418797 0.06594442 0.15292484 0.02710587 0.06736888\n",
      " 0.09630246 0.04609519 0.05264065 0.0990772  0.09143228 0.07672272\n",
      " 0.16220386 0.09974007 0.14356762 0.07402429 0.03328021 0.16308762\n",
      " 0.14918385 0.07152114 0.05942829 0.04431381 0.12833666 0.13789708\n",
      " 0.03798878 0.08907946 0.11737896 0.03662772 0.02147476 0.0995938\n",
      " 0.05880123 0.06421539 0.08194007 0.02331245 0.03552929 0.12365512\n",
      " 0.08669761 0.11262    0.06186839 0.08438127 0.06810576 0.15693064\n",
      " 0.10507444 0.1202714  0.09270624 0.03054102 0.15697551 0.1301673\n",
      " 0.10473402 0.03556417 0.03465186 0.06750757 0.07441787 0.15888465\n",
      " 0.14457079 0.07374438 0.05003128 0.05430688 0.08859935 0.07518377\n",
      " 0.04492874 0.18190908 0.07170095 0.07572952 0.08954803 0.06028006\n",
      " 0.05912219 0.06901029 0.1300654  0.11117525 0.07640647 0.1181335\n",
      " 0.08185169 0.14547479 0.11075911 0.20819633 0.11513051 0.06392607\n",
      " 0.0687061  0.1172745  0.04042568 0.07626355 0.04130865 0.09466175\n",
      " 0.05342873 0.16945965 0.11710748 0.04879801]\n",
      "43\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "initial_evaluation: score=0.6623, divergence=0.0000, diversity=1.3246, num_succ=0, num_remain=7\n",
      "   0-th evaluation: score=0.6624, divergence=0.0001, diversity=1.3245, num_succ=0, num_remain=91\n",
      " 100-th evaluation: score=0.6735, divergence=0.0194, diversity=1.3082, num_succ=0, num_remain=47\n",
      " 200-th evaluation: score=0.6763, divergence=0.0269, diversity=1.2988, num_succ=0, num_remain=40\n",
      " 300-th evaluation: score=0.6785, divergence=0.0323, diversity=1.2923, num_succ=0, num_remain=33\n",
      " 400-th evaluation: score=0.6802, divergence=0.0372, diversity=1.2860, num_succ=0, num_remain=33\n",
      " 500-th evaluation: score=0.6846, divergence=0.0500, diversity=1.2692, num_succ=0, num_remain=38\n",
      " 600-th evaluation: score=0.6919, divergence=0.0695, diversity=1.2448, num_succ=0, num_remain=40\n",
      " 700-th evaluation: score=0.7004, divergence=0.0907, diversity=1.2192, num_succ=0, num_remain=41\n",
      " 800-th evaluation: score=0.7134, divergence=0.1228, diversity=1.1812, num_succ=0, num_remain=40\n",
      " 900-th evaluation: score=0.7228, divergence=0.1470, diversity=1.1517, num_succ=0, num_remain=35\n",
      "1000-th evaluation: score=0.7334, divergence=0.1749, diversity=1.1170, num_succ=0, num_remain=33\n",
      "1100-th evaluation: score=0.7465, divergence=0.2045, diversity=1.0839, num_succ=0, num_remain=33\n",
      "1200-th evaluation: score=0.7635, divergence=0.2411, diversity=1.0449, num_succ=0, num_remain=33\n",
      "1300-th evaluation: score=0.7719, divergence=0.2591, diversity=1.0256, num_succ=0, num_remain=29\n",
      "1400-th evaluation: score=0.7838, divergence=0.2855, diversity=0.9967, num_succ=0, num_remain=33\n",
      "1500-th evaluation: score=0.7990, divergence=0.3196, diversity=0.9587, num_succ=0, num_remain=33\n",
      "1600-th evaluation: score=0.8134, divergence=0.3508, diversity=0.9252, num_succ=0, num_remain=27\n",
      "1700-th evaluation: score=0.8287, divergence=0.3827, diversity=0.8920, num_succ=0, num_remain=35\n",
      "1800-th evaluation: score=0.8455, divergence=0.4156, diversity=0.8598, num_succ=2, num_remain=35\n",
      "1900-th evaluation: score=0.8638, divergence=0.4518, diversity=0.8239, num_succ=2, num_remain=34\n",
      "2000-th evaluation: score=0.8801, divergence=0.4812, diversity=0.7978, num_succ=4, num_remain=27\n",
      "2100-th evaluation: score=0.8930, divergence=0.5049, diversity=0.7762, num_succ=6, num_remain=20\n",
      "2200-th evaluation: score=0.9018, divergence=0.5218, diversity=0.7600, num_succ=7, num_remain=22\n",
      "2300-th evaluation: score=0.9087, divergence=0.5350, diversity=0.7474, num_succ=9, num_remain=18\n",
      "2400-th evaluation: score=0.9162, divergence=0.5491, diversity=0.7342, num_succ=11, num_remain=19\n",
      "2500-th evaluation: score=0.9221, divergence=0.5612, diversity=0.7218, num_succ=11, num_remain=16\n",
      "2600-th evaluation: score=0.9282, divergence=0.5729, diversity=0.7107, num_succ=12, num_remain=15\n",
      "2700-th evaluation: score=0.9343, divergence=0.5840, diversity=0.7006, num_succ=12, num_remain=18\n",
      "2800-th evaluation: score=0.9395, divergence=0.5934, diversity=0.6922, num_succ=13, num_remain=17\n",
      "2900-th evaluation: score=0.9464, divergence=0.6053, diversity=0.6823, num_succ=15, num_remain=12\n",
      "3000-th evaluation: score=0.9487, divergence=0.6097, diversity=0.6781, num_succ=15, num_remain=9\n",
      "3100-th evaluation: score=0.9506, divergence=0.6125, diversity=0.6761, num_succ=15, num_remain=8\n",
      "3200-th evaluation: score=0.9543, divergence=0.6190, diversity=0.6706, num_succ=15, num_remain=11\n",
      "3300-th evaluation: score=0.9559, divergence=0.6218, diversity=0.6683, num_succ=15, num_remain=8\n",
      "3400-th evaluation: score=0.9584, divergence=0.6259, diversity=0.6650, num_succ=16, num_remain=9\n",
      "3500-th evaluation: score=0.9606, divergence=0.6295, diversity=0.6622, num_succ=16, num_remain=8\n",
      "3600-th evaluation: score=0.9626, divergence=0.6329, diversity=0.6593, num_succ=16, num_remain=8\n",
      "3700-th evaluation: score=0.9648, divergence=0.6372, diversity=0.6552, num_succ=16, num_remain=8\n",
      "3800-th evaluation: score=0.9670, divergence=0.6411, diversity=0.6517, num_succ=16, num_remain=8\n",
      "3900-th evaluation: score=0.9719, divergence=0.6485, diversity=0.6467, num_succ=17, num_remain=7\n",
      "4000-th evaluation: score=0.9750, divergence=0.6532, diversity=0.6436, num_succ=18, num_remain=7\n",
      "4100-th evaluation: score=0.9773, divergence=0.6569, diversity=0.6409, num_succ=18, num_remain=8\n",
      "4200-th evaluation: score=0.9789, divergence=0.6597, diversity=0.6386, num_succ=18, num_remain=8\n",
      "4300-th evaluation: score=0.9809, divergence=0.6625, diversity=0.6368, num_succ=18, num_remain=5\n",
      "4400-th evaluation: score=0.9833, divergence=0.6660, diversity=0.6347, num_succ=21, num_remain=5\n",
      "4500-th evaluation: score=0.9846, divergence=0.6676, diversity=0.6339, num_succ=22, num_remain=4\n",
      "4600-th evaluation: score=0.9858, divergence=0.6693, diversity=0.6330, num_succ=22, num_remain=6\n",
      "4700-th evaluation: score=0.9870, divergence=0.6708, diversity=0.6323, num_succ=22, num_remain=6\n",
      "4800-th evaluation: score=0.9882, divergence=0.6726, diversity=0.6312, num_succ=22, num_remain=3\n",
      "4900-th evaluation: score=0.9889, divergence=0.6733, diversity=0.6311, num_succ=22, num_remain=3\n",
      "5000-th evaluation: score=0.9892, divergence=0.6737, diversity=0.6310, num_succ=22, num_remain=4\n",
      "5100-th evaluation: score=0.9895, divergence=0.6740, diversity=0.6309, num_succ=22, num_remain=3\n",
      "5200-th evaluation: score=0.9897, divergence=0.6744, diversity=0.6306, num_succ=22, num_remain=3\n",
      "5300-th evaluation: score=0.9901, divergence=0.6748, diversity=0.6305, num_succ=22, num_remain=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400-th evaluation: score=0.9907, divergence=0.6756, diversity=0.6302, num_succ=22, num_remain=3\n",
      "5500-th evaluation: score=0.9910, divergence=0.6763, diversity=0.6295, num_succ=22, num_remain=3\n",
      "5600-th evaluation: score=0.9912, divergence=0.6766, diversity=0.6292, num_succ=22, num_remain=3\n",
      "5700-th evaluation: score=0.9917, divergence=0.6775, diversity=0.6283, num_succ=22, num_remain=5\n",
      "5800-th evaluation: score=0.9925, divergence=0.6789, diversity=0.6273, num_succ=22, num_remain=8\n",
      "5900-th evaluation: score=0.9933, divergence=0.6802, diversity=0.6262, num_succ=23, num_remain=3\n",
      "6000-th evaluation: score=0.9938, divergence=0.6809, diversity=0.6258, num_succ=23, num_remain=3\n",
      "6100-th evaluation: score=0.9958, divergence=0.6838, diversity=0.6240, num_succ=25, num_remain=3\n",
      "6200-th evaluation: score=0.9965, divergence=0.6847, diversity=0.6237, num_succ=25, num_remain=2\n",
      "6300-th evaluation: score=0.9968, divergence=0.6848, diversity=0.6239, num_succ=25, num_remain=2\n",
      "6400-th evaluation: score=0.9971, divergence=0.6851, diversity=0.6241, num_succ=25, num_remain=2\n",
      "6500-th evaluation: score=0.9973, divergence=0.6852, diversity=0.6242, num_succ=25, num_remain=2\n",
      "6600-th evaluation: score=0.9974, divergence=0.6852, diversity=0.6243, num_succ=25, num_remain=2\n",
      "6700-th evaluation: score=0.9976, divergence=0.6855, diversity=0.6243, num_succ=25, num_remain=2\n",
      "6800-th evaluation: score=0.9977, divergence=0.6856, diversity=0.6242, num_succ=25, num_remain=2\n",
      "6900-th evaluation: score=0.9978, divergence=0.6857, diversity=0.6243, num_succ=25, num_remain=2\n",
      "7000-th evaluation: score=0.9983, divergence=0.6864, diversity=0.6239, num_succ=26, num_remain=2\n",
      "7100-th evaluation: score=0.9984, divergence=0.6864, diversity=0.6239, num_succ=26, num_remain=2\n",
      "7200-th evaluation: score=0.9985, divergence=0.6866, diversity=0.6238, num_succ=26, num_remain=2\n",
      "7300-th evaluation: score=0.9986, divergence=0.6867, diversity=0.6237, num_succ=26, num_remain=2\n",
      "7400-th evaluation: score=0.9986, divergence=0.6868, diversity=0.6237, num_succ=26, num_remain=2\n",
      "7500-th evaluation: score=0.9989, divergence=0.6871, diversity=0.6235, num_succ=26, num_remain=2\n",
      "7600-th evaluation: score=0.9990, divergence=0.6872, diversity=0.6235, num_succ=26, num_remain=2\n",
      "7700-th evaluation: score=0.9994, divergence=0.6877, diversity=0.6232, num_succ=26, num_remain=2\n",
      "7800-th evaluation: score=0.9995, divergence=0.6880, diversity=0.6230, num_succ=26, num_remain=2\n",
      "7900-th evaluation: score=0.9995, divergence=0.6880, diversity=0.6230, num_succ=26, num_remain=2\n",
      "8000-th evaluation: score=1.0003, divergence=0.6893, diversity=0.6219, num_succ=27, num_remain=2\n",
      "8100-th evaluation: score=1.0003, divergence=0.6894, diversity=0.6218, num_succ=27, num_remain=2\n",
      "8200-th evaluation: score=1.0004, divergence=0.6897, diversity=0.6216, num_succ=27, num_remain=3\n",
      "8300-th evaluation: score=1.0006, divergence=0.6899, diversity=0.6214, num_succ=28, num_remain=2\n",
      "8400-th evaluation: score=1.0007, divergence=0.6901, diversity=0.6212, num_succ=28, num_remain=2\n",
      "8500-th evaluation: score=1.0011, divergence=0.6908, diversity=0.6205, num_succ=28, num_remain=2\n",
      "8600-th evaluation: score=1.0012, divergence=0.6911, diversity=0.6203, num_succ=28, num_remain=2\n",
      "8700-th evaluation: score=1.0013, divergence=0.6913, diversity=0.6200, num_succ=28, num_remain=2\n",
      "8800-th evaluation: score=1.0022, divergence=0.6925, diversity=0.6194, num_succ=30, num_remain=2\n",
      "8900-th evaluation: score=1.0023, divergence=0.6929, diversity=0.6188, num_succ=30, num_remain=2\n",
      "9000-th evaluation: score=1.0028, divergence=0.6938, diversity=0.6179, num_succ=30, num_remain=2\n",
      "9100-th evaluation: score=1.0040, divergence=0.6955, diversity=0.6170, num_succ=32, num_remain=2\n",
      "9200-th evaluation: score=1.0051, divergence=0.6971, diversity=0.6159, num_succ=32, num_remain=4\n",
      "9300-th evaluation: score=1.0058, divergence=0.6984, diversity=0.6147, num_succ=32, num_remain=3\n",
      "9400-th evaluation: score=1.0067, divergence=0.7000, diversity=0.6134, num_succ=33, num_remain=2\n",
      "9500-th evaluation: score=1.0077, divergence=0.7015, diversity=0.6125, num_succ=34, num_remain=2\n",
      "9600-th evaluation: score=1.0081, divergence=0.7021, diversity=0.6120, num_succ=34, num_remain=3\n",
      "9700-th evaluation: score=1.0090, divergence=0.7034, diversity=0.6112, num_succ=34, num_remain=2\n",
      "9800-th evaluation: score=1.0099, divergence=0.7045, diversity=0.6108, num_succ=35, num_remain=3\n",
      "9900-th evaluation: score=1.0112, divergence=0.7060, diversity=0.6103, num_succ=36, num_remain=1\n",
      "[0.17046687 0.09931244 0.06520427 0.1534537  0.09170047 0.12465582\n",
      " 0.04280853 0.03128941 0.04668438 0.14063795 0.04074918 0.10970429\n",
      " 0.10868596 0.07033161 0.04236973 0.25536743 0.05791524 0.01242209\n",
      " 0.01972873 0.12791016 0.05891384 0.03262675 0.16756312 0.10312946\n",
      " 0.05032752 0.10514978 0.08836397 0.09051123 0.09115209 0.05408251\n",
      " 0.04895235 0.04782956 0.07702656 0.11090688 0.12502157 0.03912708\n",
      " 0.07626964 0.10220912 0.16089237 0.14417761 0.04841382 0.04177061\n",
      " 0.04824577 0.05356523 0.07291573 0.11321008 0.12963993 0.0685174\n",
      " 0.10670386 0.14512925 0.10210589 0.09366274 0.03296316 0.21175824\n",
      " 0.07923749 0.145145   0.03636933 0.04873226 0.12148589 0.07976536\n",
      " 0.08971251 0.05970262 0.06959774 0.13015747 0.09210775 0.14857048\n",
      " 0.10537199 0.03149101 0.09054167 0.17137471 0.05607033 0.08879337\n",
      " 0.07188847 0.14476471 0.04557056 0.05813753 0.09716784 0.05647693\n",
      " 0.081759   0.0469442  0.04375835 0.03134626 0.10603435 0.01500754\n",
      " 0.17163441 0.15052114 0.15370068 0.11547418 0.05396585 0.03170918\n",
      " 0.07245736 0.03307453 0.03451862 0.11379922 0.07316756 0.10325869\n",
      " 0.19558985 0.09837141 0.09853435 0.0429725 ]\n",
      "44\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "initial_evaluation: score=0.6105, divergence=0.0000, diversity=1.2210, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6108, divergence=0.0003, diversity=1.2209, num_succ=0, num_remain=84\n",
      " 100-th evaluation: score=0.6359, divergence=0.0367, diversity=1.1984, num_succ=0, num_remain=31\n",
      " 200-th evaluation: score=0.6596, divergence=0.0804, diversity=1.1585, num_succ=0, num_remain=38\n",
      " 300-th evaluation: score=0.6721, divergence=0.1071, diversity=1.1299, num_succ=1, num_remain=35\n",
      " 400-th evaluation: score=0.6871, divergence=0.1425, diversity=1.0892, num_succ=1, num_remain=37\n",
      " 500-th evaluation: score=0.7120, divergence=0.1964, diversity=1.0312, num_succ=1, num_remain=37\n",
      " 600-th evaluation: score=0.7397, divergence=0.2464, diversity=0.9866, num_succ=6, num_remain=27\n",
      " 700-th evaluation: score=0.7568, divergence=0.2777, diversity=0.9581, num_succ=6, num_remain=24\n",
      " 800-th evaluation: score=0.7818, divergence=0.3217, diversity=0.9201, num_succ=8, num_remain=22\n",
      " 900-th evaluation: score=0.8001, divergence=0.3548, diversity=0.8905, num_succ=10, num_remain=19\n",
      "1000-th evaluation: score=0.8113, divergence=0.3744, diversity=0.8738, num_succ=13, num_remain=15\n",
      "1100-th evaluation: score=0.8162, divergence=0.3834, diversity=0.8656, num_succ=13, num_remain=8\n",
      "1200-th evaluation: score=0.8229, divergence=0.3960, diversity=0.8539, num_succ=14, num_remain=13\n",
      "1300-th evaluation: score=0.8329, divergence=0.4139, diversity=0.8380, num_succ=15, num_remain=13\n",
      "1400-th evaluation: score=0.8450, divergence=0.4341, diversity=0.8218, num_succ=17, num_remain=12\n",
      "1500-th evaluation: score=0.8521, divergence=0.4453, diversity=0.8137, num_succ=17, num_remain=6\n",
      "1600-th evaluation: score=0.8572, divergence=0.4543, diversity=0.8058, num_succ=17, num_remain=4\n",
      "1700-th evaluation: score=0.8639, divergence=0.4651, diversity=0.7975, num_succ=17, num_remain=4\n",
      "1800-th evaluation: score=0.8683, divergence=0.4730, diversity=0.7905, num_succ=17, num_remain=4\n",
      "1900-th evaluation: score=0.8720, divergence=0.4792, diversity=0.7856, num_succ=17, num_remain=6\n",
      "2000-th evaluation: score=0.8741, divergence=0.4829, diversity=0.7825, num_succ=17, num_remain=5\n",
      "2100-th evaluation: score=0.8778, divergence=0.4885, diversity=0.7785, num_succ=17, num_remain=3\n",
      "2200-th evaluation: score=0.8800, divergence=0.4919, diversity=0.7761, num_succ=17, num_remain=3\n",
      "2300-th evaluation: score=0.8820, divergence=0.4947, diversity=0.7746, num_succ=17, num_remain=1\n",
      "2400-th evaluation: score=0.8822, divergence=0.4948, diversity=0.7748, num_succ=17, num_remain=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500-th evaluation: score=0.8823, divergence=0.4948, diversity=0.7749, num_succ=17, num_remain=1\n",
      "2600-th evaluation: score=0.8824, divergence=0.4949, diversity=0.7750, num_succ=17, num_remain=1\n",
      "2700-th evaluation: score=0.8824, divergence=0.4949, diversity=0.7750, num_succ=17, num_remain=1\n",
      "2800-th evaluation: score=0.8824, divergence=0.4949, diversity=0.7751, num_succ=17, num_remain=1\n",
      "2900-th evaluation: score=0.8825, divergence=0.4949, diversity=0.7751, num_succ=17, num_remain=1\n",
      "3000-th evaluation: score=0.8825, divergence=0.4949, diversity=0.7751, num_succ=17, num_remain=1\n",
      "3100-th evaluation: score=0.8825, divergence=0.4949, diversity=0.7751, num_succ=17, num_remain=1\n",
      "3200-th evaluation: score=0.8825, divergence=0.4949, diversity=0.7751, num_succ=17, num_remain=1\n",
      "3300-th evaluation: score=0.8825, divergence=0.4949, diversity=0.7751, num_succ=17, num_remain=1\n",
      "3400-th evaluation: score=0.8825, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "3500-th evaluation: score=0.8825, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "3600-th evaluation: score=0.8825, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "3700-th evaluation: score=0.8825, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "3800-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "3900-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "4000-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "4100-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "4200-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "4300-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "4400-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "4500-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "4600-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "4700-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "4800-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "4900-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "5000-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "5100-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "5200-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "5300-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "5400-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "5500-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "5600-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "5700-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "5800-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "5900-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "6000-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "6100-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "6200-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "6300-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "6400-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "6500-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "6600-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "6700-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "6800-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "6900-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "7000-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "7100-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "7200-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "7300-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "7400-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "7500-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "7600-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "7700-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "7800-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "7900-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "8000-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "8100-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "8200-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "8300-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "8400-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "8500-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "8600-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "8700-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "8800-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "8900-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "9000-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "9100-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "9200-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "9300-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "9400-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "9500-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "9600-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "9700-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "9800-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "9900-th evaluation: score=0.8826, divergence=0.4950, diversity=0.7752, num_succ=17, num_remain=1\n",
      "[0.1058143  0.0420217  0.04162553 0.1142694  0.12803883 0.16879513\n",
      " 0.04855478 0.1046415  0.11777145 0.20614316 0.08459628 0.05638831\n",
      " 0.05158998 0.07818973 0.08119942 0.04635386 0.07119661 0.0600847\n",
      " 0.16344411 0.02093639 0.03491964 0.02746907 0.07825763 0.11385806\n",
      " 0.0740666  0.02371109 0.04963671 0.04151449 0.11804318 0.08403293\n",
      " 0.03954573 0.08356    0.01383504 0.08494383 0.07866709 0.10893714\n",
      " 0.04772431 0.08732169 0.07004002 0.13932445 0.09761419 0.02172139\n",
      " 0.07520314 0.03757778 0.06640692 0.1519448  0.12649462 0.08120747\n",
      " 0.14144575 0.16960958 0.05535069 0.11250507 0.14243758 0.12114082\n",
      " 0.13642738 0.05894302 0.04830014 0.0081878  0.13520974 0.04921718\n",
      " 0.07861217 0.11654364 0.05826795 0.12171742 0.08391024 0.07065175\n",
      " 0.08805387 0.06668067 0.15620463 0.03297366 0.19136033 0.04064127\n",
      " 0.04431089 0.03042755 0.04276373 0.00414287 0.04273499 0.04255233\n",
      " 0.03383274 0.05347266 0.1393018  0.01860531 0.20363639 0.13493424\n",
      " 0.04243653 0.03801298 0.05053249 0.07530891 0.09926125 0.05250344\n",
      " 0.08526463 0.20546751 0.19475061 0.11787493 0.13975347 0.04140603\n",
      " 0.03428239 0.0838145  0.29295267 0.05702126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "initial_evaluation: score=0.6856, divergence=0.0000, diversity=1.3713, num_succ=0, num_remain=7\n",
      "   0-th evaluation: score=0.6857, divergence=0.0000, diversity=1.3713, num_succ=0, num_remain=85\n",
      " 100-th evaluation: score=0.6882, divergence=0.0044, diversity=1.3676, num_succ=0, num_remain=42\n",
      " 200-th evaluation: score=0.6885, divergence=0.0052, diversity=1.3666, num_succ=0, num_remain=41\n",
      " 300-th evaluation: score=0.6892, divergence=0.0071, diversity=1.3643, num_succ=0, num_remain=37\n",
      " 400-th evaluation: score=0.6898, divergence=0.0086, diversity=1.3624, num_succ=0, num_remain=34\n",
      " 500-th evaluation: score=0.6904, divergence=0.0101, diversity=1.3605, num_succ=0, num_remain=28\n",
      " 600-th evaluation: score=0.6909, divergence=0.0116, diversity=1.3586, num_succ=0, num_remain=27\n",
      " 700-th evaluation: score=0.6912, divergence=0.0127, diversity=1.3571, num_succ=0, num_remain=28\n",
      " 800-th evaluation: score=0.6914, divergence=0.0130, diversity=1.3568, num_succ=0, num_remain=21\n",
      " 900-th evaluation: score=0.6917, divergence=0.0138, diversity=1.3556, num_succ=0, num_remain=26\n",
      "1000-th evaluation: score=0.6921, divergence=0.0150, diversity=1.3540, num_succ=0, num_remain=27\n",
      "1100-th evaluation: score=0.6925, divergence=0.0163, diversity=1.3522, num_succ=0, num_remain=20\n",
      "1200-th evaluation: score=0.6929, divergence=0.0176, diversity=1.3504, num_succ=0, num_remain=29\n",
      "1300-th evaluation: score=0.6933, divergence=0.0193, diversity=1.3482, num_succ=0, num_remain=23\n",
      "1400-th evaluation: score=0.6939, divergence=0.0210, diversity=1.3458, num_succ=0, num_remain=30\n",
      "1500-th evaluation: score=0.6945, divergence=0.0230, diversity=1.3432, num_succ=0, num_remain=26\n",
      "1600-th evaluation: score=0.6949, divergence=0.0242, diversity=1.3414, num_succ=0, num_remain=23\n",
      "1700-th evaluation: score=0.6954, divergence=0.0258, diversity=1.3391, num_succ=0, num_remain=22\n",
      "1800-th evaluation: score=0.6961, divergence=0.0278, diversity=1.3365, num_succ=0, num_remain=27\n",
      "1900-th evaluation: score=0.6968, divergence=0.0300, diversity=1.3335, num_succ=0, num_remain=23\n",
      "2000-th evaluation: score=0.6979, divergence=0.0337, diversity=1.3284, num_succ=0, num_remain=25\n",
      "2100-th evaluation: score=0.6994, divergence=0.0381, diversity=1.3225, num_succ=0, num_remain=32\n",
      "2200-th evaluation: score=0.7023, divergence=0.0466, diversity=1.3114, num_succ=0, num_remain=39\n",
      "2300-th evaluation: score=0.7052, divergence=0.0545, diversity=1.3013, num_succ=0, num_remain=28\n",
      "2400-th evaluation: score=0.7092, divergence=0.0653, diversity=1.2880, num_succ=0, num_remain=41\n",
      "2500-th evaluation: score=0.7123, divergence=0.0739, diversity=1.2769, num_succ=0, num_remain=25\n",
      "2600-th evaluation: score=0.7158, divergence=0.0836, diversity=1.2644, num_succ=0, num_remain=27\n",
      "2700-th evaluation: score=0.7207, divergence=0.0965, diversity=1.2485, num_succ=0, num_remain=36\n",
      "2800-th evaluation: score=0.7268, divergence=0.1122, diversity=1.2292, num_succ=1, num_remain=40\n",
      "2900-th evaluation: score=0.7325, divergence=0.1273, diversity=1.2104, num_succ=1, num_remain=42\n",
      "3000-th evaluation: score=0.7390, divergence=0.1452, diversity=1.1878, num_succ=1, num_remain=33\n",
      "3100-th evaluation: score=0.7468, divergence=0.1658, diversity=1.1620, num_succ=1, num_remain=42\n",
      "3200-th evaluation: score=0.7563, divergence=0.1912, diversity=1.1301, num_succ=1, num_remain=35\n",
      "3300-th evaluation: score=0.7641, divergence=0.2120, diversity=1.1042, num_succ=1, num_remain=36\n",
      "3400-th evaluation: score=0.7734, divergence=0.2357, diversity=1.0754, num_succ=1, num_remain=36\n",
      "3500-th evaluation: score=0.7842, divergence=0.2620, diversity=1.0444, num_succ=1, num_remain=34\n",
      "3600-th evaluation: score=0.7931, divergence=0.2840, diversity=1.0183, num_succ=1, num_remain=40\n",
      "3700-th evaluation: score=0.8034, divergence=0.3095, diversity=0.9878, num_succ=1, num_remain=39\n",
      "3800-th evaluation: score=0.8140, divergence=0.3341, diversity=0.9598, num_succ=1, num_remain=30\n",
      "3900-th evaluation: score=0.8245, divergence=0.3586, diversity=0.9318, num_succ=1, num_remain=33\n",
      "4000-th evaluation: score=0.8371, divergence=0.3875, diversity=0.8990, num_succ=1, num_remain=37\n",
      "4100-th evaluation: score=0.8496, divergence=0.4160, diversity=0.8670, num_succ=1, num_remain=41\n",
      "4200-th evaluation: score=0.8614, divergence=0.4418, diversity=0.8393, num_succ=2, num_remain=38\n",
      "4300-th evaluation: score=0.8727, divergence=0.4652, diversity=0.8149, num_succ=3, num_remain=28\n",
      "4400-th evaluation: score=0.8811, divergence=0.4833, diversity=0.7955, num_succ=3, num_remain=24\n",
      "4500-th evaluation: score=0.8915, divergence=0.5047, diversity=0.7736, num_succ=4, num_remain=24\n",
      "4600-th evaluation: score=0.8998, divergence=0.5222, diversity=0.7552, num_succ=4, num_remain=26\n",
      "4700-th evaluation: score=0.9066, divergence=0.5364, diversity=0.7404, num_succ=4, num_remain=24\n",
      "4800-th evaluation: score=0.9139, divergence=0.5502, diversity=0.7273, num_succ=4, num_remain=20\n",
      "4900-th evaluation: score=0.9197, divergence=0.5612, diversity=0.7170, num_succ=5, num_remain=13\n",
      "5000-th evaluation: score=0.9238, divergence=0.5692, diversity=0.7091, num_succ=5, num_remain=13\n",
      "5100-th evaluation: score=0.9291, divergence=0.5794, diversity=0.6995, num_succ=5, num_remain=19\n",
      "5200-th evaluation: score=0.9331, divergence=0.5870, diversity=0.6922, num_succ=5, num_remain=11\n",
      "5300-th evaluation: score=0.9359, divergence=0.5924, diversity=0.6871, num_succ=5, num_remain=7\n",
      "5400-th evaluation: score=0.9399, divergence=0.5998, diversity=0.6801, num_succ=5, num_remain=16\n",
      "5500-th evaluation: score=0.9429, divergence=0.6057, diversity=0.6744, num_succ=5, num_remain=9\n",
      "5600-th evaluation: score=0.9461, divergence=0.6119, diversity=0.6683, num_succ=5, num_remain=6\n",
      "5700-th evaluation: score=0.9490, divergence=0.6171, diversity=0.6638, num_succ=5, num_remain=9\n",
      "5800-th evaluation: score=0.9522, divergence=0.6228, diversity=0.6588, num_succ=5, num_remain=10\n",
      "5900-th evaluation: score=0.9554, divergence=0.6287, diversity=0.6535, num_succ=6, num_remain=7\n",
      "6000-th evaluation: score=0.9585, divergence=0.6342, diversity=0.6486, num_succ=6, num_remain=12\n",
      "6100-th evaluation: score=0.9636, divergence=0.6427, diversity=0.6420, num_succ=7, num_remain=13\n",
      "6200-th evaluation: score=0.9665, divergence=0.6479, diversity=0.6371, num_succ=8, num_remain=5\n",
      "6300-th evaluation: score=0.9689, divergence=0.6527, diversity=0.6325, num_succ=8, num_remain=5\n",
      "6400-th evaluation: score=0.9715, divergence=0.6575, diversity=0.6280, num_succ=8, num_remain=8\n",
      "6500-th evaluation: score=0.9758, divergence=0.6645, diversity=0.6227, num_succ=8, num_remain=11\n",
      "6600-th evaluation: score=0.9795, divergence=0.6705, diversity=0.6180, num_succ=8, num_remain=7\n",
      "6700-th evaluation: score=0.9821, divergence=0.6748, diversity=0.6145, num_succ=8, num_remain=5\n",
      "6800-th evaluation: score=0.9843, divergence=0.6784, diversity=0.6119, num_succ=9, num_remain=4\n",
      "6900-th evaluation: score=0.9864, divergence=0.6816, diversity=0.6097, num_succ=10, num_remain=3\n",
      "7000-th evaluation: score=0.9874, divergence=0.6834, diversity=0.6079, num_succ=10, num_remain=2\n",
      "7100-th evaluation: score=0.9886, divergence=0.6856, diversity=0.6060, num_succ=10, num_remain=3\n",
      "7200-th evaluation: score=0.9890, divergence=0.6866, diversity=0.6048, num_succ=10, num_remain=3\n",
      "7300-th evaluation: score=0.9934, divergence=0.6934, diversity=0.6000, num_succ=13, num_remain=5\n",
      "7400-th evaluation: score=0.9949, divergence=0.6959, diversity=0.5979, num_succ=15, num_remain=2\n",
      "7500-th evaluation: score=0.9958, divergence=0.6979, diversity=0.5958, num_succ=16, num_remain=2\n",
      "7600-th evaluation: score=0.9971, divergence=0.7000, diversity=0.5942, num_succ=17, num_remain=6\n",
      "7700-th evaluation: score=0.9996, divergence=0.7038, diversity=0.5917, num_succ=18, num_remain=3\n",
      "7800-th evaluation: score=1.0012, divergence=0.7067, diversity=0.5891, num_succ=18, num_remain=5\n",
      "7900-th evaluation: score=1.0029, divergence=0.7096, diversity=0.5867, num_succ=21, num_remain=2\n",
      "8000-th evaluation: score=1.0033, divergence=0.7104, diversity=0.5858, num_succ=21, num_remain=2\n",
      "8100-th evaluation: score=1.0046, divergence=0.7127, diversity=0.5838, num_succ=24, num_remain=5\n",
      "8200-th evaluation: score=1.0057, divergence=0.7144, diversity=0.5826, num_succ=26, num_remain=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8300-th evaluation: score=1.0065, divergence=0.7160, diversity=0.5809, num_succ=26, num_remain=3\n",
      "8400-th evaluation: score=1.0070, divergence=0.7171, diversity=0.5797, num_succ=26, num_remain=2\n",
      "8500-th evaluation: score=1.0081, divergence=0.7191, diversity=0.5781, num_succ=26, num_remain=2\n",
      "8600-th evaluation: score=1.0086, divergence=0.7202, diversity=0.5766, num_succ=26, num_remain=2\n",
      "8700-th evaluation: score=1.0090, divergence=0.7214, diversity=0.5751, num_succ=26, num_remain=2\n",
      "8800-th evaluation: score=1.0099, divergence=0.7230, diversity=0.5737, num_succ=26, num_remain=2\n",
      "8900-th evaluation: score=1.0110, divergence=0.7249, diversity=0.5722, num_succ=26, num_remain=3\n",
      "9000-th evaluation: score=1.0114, divergence=0.7259, diversity=0.5711, num_succ=26, num_remain=5\n",
      "9100-th evaluation: score=1.0124, divergence=0.7275, diversity=0.5697, num_succ=27, num_remain=2\n",
      "9200-th evaluation: score=1.0129, divergence=0.7286, diversity=0.5685, num_succ=27, num_remain=3\n",
      "9300-th evaluation: score=1.0134, divergence=0.7296, diversity=0.5675, num_succ=27, num_remain=2\n",
      "9400-th evaluation: score=1.0140, divergence=0.7308, diversity=0.5665, num_succ=28, num_remain=2\n",
      "9500-th evaluation: score=1.0145, divergence=0.7317, diversity=0.5656, num_succ=28, num_remain=2\n",
      "9600-th evaluation: score=1.0154, divergence=0.7332, diversity=0.5644, num_succ=29, num_remain=2\n",
      "9700-th evaluation: score=1.0160, divergence=0.7343, diversity=0.5633, num_succ=29, num_remain=1\n",
      "9800-th evaluation: score=1.0163, divergence=0.7352, diversity=0.5623, num_succ=29, num_remain=2\n",
      "9900-th evaluation: score=1.0174, divergence=0.7369, diversity=0.5610, num_succ=30, num_remain=2\n",
      "[0.14579363 0.13281467 0.14493035 0.07489527 0.08039086 0.10318778\n",
      " 0.23454797 0.10065983 0.0689639  0.03962108 0.12274596 0.11824\n",
      " 0.12511405 0.08522842 0.05940571 0.09205868 0.11698536 0.04273397\n",
      " 0.02778999 0.04802476 0.08468813 0.06293014 0.10883827 0.07024238\n",
      " 0.0418244  0.13977952 0.03716648 0.0759738  0.17572382 0.06854345\n",
      " 0.11768309 0.06897947 0.08474134 0.03305572 0.11653486 0.02875636\n",
      " 0.09627    0.14393055 0.04417202 0.09733831 0.14734199 0.10823652\n",
      " 0.04208001 0.05657324 0.08204396 0.097644   0.11312277 0.07316113\n",
      " 0.09702885 0.08512847 0.13443383 0.07408022 0.08498908 0.0857346\n",
      " 0.07398584 0.11575861 0.10416738 0.09619879 0.16579297 0.12192933\n",
      " 0.12666276 0.10232299 0.06963042 0.11080838 0.09843831 0.10299027\n",
      " 0.10708805 0.0730996  0.07927877 0.1197646  0.00554231 0.10410517\n",
      " 0.11152102 0.07117585 0.08171266 0.07129814 0.12141171 0.12956921\n",
      " 0.06259801 0.07529821 0.12255609 0.13246282 0.08337686 0.15196957\n",
      " 0.0896006  0.10431635 0.10494806 0.10510572 0.11235334 0.0250397\n",
      " 0.06279037 0.07693957 0.12150408 0.11450519 0.07061266 0.0366099\n",
      " 0.05869292 0.0575138  0.12174007 0.12117779]\n",
      "46\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "initial_evaluation: score=0.6740, divergence=0.0000, diversity=1.3481, num_succ=0, num_remain=8\n",
      "   0-th evaluation: score=0.6741, divergence=0.0001, diversity=1.3480, num_succ=0, num_remain=89\n",
      " 100-th evaluation: score=0.6796, divergence=0.0073, diversity=1.3446, num_succ=0, num_remain=42\n",
      " 200-th evaluation: score=0.6806, divergence=0.0099, diversity=1.3414, num_succ=0, num_remain=35\n",
      " 300-th evaluation: score=0.6810, divergence=0.0109, diversity=1.3403, num_succ=0, num_remain=30\n",
      " 400-th evaluation: score=0.6813, divergence=0.0115, diversity=1.3395, num_succ=0, num_remain=32\n",
      " 500-th evaluation: score=0.6821, divergence=0.0135, diversity=1.3372, num_succ=0, num_remain=33\n",
      " 600-th evaluation: score=0.6822, divergence=0.0138, diversity=1.3368, num_succ=0, num_remain=32\n",
      " 700-th evaluation: score=0.6828, divergence=0.0158, diversity=1.3339, num_succ=0, num_remain=39\n",
      " 800-th evaluation: score=0.6839, divergence=0.0185, diversity=1.3307, num_succ=0, num_remain=36\n",
      " 900-th evaluation: score=0.6846, divergence=0.0203, diversity=1.3286, num_succ=0, num_remain=30\n",
      "1000-th evaluation: score=0.6850, divergence=0.0215, diversity=1.3270, num_succ=0, num_remain=28\n",
      "1100-th evaluation: score=0.6858, divergence=0.0236, diversity=1.3243, num_succ=0, num_remain=26\n",
      "1200-th evaluation: score=0.6862, divergence=0.0248, diversity=1.3227, num_succ=0, num_remain=33\n",
      "1300-th evaluation: score=0.6866, divergence=0.0262, diversity=1.3208, num_succ=0, num_remain=27\n",
      "1400-th evaluation: score=0.6870, divergence=0.0273, diversity=1.3194, num_succ=0, num_remain=30\n",
      "1500-th evaluation: score=0.6880, divergence=0.0299, diversity=1.3162, num_succ=0, num_remain=32\n",
      "1600-th evaluation: score=0.6899, divergence=0.0343, diversity=1.3112, num_succ=0, num_remain=34\n",
      "1700-th evaluation: score=0.6913, divergence=0.0387, diversity=1.3051, num_succ=0, num_remain=28\n",
      "1800-th evaluation: score=0.6938, divergence=0.0454, diversity=1.2969, num_succ=0, num_remain=34\n",
      "1900-th evaluation: score=0.6979, divergence=0.0545, diversity=1.2868, num_succ=0, num_remain=32\n",
      "2000-th evaluation: score=0.7024, divergence=0.0645, diversity=1.2759, num_succ=0, num_remain=35\n",
      "2100-th evaluation: score=0.7071, divergence=0.0773, diversity=1.2596, num_succ=0, num_remain=44\n",
      "2200-th evaluation: score=0.7133, divergence=0.0943, diversity=1.2381, num_succ=0, num_remain=42\n",
      "2300-th evaluation: score=0.7200, divergence=0.1098, diversity=1.2203, num_succ=0, num_remain=34\n",
      "2400-th evaluation: score=0.7247, divergence=0.1219, diversity=1.2056, num_succ=0, num_remain=35\n",
      "2500-th evaluation: score=0.7305, divergence=0.1373, diversity=1.1864, num_succ=0, num_remain=37\n",
      "2600-th evaluation: score=0.7375, divergence=0.1544, diversity=1.1661, num_succ=0, num_remain=42\n",
      "2700-th evaluation: score=0.7465, divergence=0.1775, diversity=1.1381, num_succ=0, num_remain=38\n",
      "2800-th evaluation: score=0.7495, divergence=0.1846, diversity=1.1298, num_succ=0, num_remain=37\n",
      "2900-th evaluation: score=0.7572, divergence=0.2039, diversity=1.1068, num_succ=0, num_remain=37\n",
      "3000-th evaluation: score=0.7666, divergence=0.2277, diversity=1.0779, num_succ=1, num_remain=37\n",
      "3100-th evaluation: score=0.7724, divergence=0.2444, diversity=1.0560, num_succ=1, num_remain=40\n",
      "3200-th evaluation: score=0.7768, divergence=0.2557, diversity=1.0423, num_succ=2, num_remain=36\n",
      "3300-th evaluation: score=0.7831, divergence=0.2710, diversity=1.0242, num_succ=2, num_remain=34\n",
      "3400-th evaluation: score=0.7892, divergence=0.2858, diversity=1.0068, num_succ=2, num_remain=31\n",
      "3500-th evaluation: score=0.7952, divergence=0.3000, diversity=0.9905, num_succ=2, num_remain=31\n",
      "3600-th evaluation: score=0.8026, divergence=0.3194, diversity=0.9664, num_succ=2, num_remain=36\n",
      "3700-th evaluation: score=0.8134, divergence=0.3452, diversity=0.9364, num_succ=2, num_remain=39\n",
      "3800-th evaluation: score=0.8216, divergence=0.3635, diversity=0.9163, num_succ=2, num_remain=35\n",
      "3900-th evaluation: score=0.8308, divergence=0.3854, diversity=0.8908, num_succ=2, num_remain=32\n",
      "4000-th evaluation: score=0.8410, divergence=0.4102, diversity=0.8616, num_succ=2, num_remain=37\n",
      "4100-th evaluation: score=0.8542, divergence=0.4368, diversity=0.8348, num_succ=3, num_remain=34\n",
      "4200-th evaluation: score=0.8655, divergence=0.4598, diversity=0.8116, num_succ=4, num_remain=31\n",
      "4300-th evaluation: score=0.8746, divergence=0.4786, diversity=0.7920, num_succ=6, num_remain=30\n",
      "4400-th evaluation: score=0.8831, divergence=0.4951, diversity=0.7759, num_succ=7, num_remain=24\n",
      "4500-th evaluation: score=0.8937, divergence=0.5162, diversity=0.7550, num_succ=7, num_remain=27\n",
      "4600-th evaluation: score=0.9042, divergence=0.5351, diversity=0.7383, num_succ=9, num_remain=31\n",
      "4700-th evaluation: score=0.9124, divergence=0.5500, diversity=0.7247, num_succ=11, num_remain=20\n",
      "4800-th evaluation: score=0.9177, divergence=0.5604, diversity=0.7146, num_succ=13, num_remain=14\n",
      "4900-th evaluation: score=0.9218, divergence=0.5684, diversity=0.7067, num_succ=13, num_remain=21\n",
      "5000-th evaluation: score=0.9255, divergence=0.5761, diversity=0.6989, num_succ=13, num_remain=13\n",
      "5100-th evaluation: score=0.9296, divergence=0.5832, diversity=0.6928, num_succ=13, num_remain=13\n",
      "5200-th evaluation: score=0.9338, divergence=0.5905, diversity=0.6866, num_succ=13, num_remain=14\n",
      "5300-th evaluation: score=0.9369, divergence=0.5959, diversity=0.6819, num_succ=13, num_remain=11\n",
      "5400-th evaluation: score=0.9402, divergence=0.6016, diversity=0.6771, num_succ=13, num_remain=11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500-th evaluation: score=0.9422, divergence=0.6055, diversity=0.6733, num_succ=15, num_remain=10\n",
      "5600-th evaluation: score=0.9449, divergence=0.6105, diversity=0.6686, num_succ=15, num_remain=11\n",
      "5700-th evaluation: score=0.9468, divergence=0.6145, diversity=0.6645, num_succ=16, num_remain=10\n",
      "5800-th evaluation: score=0.9499, divergence=0.6194, diversity=0.6610, num_succ=17, num_remain=9\n",
      "5900-th evaluation: score=0.9530, divergence=0.6251, diversity=0.6559, num_succ=18, num_remain=7\n",
      "6000-th evaluation: score=0.9560, divergence=0.6300, diversity=0.6519, num_succ=18, num_remain=6\n",
      "6100-th evaluation: score=0.9582, divergence=0.6336, diversity=0.6492, num_succ=18, num_remain=6\n",
      "6200-th evaluation: score=0.9596, divergence=0.6365, diversity=0.6461, num_succ=19, num_remain=5\n",
      "6300-th evaluation: score=0.9631, divergence=0.6419, diversity=0.6423, num_succ=20, num_remain=7\n",
      "6400-th evaluation: score=0.9645, divergence=0.6444, diversity=0.6400, num_succ=20, num_remain=4\n",
      "6500-th evaluation: score=0.9663, divergence=0.6477, diversity=0.6372, num_succ=20, num_remain=4\n",
      "6600-th evaluation: score=0.9677, divergence=0.6500, diversity=0.6354, num_succ=20, num_remain=4\n",
      "6700-th evaluation: score=0.9697, divergence=0.6529, diversity=0.6336, num_succ=20, num_remain=11\n",
      "6800-th evaluation: score=0.9732, divergence=0.6587, diversity=0.6290, num_succ=20, num_remain=3\n",
      "6900-th evaluation: score=0.9749, divergence=0.6618, diversity=0.6262, num_succ=20, num_remain=6\n",
      "7000-th evaluation: score=0.9765, divergence=0.6651, diversity=0.6227, num_succ=20, num_remain=3\n",
      "7100-th evaluation: score=0.9776, divergence=0.6677, diversity=0.6197, num_succ=20, num_remain=3\n",
      "7200-th evaluation: score=0.9798, divergence=0.6718, diversity=0.6160, num_succ=20, num_remain=8\n",
      "7300-th evaluation: score=0.9819, divergence=0.6755, diversity=0.6128, num_succ=20, num_remain=3\n",
      "7400-th evaluation: score=0.9830, divergence=0.6776, diversity=0.6108, num_succ=20, num_remain=4\n",
      "7500-th evaluation: score=0.9848, divergence=0.6804, diversity=0.6087, num_succ=21, num_remain=8\n",
      "7600-th evaluation: score=0.9871, divergence=0.6842, diversity=0.6058, num_succ=21, num_remain=4\n",
      "7700-th evaluation: score=0.9882, divergence=0.6862, diversity=0.6040, num_succ=21, num_remain=5\n",
      "7800-th evaluation: score=0.9904, divergence=0.6897, diversity=0.6015, num_succ=22, num_remain=2\n",
      "7900-th evaluation: score=0.9920, divergence=0.6923, diversity=0.5995, num_succ=23, num_remain=4\n",
      "8000-th evaluation: score=0.9936, divergence=0.6951, diversity=0.5971, num_succ=24, num_remain=2\n",
      "8100-th evaluation: score=0.9956, divergence=0.6982, diversity=0.5948, num_succ=26, num_remain=2\n",
      "8200-th evaluation: score=0.9961, divergence=0.6994, diversity=0.5933, num_succ=27, num_remain=2\n",
      "8300-th evaluation: score=0.9969, divergence=0.7009, diversity=0.5918, num_succ=27, num_remain=1\n",
      "8400-th evaluation: score=0.9986, divergence=0.7035, diversity=0.5902, num_succ=29, num_remain=3\n",
      "8500-th evaluation: score=1.0003, divergence=0.7061, diversity=0.5885, num_succ=31, num_remain=1\n",
      "8600-th evaluation: score=1.0014, divergence=0.7078, diversity=0.5871, num_succ=32, num_remain=1\n",
      "8700-th evaluation: score=1.0020, divergence=0.7090, diversity=0.5858, num_succ=32, num_remain=1\n",
      "8800-th evaluation: score=1.0027, divergence=0.7105, diversity=0.5844, num_succ=32, num_remain=1\n",
      "8900-th evaluation: score=1.0038, divergence=0.7122, diversity=0.5831, num_succ=33, num_remain=1\n",
      "9000-th evaluation: score=1.0044, divergence=0.7134, diversity=0.5820, num_succ=33, num_remain=1\n",
      "9100-th evaluation: score=1.0047, divergence=0.7140, diversity=0.5815, num_succ=33, num_remain=2\n",
      "9200-th evaluation: score=1.0050, divergence=0.7146, diversity=0.5808, num_succ=33, num_remain=1\n",
      "9300-th evaluation: score=1.0052, divergence=0.7150, diversity=0.5804, num_succ=33, num_remain=1\n",
      "9400-th evaluation: score=1.0056, divergence=0.7157, diversity=0.5799, num_succ=34, num_remain=1\n",
      "9500-th - no remaining indice: score=1.0059, divergence=0.7161, diversity=0.5795, num_succ=34, num_remain=0\n",
      "[0.10162432 0.14142535 0.10375203 0.12331706 0.08248867 0.07132027\n",
      " 0.09735802 0.08938128 0.12736735 0.10764358 0.14651084 0.07170781\n",
      " 0.12495112 0.0631814  0.12837246 0.10823644 0.09695451 0.07530282\n",
      " 0.04436999 0.13375493 0.12349142 0.07776826 0.1190511  0.0957298\n",
      " 0.11404234 0.09867842 0.08692878 0.0882901  0.07979071 0.12821757\n",
      " 0.09227499 0.0737765  0.0769312  0.00578376 0.11422192 0.09630474\n",
      " 0.06893445 0.14405129 0.13517902 0.06328796 0.07704718 0.14000588\n",
      " 0.1018471  0.10392507 0.10591181 0.14936794 0.05316138 0.07212131\n",
      " 0.08698808 0.07180548 0.11138593 0.09218834 0.17590446 0.06141321\n",
      " 0.0633727  0.03321886 0.09693285 0.09029939 0.12800101 0.10842213\n",
      " 0.08046763 0.08983515 0.08124931 0.07137841 0.10372133 0.09012628\n",
      " 0.06252092 0.16799305 0.09565513 0.04073975 0.12904478 0.04180481\n",
      " 0.08098692 0.02146628 0.07890634 0.0828289  0.11013524 0.08632983\n",
      " 0.08620279 0.04587111 0.05758672 0.04919143 0.08018433 0.08504193\n",
      " 0.1873834  0.1867272  0.11920195 0.09744308 0.04748943 0.07414565\n",
      " 0.06918164 0.11009573 0.136841   0.08932459 0.07293342 0.10537498\n",
      " 0.09877755 0.10813865 0.05625531 0.11426332]\n",
      "47\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "initial_evaluation: score=0.5974, divergence=0.0000, diversity=1.1947, num_succ=0, num_remain=7\n",
      "   0-th evaluation: score=0.5976, divergence=0.0003, diversity=1.1947, num_succ=0, num_remain=82\n",
      " 100-th evaluation: score=0.6219, divergence=0.0299, diversity=1.1840, num_succ=2, num_remain=39\n",
      " 200-th evaluation: score=0.6312, divergence=0.0458, diversity=1.1708, num_succ=3, num_remain=31\n",
      " 300-th evaluation: score=0.6435, divergence=0.0670, diversity=1.1529, num_succ=7, num_remain=31\n",
      " 400-th evaluation: score=0.6568, divergence=0.0915, diversity=1.1306, num_succ=8, num_remain=34\n",
      " 500-th evaluation: score=0.6660, divergence=0.1077, diversity=1.1166, num_succ=8, num_remain=29\n",
      " 600-th evaluation: score=0.6704, divergence=0.1166, diversity=1.1075, num_succ=9, num_remain=23\n",
      " 700-th evaluation: score=0.6755, divergence=0.1269, diversity=1.0972, num_succ=9, num_remain=27\n",
      " 800-th evaluation: score=0.6798, divergence=0.1375, diversity=1.0845, num_succ=9, num_remain=25\n",
      " 900-th evaluation: score=0.6838, divergence=0.1451, diversity=1.0773, num_succ=9, num_remain=29\n",
      "1000-th evaluation: score=0.6917, divergence=0.1631, diversity=1.0572, num_succ=9, num_remain=33\n",
      "1100-th evaluation: score=0.6980, divergence=0.1767, diversity=1.0427, num_succ=9, num_remain=28\n",
      "1200-th evaluation: score=0.7014, divergence=0.1850, diversity=1.0329, num_succ=9, num_remain=28\n",
      "1300-th evaluation: score=0.7073, divergence=0.2026, diversity=1.0095, num_succ=9, num_remain=33\n",
      "1400-th evaluation: score=0.7213, divergence=0.2315, diversity=0.9796, num_succ=10, num_remain=29\n",
      "1500-th evaluation: score=0.7375, divergence=0.2614, diversity=0.9522, num_succ=12, num_remain=34\n",
      "1600-th evaluation: score=0.7473, divergence=0.2814, diversity=0.9316, num_succ=12, num_remain=25\n",
      "1700-th evaluation: score=0.7600, divergence=0.3065, diversity=0.9070, num_succ=12, num_remain=21\n",
      "1800-th evaluation: score=0.7739, divergence=0.3332, diversity=0.8815, num_succ=12, num_remain=21\n",
      "1900-th evaluation: score=0.7897, divergence=0.3608, diversity=0.8578, num_succ=13, num_remain=16\n",
      "2000-th evaluation: score=0.7952, divergence=0.3704, diversity=0.8496, num_succ=13, num_remain=9\n",
      "2100-th evaluation: score=0.7981, divergence=0.3756, diversity=0.8451, num_succ=13, num_remain=8\n",
      "2200-th evaluation: score=0.8026, divergence=0.3839, diversity=0.8374, num_succ=14, num_remain=10\n",
      "2300-th evaluation: score=0.8085, divergence=0.3937, diversity=0.8297, num_succ=15, num_remain=8\n",
      "2400-th evaluation: score=0.8147, divergence=0.4036, diversity=0.8221, num_succ=16, num_remain=6\n",
      "2500-th evaluation: score=0.8200, divergence=0.4129, diversity=0.8140, num_succ=16, num_remain=6\n",
      "2600-th evaluation: score=0.8264, divergence=0.4233, diversity=0.8061, num_succ=18, num_remain=6\n",
      "2700-th evaluation: score=0.8298, divergence=0.4299, diversity=0.7999, num_succ=18, num_remain=3\n",
      "2800-th evaluation: score=0.8370, divergence=0.4410, diversity=0.7921, num_succ=18, num_remain=7\n",
      "2900-th evaluation: score=0.8433, divergence=0.4499, diversity=0.7866, num_succ=19, num_remain=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000-th evaluation: score=0.8441, divergence=0.4508, diversity=0.7865, num_succ=19, num_remain=1\n",
      "3100-th evaluation: score=0.8444, divergence=0.4509, diversity=0.7868, num_succ=19, num_remain=1\n",
      "3200-th evaluation: score=0.8445, divergence=0.4511, diversity=0.7868, num_succ=19, num_remain=1\n",
      "3300-th evaluation: score=0.8446, divergence=0.4512, diversity=0.7869, num_succ=19, num_remain=1\n",
      "3400-th evaluation: score=0.8447, divergence=0.4512, diversity=0.7869, num_succ=19, num_remain=1\n",
      "3500-th evaluation: score=0.8447, divergence=0.4512, diversity=0.7870, num_succ=19, num_remain=1\n",
      "3600-th evaluation: score=0.8448, divergence=0.4513, diversity=0.7870, num_succ=19, num_remain=1\n",
      "3700-th evaluation: score=0.8449, divergence=0.4514, diversity=0.7870, num_succ=19, num_remain=1\n",
      "3800-th evaluation: score=0.8449, divergence=0.4514, diversity=0.7870, num_succ=19, num_remain=1\n",
      "3900-th evaluation: score=0.8449, divergence=0.4514, diversity=0.7870, num_succ=19, num_remain=1\n",
      "4000-th evaluation: score=0.8449, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "4100-th evaluation: score=0.8449, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "4200-th evaluation: score=0.8449, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "4300-th evaluation: score=0.8449, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "4400-th evaluation: score=0.8449, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "4500-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "4600-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "4700-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "4800-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "4900-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "5000-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "5100-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "5200-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "5300-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "5400-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "5500-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "5600-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "5700-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "5800-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "5900-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "6000-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "6100-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "6200-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "6300-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "6400-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "6500-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "6600-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "6700-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "6800-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "6900-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "7000-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "7100-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "7200-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "7300-th evaluation: score=0.8450, divergence=0.4514, diversity=0.7871, num_succ=19, num_remain=1\n",
      "7400-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "7500-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "7600-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "7700-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "7800-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "7900-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "8000-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "8100-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "8200-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "8300-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "8400-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "8500-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "8600-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "8700-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "8800-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "8900-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "9000-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "9100-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "9200-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "9300-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "9400-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "9500-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "9600-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "9700-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "9800-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "9900-th evaluation: score=0.8450, divergence=0.4515, diversity=0.7871, num_succ=19, num_remain=1\n",
      "[3.42191847e-02 1.45587773e-01 5.84887314e-02 3.18457322e-02\n",
      " 9.99096032e-02 3.71484549e-02 9.28611327e-02 2.15763403e-02\n",
      " 1.69941965e-01 5.05366988e-02 1.35227721e-01 7.27227018e-02\n",
      " 8.13737642e-02 8.86669542e-02 5.74751748e-02 5.94008369e-02\n",
      " 1.97799063e-01 9.80953408e-02 4.88079814e-02 7.98785251e-02\n",
      " 5.56474230e-02 3.79144256e-02 8.37346267e-02 2.41972101e-01\n",
      " 5.94606959e-02 1.22653560e-01 1.03996092e-01 3.89306239e-02\n",
      " 5.25414984e-02 1.80804046e-01 1.39041556e-03 9.86785307e-02\n",
      " 8.67380884e-02 6.90806314e-02 4.02916439e-02 8.16283759e-02\n",
      " 1.51469863e-01 9.20842581e-02 9.20200713e-02 6.53847160e-02\n",
      " 6.24735439e-02 1.03145419e-01 1.25664609e-03 5.17491110e-02\n",
      " 6.74748920e-04 1.37389391e-01 6.86816837e-02 2.90353369e-02\n",
      " 1.07332179e-01 5.83667652e-02 1.45187869e-01 1.44183249e-02\n",
      " 4.44667688e-02 2.94153433e-02 7.38673862e-02 1.15790399e-01\n",
      " 2.74058787e-04 4.27483370e-03 1.54175491e-01 2.08678679e-02\n",
      " 3.07681854e-01 1.04053815e-01 1.47854210e-01 1.32835833e-01\n",
      " 3.33931863e-02 1.13438923e-01 4.50908764e-02 1.38127820e-01\n",
      " 7.52765745e-02 1.59603946e-01 1.07216564e-01 8.09218707e-02\n",
      " 8.25460456e-02 1.00251277e-01 1.08919314e-01 2.14752825e-02\n",
      " 6.20354208e-02 5.45517499e-02 9.42006822e-03 6.66183740e-02\n",
      " 1.15252118e-01 3.95222447e-02 5.14752771e-02 5.89278100e-02\n",
      " 4.31510506e-02 1.17750234e-01 2.30190439e-01 9.53672868e-02\n",
      " 1.96320742e-01 1.21069797e-01 6.60880174e-02 8.63372859e-02\n",
      " 1.28654244e-01 8.25835348e-03 1.86516789e-02 1.27162040e-01\n",
      " 1.11187549e-01 7.09176009e-02 2.95574312e-03 2.77554778e-03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "initial_evaluation: score=0.6770, divergence=0.0000, diversity=1.3540, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6771, divergence=0.0001, diversity=1.3540, num_succ=0, num_remain=91\n",
      " 100-th evaluation: score=0.6807, divergence=0.0047, diversity=1.3521, num_succ=0, num_remain=42\n",
      " 200-th evaluation: score=0.6812, divergence=0.0055, diversity=1.3514, num_succ=0, num_remain=37\n",
      " 300-th evaluation: score=0.6816, divergence=0.0063, diversity=1.3506, num_succ=0, num_remain=33\n",
      " 400-th evaluation: score=0.6819, divergence=0.0068, diversity=1.3500, num_succ=0, num_remain=26\n",
      " 500-th evaluation: score=0.6819, divergence=0.0071, diversity=1.3498, num_succ=0, num_remain=25\n",
      " 600-th evaluation: score=0.6824, divergence=0.0082, diversity=1.3484, num_succ=0, num_remain=27\n",
      " 700-th evaluation: score=0.6827, divergence=0.0086, diversity=1.3481, num_succ=0, num_remain=27\n",
      " 800-th evaluation: score=0.6828, divergence=0.0088, diversity=1.3480, num_succ=0, num_remain=22\n",
      " 900-th evaluation: score=0.6828, divergence=0.0088, diversity=1.3479, num_succ=0, num_remain=24\n",
      "1000-th evaluation: score=0.6828, divergence=0.0090, diversity=1.3478, num_succ=0, num_remain=22\n",
      "1100-th evaluation: score=0.6829, divergence=0.0090, diversity=1.3477, num_succ=0, num_remain=21\n",
      "1200-th evaluation: score=0.6829, divergence=0.0090, diversity=1.3477, num_succ=0, num_remain=22\n",
      "1300-th evaluation: score=0.6829, divergence=0.0091, diversity=1.3478, num_succ=0, num_remain=21\n",
      "1400-th evaluation: score=0.6830, divergence=0.0091, diversity=1.3478, num_succ=0, num_remain=23\n",
      "1500-th evaluation: score=0.6830, divergence=0.0092, diversity=1.3477, num_succ=0, num_remain=23\n",
      "1600-th evaluation: score=0.6831, divergence=0.0094, diversity=1.3474, num_succ=0, num_remain=23\n",
      "1700-th evaluation: score=0.6831, divergence=0.0094, diversity=1.3473, num_succ=0, num_remain=19\n",
      "1800-th evaluation: score=0.6831, divergence=0.0095, diversity=1.3474, num_succ=0, num_remain=19\n",
      "1900-th evaluation: score=0.6832, divergence=0.0095, diversity=1.3473, num_succ=0, num_remain=19\n",
      "2000-th evaluation: score=0.6832, divergence=0.0095, diversity=1.3473, num_succ=0, num_remain=20\n",
      "2100-th evaluation: score=0.6832, divergence=0.0095, diversity=1.3473, num_succ=0, num_remain=20\n",
      "2200-th evaluation: score=0.6833, divergence=0.0097, diversity=1.3470, num_succ=0, num_remain=24\n",
      "2300-th evaluation: score=0.6833, divergence=0.0098, diversity=1.3470, num_succ=0, num_remain=20\n",
      "2400-th evaluation: score=0.6833, divergence=0.0098, diversity=1.3469, num_succ=0, num_remain=21\n",
      "2500-th evaluation: score=0.6834, divergence=0.0100, diversity=1.3469, num_succ=0, num_remain=21\n",
      "2600-th evaluation: score=0.6834, divergence=0.0100, diversity=1.3469, num_succ=0, num_remain=20\n",
      "2700-th evaluation: score=0.6835, divergence=0.0100, diversity=1.3469, num_succ=0, num_remain=18\n",
      "2800-th evaluation: score=0.6835, divergence=0.0100, diversity=1.3469, num_succ=0, num_remain=18\n",
      "2900-th evaluation: score=0.6835, divergence=0.0100, diversity=1.3469, num_succ=0, num_remain=17\n",
      "3000-th evaluation: score=0.6835, divergence=0.0100, diversity=1.3469, num_succ=0, num_remain=17\n",
      "3100-th evaluation: score=0.6835, divergence=0.0101, diversity=1.3469, num_succ=0, num_remain=16\n",
      "3200-th evaluation: score=0.6835, divergence=0.0101, diversity=1.3469, num_succ=0, num_remain=16\n",
      "3300-th evaluation: score=0.6835, divergence=0.0101, diversity=1.3469, num_succ=0, num_remain=17\n",
      "3400-th evaluation: score=0.6835, divergence=0.0101, diversity=1.3469, num_succ=0, num_remain=16\n",
      "3500-th evaluation: score=0.6835, divergence=0.0101, diversity=1.3469, num_succ=0, num_remain=16\n",
      "3600-th evaluation: score=0.6836, divergence=0.0101, diversity=1.3469, num_succ=0, num_remain=17\n",
      "3700-th evaluation: score=0.6836, divergence=0.0101, diversity=1.3469, num_succ=0, num_remain=17\n",
      "3800-th evaluation: score=0.6836, divergence=0.0101, diversity=1.3469, num_succ=0, num_remain=17\n",
      "3900-th evaluation: score=0.6837, divergence=0.0104, diversity=1.3467, num_succ=0, num_remain=25\n",
      "4000-th evaluation: score=0.6837, divergence=0.0104, diversity=1.3467, num_succ=0, num_remain=20\n",
      "4100-th evaluation: score=0.6837, divergence=0.0104, diversity=1.3467, num_succ=0, num_remain=20\n",
      "4200-th evaluation: score=0.6838, divergence=0.0104, diversity=1.3467, num_succ=0, num_remain=20\n",
      "4300-th evaluation: score=0.6838, divergence=0.0104, diversity=1.3467, num_succ=0, num_remain=20\n",
      "4400-th evaluation: score=0.6838, divergence=0.0104, diversity=1.3467, num_succ=0, num_remain=20\n",
      "4500-th evaluation: score=0.6838, divergence=0.0104, diversity=1.3467, num_succ=0, num_remain=19\n",
      "4600-th evaluation: score=0.6838, divergence=0.0104, diversity=1.3467, num_succ=0, num_remain=19\n",
      "4700-th evaluation: score=0.6838, divergence=0.0104, diversity=1.3467, num_succ=0, num_remain=19\n",
      "4800-th evaluation: score=0.6838, divergence=0.0104, diversity=1.3467, num_succ=0, num_remain=19\n",
      "4900-th evaluation: score=0.6838, divergence=0.0104, diversity=1.3467, num_succ=0, num_remain=19\n",
      "5000-th evaluation: score=0.6838, divergence=0.0104, diversity=1.3467, num_succ=0, num_remain=19\n",
      "5100-th evaluation: score=0.6838, divergence=0.0104, diversity=1.3467, num_succ=0, num_remain=19\n",
      "5200-th evaluation: score=0.6838, divergence=0.0104, diversity=1.3467, num_succ=0, num_remain=20\n",
      "5300-th evaluation: score=0.6838, divergence=0.0104, diversity=1.3467, num_succ=0, num_remain=18\n",
      "5400-th evaluation: score=0.6838, divergence=0.0104, diversity=1.3467, num_succ=0, num_remain=18\n",
      "5500-th evaluation: score=0.6838, divergence=0.0104, diversity=1.3467, num_succ=0, num_remain=18\n",
      "5600-th evaluation: score=0.6838, divergence=0.0104, diversity=1.3467, num_succ=0, num_remain=17\n",
      "5700-th evaluation: score=0.6838, divergence=0.0105, diversity=1.3467, num_succ=0, num_remain=17\n",
      "5800-th evaluation: score=0.6838, divergence=0.0105, diversity=1.3467, num_succ=0, num_remain=17\n",
      "5900-th evaluation: score=0.6838, divergence=0.0105, diversity=1.3467, num_succ=0, num_remain=18\n",
      "6000-th evaluation: score=0.6838, divergence=0.0105, diversity=1.3467, num_succ=0, num_remain=17\n",
      "6100-th evaluation: score=0.6838, divergence=0.0105, diversity=1.3467, num_succ=0, num_remain=17\n",
      "6200-th evaluation: score=0.6838, divergence=0.0105, diversity=1.3467, num_succ=0, num_remain=17\n",
      "6300-th evaluation: score=0.6839, divergence=0.0105, diversity=1.3467, num_succ=0, num_remain=17\n",
      "6400-th evaluation: score=0.6839, divergence=0.0105, diversity=1.3467, num_succ=0, num_remain=17\n",
      "6500-th evaluation: score=0.6839, divergence=0.0107, diversity=1.3465, num_succ=0, num_remain=21\n",
      "6600-th evaluation: score=0.6839, divergence=0.0107, diversity=1.3465, num_succ=0, num_remain=20\n",
      "6700-th evaluation: score=0.6839, divergence=0.0107, diversity=1.3464, num_succ=0, num_remain=24\n",
      "6800-th evaluation: score=0.6839, divergence=0.0108, diversity=1.3464, num_succ=0, num_remain=20\n",
      "6900-th evaluation: score=0.6840, divergence=0.0110, diversity=1.3461, num_succ=0, num_remain=22\n",
      "7000-th evaluation: score=0.6842, divergence=0.0112, diversity=1.3458, num_succ=0, num_remain=26\n",
      "7100-th evaluation: score=0.6842, divergence=0.0113, diversity=1.3458, num_succ=0, num_remain=22\n",
      "7200-th evaluation: score=0.6842, divergence=0.0113, diversity=1.3458, num_succ=0, num_remain=19\n",
      "7300-th evaluation: score=0.6842, divergence=0.0113, diversity=1.3458, num_succ=0, num_remain=19\n",
      "7400-th evaluation: score=0.6842, divergence=0.0113, diversity=1.3458, num_succ=0, num_remain=19\n",
      "7500-th evaluation: score=0.6842, divergence=0.0113, diversity=1.3458, num_succ=0, num_remain=19\n",
      "7600-th evaluation: score=0.6842, divergence=0.0113, diversity=1.3458, num_succ=0, num_remain=19\n",
      "7700-th evaluation: score=0.6842, divergence=0.0113, diversity=1.3458, num_succ=0, num_remain=19\n",
      "7800-th evaluation: score=0.6843, divergence=0.0115, diversity=1.3456, num_succ=0, num_remain=39\n",
      "7900-th evaluation: score=0.6843, divergence=0.0118, diversity=1.3451, num_succ=0, num_remain=30\n",
      "8000-th evaluation: score=0.6844, divergence=0.0119, diversity=1.3450, num_succ=0, num_remain=26\n",
      "8100-th evaluation: score=0.6844, divergence=0.0119, diversity=1.3450, num_succ=0, num_remain=24\n",
      "8200-th evaluation: score=0.6845, divergence=0.0123, diversity=1.3444, num_succ=0, num_remain=27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8300-th evaluation: score=0.6845, divergence=0.0124, diversity=1.3443, num_succ=0, num_remain=22\n",
      "8400-th evaluation: score=0.6846, divergence=0.0125, diversity=1.3442, num_succ=0, num_remain=20\n",
      "8500-th evaluation: score=0.6846, divergence=0.0125, diversity=1.3442, num_succ=0, num_remain=20\n",
      "8600-th evaluation: score=0.6846, divergence=0.0125, diversity=1.3442, num_succ=0, num_remain=20\n",
      "8700-th evaluation: score=0.6846, divergence=0.0125, diversity=1.3442, num_succ=0, num_remain=20\n",
      "8800-th evaluation: score=0.6846, divergence=0.0125, diversity=1.3442, num_succ=0, num_remain=22\n",
      "8900-th evaluation: score=0.6848, divergence=0.0133, diversity=1.3431, num_succ=0, num_remain=25\n",
      "9000-th evaluation: score=0.6849, divergence=0.0139, diversity=1.3421, num_succ=0, num_remain=26\n",
      "9100-th evaluation: score=0.6850, divergence=0.0140, diversity=1.3419, num_succ=0, num_remain=26\n",
      "9200-th evaluation: score=0.6851, divergence=0.0144, diversity=1.3413, num_succ=0, num_remain=28\n",
      "9300-th evaluation: score=0.6852, divergence=0.0147, diversity=1.3409, num_succ=0, num_remain=23\n",
      "9400-th evaluation: score=0.6852, divergence=0.0148, diversity=1.3408, num_succ=0, num_remain=22\n",
      "9500-th evaluation: score=0.6853, divergence=0.0149, diversity=1.3407, num_succ=0, num_remain=25\n",
      "9600-th evaluation: score=0.6855, divergence=0.0158, diversity=1.3395, num_succ=0, num_remain=37\n",
      "9700-th evaluation: score=0.6857, divergence=0.0160, diversity=1.3392, num_succ=0, num_remain=28\n",
      "9800-th evaluation: score=0.6857, divergence=0.0163, diversity=1.3390, num_succ=0, num_remain=30\n",
      "9900-th evaluation: score=0.6858, divergence=0.0165, diversity=1.3386, num_succ=0, num_remain=25\n",
      "[0.00313923 0.03670478 0.28610391 0.06927735 0.02069319 0.11586936\n",
      " 0.05305307 0.00602285 0.092117   0.14262516 0.0232422  0.29923356\n",
      " 0.07064322 0.037279   0.00749442 0.04989018 0.05179008 0.04212405\n",
      " 0.05165144 0.04899524 0.1186174  0.03806885 0.11766019 0.04426999\n",
      " 0.02280031 0.08212279 0.0469628  0.05701992 0.00957094 0.05279252\n",
      " 0.00852085 0.22572209 0.15625655 0.01637407 0.00506658 0.23855932\n",
      " 0.08222661 0.06920351 0.03092565 0.04573389 0.00079838 0.03088904\n",
      " 0.1163364  0.10095783 0.10822431 0.00089567 0.16420918 0.09446595\n",
      " 0.07022941 0.043968   0.08284111 0.15958133 0.0777942  0.06200024\n",
      " 0.00493825 0.04894054 0.13878285 0.00323347 0.00693377 0.10110551\n",
      " 0.0186942  0.05485788 0.00191842 0.11338504 0.07149376 0.05643381\n",
      " 0.01667564 0.03905299 0.10002544 0.06070033 0.00330321 0.05409622\n",
      " 0.01809336 0.0631936  0.06913303 0.07448184 0.02832583 0.15295786\n",
      " 0.05187171 0.11892139 0.0572751  0.22364168 0.01874374 0.03\n",
      " 0.37257874 0.24942522 0.05565289 0.12694396 0.0583334  0.08465203\n",
      " 0.08948036 0.05729572 0.02634177 0.08034806 0.04216224 0.01931491\n",
      " 0.02455621 0.00099476 0.06599233 0.02994298]\n",
      "49\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "initial_evaluation: score=0.6800, divergence=0.0000, diversity=1.3601, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6801, divergence=0.0000, diversity=1.3601, num_succ=0, num_remain=90\n",
      " 100-th evaluation: score=0.6841, divergence=0.0067, diversity=1.3547, num_succ=0, num_remain=43\n",
      " 200-th evaluation: score=0.6857, divergence=0.0108, diversity=1.3498, num_succ=0, num_remain=33\n",
      " 300-th evaluation: score=0.6880, divergence=0.0160, diversity=1.3440, num_succ=0, num_remain=42\n",
      " 400-th evaluation: score=0.6895, divergence=0.0202, diversity=1.3386, num_succ=0, num_remain=41\n",
      " 500-th evaluation: score=0.6913, divergence=0.0247, diversity=1.3332, num_succ=0, num_remain=37\n",
      " 600-th evaluation: score=0.6916, divergence=0.0258, diversity=1.3316, num_succ=0, num_remain=28\n",
      " 700-th evaluation: score=0.6924, divergence=0.0276, diversity=1.3295, num_succ=0, num_remain=30\n",
      " 800-th evaluation: score=0.6935, divergence=0.0316, diversity=1.3238, num_succ=0, num_remain=41\n",
      " 900-th evaluation: score=0.6962, divergence=0.0387, diversity=1.3148, num_succ=0, num_remain=35\n",
      "1000-th evaluation: score=0.6994, divergence=0.0478, diversity=1.3032, num_succ=0, num_remain=47\n",
      "1100-th evaluation: score=0.7040, divergence=0.0603, diversity=1.2875, num_succ=0, num_remain=41\n",
      "1200-th evaluation: score=0.7118, divergence=0.0814, diversity=1.2608, num_succ=0, num_remain=44\n",
      "1300-th evaluation: score=0.7232, divergence=0.1109, diversity=1.2245, num_succ=0, num_remain=43\n",
      "1400-th evaluation: score=0.7345, divergence=0.1391, diversity=1.1907, num_succ=0, num_remain=42\n",
      "1500-th evaluation: score=0.7448, divergence=0.1651, diversity=1.1595, num_succ=0, num_remain=40\n",
      "1600-th evaluation: score=0.7618, divergence=0.2054, diversity=1.1128, num_succ=0, num_remain=46\n",
      "1700-th evaluation: score=0.7802, divergence=0.2482, diversity=1.0640, num_succ=0, num_remain=42\n",
      "1800-th evaluation: score=0.7989, divergence=0.2898, diversity=1.0181, num_succ=0, num_remain=40\n",
      "1900-th evaluation: score=0.8169, divergence=0.3289, diversity=0.9761, num_succ=0, num_remain=41\n",
      "2000-th evaluation: score=0.8352, divergence=0.3659, diversity=0.9386, num_succ=2, num_remain=35\n",
      "2100-th evaluation: score=0.8498, divergence=0.3952, diversity=0.9093, num_succ=2, num_remain=30\n",
      "2200-th evaluation: score=0.8635, divergence=0.4228, diversity=0.8814, num_succ=2, num_remain=28\n",
      "2300-th evaluation: score=0.8763, divergence=0.4472, diversity=0.8582, num_succ=3, num_remain=28\n",
      "2400-th evaluation: score=0.8901, divergence=0.4744, diversity=0.8314, num_succ=4, num_remain=32\n",
      "2500-th evaluation: score=0.9020, divergence=0.4981, diversity=0.8077, num_succ=5, num_remain=31\n",
      "2600-th evaluation: score=0.9097, divergence=0.5155, diversity=0.7884, num_succ=6, num_remain=23\n",
      "2700-th evaluation: score=0.9205, divergence=0.5376, diversity=0.7659, num_succ=7, num_remain=22\n",
      "2800-th evaluation: score=0.9296, divergence=0.5553, diversity=0.7487, num_succ=8, num_remain=22\n",
      "2900-th evaluation: score=0.9360, divergence=0.5676, diversity=0.7367, num_succ=8, num_remain=23\n",
      "3000-th evaluation: score=0.9452, divergence=0.5843, diversity=0.7217, num_succ=8, num_remain=22\n",
      "3100-th evaluation: score=0.9525, divergence=0.5974, diversity=0.7103, num_succ=8, num_remain=21\n",
      "3200-th evaluation: score=0.9597, divergence=0.6088, diversity=0.7016, num_succ=9, num_remain=18\n",
      "3300-th evaluation: score=0.9676, divergence=0.6218, diversity=0.6916, num_succ=12, num_remain=13\n",
      "3400-th evaluation: score=0.9737, divergence=0.6309, diversity=0.6855, num_succ=13, num_remain=14\n",
      "3500-th evaluation: score=0.9772, divergence=0.6370, diversity=0.6804, num_succ=13, num_remain=9\n",
      "3600-th evaluation: score=0.9830, divergence=0.6474, diversity=0.6712, num_succ=14, num_remain=9\n",
      "3700-th evaluation: score=0.9865, divergence=0.6544, diversity=0.6643, num_succ=14, num_remain=12\n",
      "3800-th evaluation: score=0.9908, divergence=0.6624, diversity=0.6567, num_succ=15, num_remain=10\n",
      "3900-th evaluation: score=0.9952, divergence=0.6710, diversity=0.6483, num_succ=15, num_remain=12\n",
      "4000-th evaluation: score=1.0006, divergence=0.6795, diversity=0.6421, num_succ=18, num_remain=10\n",
      "4100-th evaluation: score=1.0055, divergence=0.6879, diversity=0.6352, num_succ=19, num_remain=16\n",
      "4200-th evaluation: score=1.0104, divergence=0.6967, diversity=0.6274, num_succ=19, num_remain=11\n",
      "4300-th evaluation: score=1.0147, divergence=0.7032, diversity=0.6231, num_succ=23, num_remain=7\n",
      "4400-th evaluation: score=1.0165, divergence=0.7057, diversity=0.6216, num_succ=25, num_remain=7\n",
      "4500-th evaluation: score=1.0186, divergence=0.7092, diversity=0.6188, num_succ=28, num_remain=6\n",
      "4600-th evaluation: score=1.0207, divergence=0.7130, diversity=0.6155, num_succ=31, num_remain=9\n",
      "4700-th evaluation: score=1.0232, divergence=0.7174, diversity=0.6117, num_succ=32, num_remain=7\n",
      "4800-th evaluation: score=1.0259, divergence=0.7213, diversity=0.6093, num_succ=33, num_remain=8\n",
      "4900-th evaluation: score=1.0279, divergence=0.7243, diversity=0.6072, num_succ=33, num_remain=5\n",
      "5000-th evaluation: score=1.0298, divergence=0.7274, diversity=0.6047, num_succ=37, num_remain=6\n",
      "5100-th evaluation: score=1.0316, divergence=0.7299, diversity=0.6034, num_succ=38, num_remain=9\n",
      "5200-th evaluation: score=1.0328, divergence=0.7318, diversity=0.6019, num_succ=39, num_remain=3\n",
      "5300-th evaluation: score=1.0339, divergence=0.7334, diversity=0.6009, num_succ=39, num_remain=3\n",
      "5400-th evaluation: score=1.0354, divergence=0.7355, diversity=0.5997, num_succ=42, num_remain=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500-th evaluation: score=1.0360, divergence=0.7365, diversity=0.5989, num_succ=42, num_remain=3\n",
      "5600-th evaluation: score=1.0365, divergence=0.7373, diversity=0.5984, num_succ=42, num_remain=1\n",
      "5700-th evaluation: score=1.0368, divergence=0.7374, diversity=0.5986, num_succ=42, num_remain=1\n",
      "5800-th evaluation: score=1.0369, divergence=0.7375, diversity=0.5988, num_succ=42, num_remain=1\n",
      "5900-th evaluation: score=1.0370, divergence=0.7375, diversity=0.5988, num_succ=42, num_remain=1\n",
      "6000-th evaluation: score=1.0370, divergence=0.7376, diversity=0.5989, num_succ=42, num_remain=1\n",
      "6100-th evaluation: score=1.0372, divergence=0.7377, diversity=0.5988, num_succ=42, num_remain=1\n",
      "6200-th evaluation: score=1.0372, divergence=0.7378, diversity=0.5989, num_succ=42, num_remain=1\n",
      "6300-th evaluation: score=1.0372, divergence=0.7378, diversity=0.5989, num_succ=42, num_remain=1\n",
      "6400-th evaluation: score=1.0372, divergence=0.7378, diversity=0.5989, num_succ=42, num_remain=1\n",
      "6500-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5989, num_succ=42, num_remain=1\n",
      "6600-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5989, num_succ=42, num_remain=1\n",
      "6700-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5989, num_succ=42, num_remain=1\n",
      "6800-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5989, num_succ=42, num_remain=1\n",
      "6900-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5989, num_succ=42, num_remain=1\n",
      "7000-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "7100-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "7200-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "7300-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "7400-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "7500-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "7600-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "7700-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "7800-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "7900-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "8000-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "8100-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "8200-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "8300-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "8400-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "8500-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "8600-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "8700-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "8800-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "8900-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "9000-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "9100-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "9200-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "9300-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "9400-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "9500-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "9600-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "9700-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "9800-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "9900-th evaluation: score=1.0373, divergence=0.7378, diversity=0.5990, num_succ=42, num_remain=1\n",
      "[0.14836762 0.07332168 0.06125456 0.06325026 0.07134303 0.0916761\n",
      " 0.11723134 0.13600647 0.06179306 0.06144179 0.12451596 0.07923913\n",
      " 0.05391075 0.05319842 0.19448299 0.06106948 0.17352019 0.05735954\n",
      " 0.10001207 0.08075959 0.06094558 0.05618597 0.07876291 0.13934648\n",
      " 0.04834833 0.07180632 0.07509398 0.17690301 0.05747254 0.15661347\n",
      " 0.09211882 0.11848432 0.04561466 0.0238438  0.08265158 0.07844493\n",
      " 0.0959966  0.06419793 0.10390526 0.06567269 0.14357827 0.12739169\n",
      " 0.06131912 0.10130218 0.04862353 0.06983055 0.10890922 0.10823791\n",
      " 0.08146353 0.11152577 0.09943785 0.09549316 0.1477412  0.11989425\n",
      " 0.12532862 0.08006396 0.08836091 0.13987919 0.05445917 0.06210968\n",
      " 0.0406236  0.10765765 0.08180673 0.1683681  0.09593127 0.11132255\n",
      " 0.09316653 0.20541879 0.09136539 0.0330521  0.10769964 0.08378069\n",
      " 0.03819327 0.06781089 0.08140395 0.08956564 0.10289177 0.13566632\n",
      " 0.09479228 0.13654044 0.07819376 0.1020676  0.08807001 0.07552614\n",
      " 0.1193604  0.09600203 0.05639838 0.01553589 0.09450052 0.10389755\n",
      " 0.12662412 0.06885346 0.14121261 0.14083062 0.05998663 0.101298\n",
      " 0.08248291 0.05822616 0.09844955 0.10891088]\n",
      "50\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "initial_evaluation: score=0.6251, divergence=0.0000, diversity=1.2501, num_succ=0, num_remain=7\n",
      "   0-th evaluation: score=0.6252, divergence=0.0002, diversity=1.2501, num_succ=0, num_remain=89\n",
      " 100-th evaluation: score=0.6543, divergence=0.0411, diversity=1.2264, num_succ=1, num_remain=42\n",
      " 200-th evaluation: score=0.6779, divergence=0.0880, diversity=1.1799, num_succ=1, num_remain=43\n",
      " 300-th evaluation: score=0.6985, divergence=0.1350, diversity=1.1270, num_succ=1, num_remain=36\n",
      " 400-th evaluation: score=0.7223, divergence=0.1870, diversity=1.0707, num_succ=3, num_remain=38\n",
      " 500-th evaluation: score=0.7584, divergence=0.2629, diversity=0.9910, num_succ=3, num_remain=47\n",
      " 600-th evaluation: score=0.7987, divergence=0.3340, diversity=0.9295, num_succ=6, num_remain=26\n",
      " 700-th evaluation: score=0.8302, divergence=0.3868, diversity=0.8868, num_succ=9, num_remain=29\n",
      " 800-th evaluation: score=0.8605, divergence=0.4326, diversity=0.8557, num_succ=17, num_remain=18\n",
      " 900-th evaluation: score=0.8761, divergence=0.4584, diversity=0.8354, num_succ=20, num_remain=13\n",
      "1000-th evaluation: score=0.8871, divergence=0.4761, diversity=0.8218, num_succ=21, num_remain=11\n",
      "1100-th evaluation: score=0.8910, divergence=0.4832, diversity=0.8155, num_succ=21, num_remain=13\n",
      "1200-th evaluation: score=0.8946, divergence=0.4900, diversity=0.8093, num_succ=21, num_remain=9\n",
      "1300-th evaluation: score=0.8997, divergence=0.4987, diversity=0.8021, num_succ=21, num_remain=9\n",
      "1400-th evaluation: score=0.9044, divergence=0.5062, diversity=0.7963, num_succ=22, num_remain=10\n",
      "1500-th evaluation: score=0.9136, divergence=0.5205, diversity=0.7860, num_succ=23, num_remain=9\n",
      "1600-th evaluation: score=0.9184, divergence=0.5283, diversity=0.7801, num_succ=23, num_remain=8\n",
      "1700-th evaluation: score=0.9250, divergence=0.5385, diversity=0.7730, num_succ=26, num_remain=14\n",
      "1800-th evaluation: score=0.9299, divergence=0.5462, diversity=0.7675, num_succ=28, num_remain=7\n",
      "1900-th evaluation: score=0.9324, divergence=0.5501, diversity=0.7645, num_succ=28, num_remain=5\n",
      "2000-th evaluation: score=0.9335, divergence=0.5520, diversity=0.7630, num_succ=28, num_remain=4\n",
      "2100-th evaluation: score=0.9338, divergence=0.5525, diversity=0.7626, num_succ=28, num_remain=4\n",
      "2200-th evaluation: score=0.9342, divergence=0.5530, diversity=0.7624, num_succ=28, num_remain=4\n",
      "2300-th evaluation: score=0.9344, divergence=0.5534, diversity=0.7620, num_succ=28, num_remain=4\n",
      "2400-th evaluation: score=0.9353, divergence=0.5548, diversity=0.7611, num_succ=28, num_remain=4\n",
      "2500-th evaluation: score=0.9355, divergence=0.5549, diversity=0.7611, num_succ=28, num_remain=4\n",
      "2600-th evaluation: score=0.9357, divergence=0.5554, diversity=0.7606, num_succ=28, num_remain=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700-th evaluation: score=0.9361, divergence=0.5560, diversity=0.7601, num_succ=28, num_remain=5\n",
      "2800-th evaluation: score=0.9381, divergence=0.5592, diversity=0.7577, num_succ=29, num_remain=8\n",
      "2900-th evaluation: score=0.9403, divergence=0.5627, diversity=0.7551, num_succ=30, num_remain=4\n",
      "3000-th evaluation: score=0.9417, divergence=0.5647, diversity=0.7541, num_succ=30, num_remain=5\n",
      "3100-th evaluation: score=0.9426, divergence=0.5656, diversity=0.7539, num_succ=30, num_remain=4\n",
      "3200-th evaluation: score=0.9436, divergence=0.5673, diversity=0.7526, num_succ=30, num_remain=4\n",
      "3300-th evaluation: score=0.9442, divergence=0.5683, diversity=0.7519, num_succ=30, num_remain=3\n",
      "3400-th evaluation: score=0.9448, divergence=0.5688, diversity=0.7520, num_succ=30, num_remain=3\n",
      "3500-th evaluation: score=0.9450, divergence=0.5690, diversity=0.7520, num_succ=30, num_remain=3\n",
      "3600-th evaluation: score=0.9452, divergence=0.5691, diversity=0.7522, num_succ=30, num_remain=3\n",
      "3700-th evaluation: score=0.9454, divergence=0.5693, diversity=0.7521, num_succ=30, num_remain=3\n",
      "3800-th evaluation: score=0.9458, divergence=0.5699, diversity=0.7517, num_succ=30, num_remain=3\n",
      "3900-th evaluation: score=0.9460, divergence=0.5700, diversity=0.7519, num_succ=30, num_remain=3\n",
      "4000-th evaluation: score=0.9462, divergence=0.5703, diversity=0.7517, num_succ=30, num_remain=3\n",
      "4100-th evaluation: score=0.9464, divergence=0.5706, diversity=0.7515, num_succ=30, num_remain=3\n",
      "4200-th evaluation: score=0.9466, divergence=0.5710, diversity=0.7513, num_succ=30, num_remain=3\n",
      "4300-th evaluation: score=0.9468, divergence=0.5712, diversity=0.7512, num_succ=30, num_remain=3\n",
      "4400-th evaluation: score=0.9474, divergence=0.5720, diversity=0.7507, num_succ=30, num_remain=3\n",
      "4500-th evaluation: score=0.9477, divergence=0.5727, diversity=0.7500, num_succ=30, num_remain=3\n",
      "4600-th evaluation: score=0.9479, divergence=0.5730, diversity=0.7498, num_succ=30, num_remain=3\n",
      "4700-th evaluation: score=0.9490, divergence=0.5745, diversity=0.7489, num_succ=30, num_remain=3\n",
      "4800-th evaluation: score=0.9491, divergence=0.5748, diversity=0.7487, num_succ=30, num_remain=3\n",
      "4900-th evaluation: score=0.9502, divergence=0.5763, diversity=0.7478, num_succ=30, num_remain=3\n",
      "5000-th evaluation: score=0.9504, divergence=0.5767, diversity=0.7473, num_succ=30, num_remain=3\n",
      "5100-th evaluation: score=0.9513, divergence=0.5781, diversity=0.7463, num_succ=30, num_remain=5\n",
      "5200-th evaluation: score=0.9524, divergence=0.5801, diversity=0.7445, num_succ=31, num_remain=3\n",
      "5300-th evaluation: score=0.9525, divergence=0.5804, diversity=0.7442, num_succ=31, num_remain=3\n",
      "5400-th evaluation: score=0.9532, divergence=0.5813, diversity=0.7437, num_succ=31, num_remain=3\n",
      "5500-th evaluation: score=0.9537, divergence=0.5826, diversity=0.7423, num_succ=31, num_remain=3\n",
      "5600-th evaluation: score=0.9556, divergence=0.5854, diversity=0.7405, num_succ=31, num_remain=3\n",
      "5700-th evaluation: score=0.9560, divergence=0.5859, diversity=0.7402, num_succ=31, num_remain=2\n",
      "5800-th evaluation: score=0.9565, divergence=0.5864, diversity=0.7402, num_succ=31, num_remain=2\n",
      "5900-th evaluation: score=0.9567, divergence=0.5866, diversity=0.7403, num_succ=31, num_remain=2\n",
      "6000-th evaluation: score=0.9569, divergence=0.5867, diversity=0.7403, num_succ=31, num_remain=2\n",
      "6100-th evaluation: score=0.9570, divergence=0.5868, diversity=0.7403, num_succ=31, num_remain=2\n",
      "6200-th evaluation: score=0.9571, divergence=0.5870, diversity=0.7402, num_succ=31, num_remain=3\n",
      "6300-th evaluation: score=0.9577, divergence=0.5877, diversity=0.7400, num_succ=32, num_remain=2\n",
      "6400-th evaluation: score=0.9578, divergence=0.5878, diversity=0.7400, num_succ=32, num_remain=2\n",
      "6500-th evaluation: score=0.9580, divergence=0.5881, diversity=0.7398, num_succ=32, num_remain=2\n",
      "6600-th evaluation: score=0.9580, divergence=0.5881, diversity=0.7398, num_succ=32, num_remain=2\n",
      "6700-th evaluation: score=0.9583, divergence=0.5886, diversity=0.7394, num_succ=32, num_remain=2\n",
      "6800-th evaluation: score=0.9592, divergence=0.5898, diversity=0.7387, num_succ=33, num_remain=2\n",
      "6900-th evaluation: score=0.9593, divergence=0.5899, diversity=0.7386, num_succ=33, num_remain=2\n",
      "7000-th evaluation: score=0.9595, divergence=0.5905, diversity=0.7380, num_succ=33, num_remain=2\n",
      "7100-th evaluation: score=0.9598, divergence=0.5910, diversity=0.7377, num_succ=34, num_remain=2\n",
      "7200-th evaluation: score=0.9608, divergence=0.5924, diversity=0.7369, num_succ=35, num_remain=2\n",
      "7300-th evaluation: score=0.9616, divergence=0.5935, diversity=0.7361, num_succ=35, num_remain=3\n",
      "7400-th evaluation: score=0.9630, divergence=0.5961, diversity=0.7338, num_succ=35, num_remain=3\n",
      "7500-th evaluation: score=0.9634, divergence=0.5966, diversity=0.7336, num_succ=36, num_remain=2\n",
      "7600-th evaluation: score=0.9640, divergence=0.5973, diversity=0.7334, num_succ=36, num_remain=2\n",
      "7700-th evaluation: score=0.9644, divergence=0.5980, diversity=0.7327, num_succ=37, num_remain=2\n",
      "7800-th evaluation: score=0.9649, divergence=0.5987, diversity=0.7324, num_succ=37, num_remain=2\n",
      "7900-th evaluation: score=0.9652, divergence=0.5991, diversity=0.7321, num_succ=37, num_remain=2\n",
      "8000-th evaluation: score=0.9658, divergence=0.5999, diversity=0.7319, num_succ=37, num_remain=1\n",
      "8100-th evaluation: score=0.9661, divergence=0.6001, diversity=0.7319, num_succ=37, num_remain=1\n",
      "8200-th evaluation: score=0.9663, divergence=0.6004, diversity=0.7319, num_succ=37, num_remain=1\n",
      "8300-th evaluation: score=0.9665, divergence=0.6005, diversity=0.7320, num_succ=37, num_remain=1\n",
      "8400-th evaluation: score=0.9666, divergence=0.6005, diversity=0.7321, num_succ=37, num_remain=1\n",
      "8500-th evaluation: score=0.9668, divergence=0.6006, diversity=0.7323, num_succ=37, num_remain=1\n",
      "8600-th evaluation: score=0.9669, divergence=0.6007, diversity=0.7324, num_succ=37, num_remain=1\n",
      "8700-th evaluation: score=0.9670, divergence=0.6007, diversity=0.7325, num_succ=37, num_remain=1\n",
      "8800-th evaluation: score=0.9670, divergence=0.6008, diversity=0.7326, num_succ=37, num_remain=1\n",
      "8900-th evaluation: score=0.9672, divergence=0.6009, diversity=0.7325, num_succ=38, num_remain=1\n",
      "9000-th evaluation: score=0.9672, divergence=0.6010, diversity=0.7326, num_succ=38, num_remain=1\n",
      "9100-th evaluation: score=0.9673, divergence=0.6010, diversity=0.7326, num_succ=38, num_remain=1\n",
      "9200-th evaluation: score=0.9674, divergence=0.6010, diversity=0.7327, num_succ=38, num_remain=1\n",
      "9300-th evaluation: score=0.9674, divergence=0.6010, diversity=0.7328, num_succ=38, num_remain=1\n",
      "9400-th evaluation: score=0.9674, divergence=0.6011, diversity=0.7328, num_succ=38, num_remain=1\n",
      "9500-th evaluation: score=0.9675, divergence=0.6011, diversity=0.7328, num_succ=38, num_remain=1\n",
      "9600-th evaluation: score=0.9675, divergence=0.6011, diversity=0.7328, num_succ=38, num_remain=1\n",
      "9700-th evaluation: score=0.9675, divergence=0.6011, diversity=0.7329, num_succ=38, num_remain=1\n",
      "9800-th evaluation: score=0.9676, divergence=0.6011, diversity=0.7329, num_succ=38, num_remain=1\n",
      "9900-th evaluation: score=0.9676, divergence=0.6012, diversity=0.7328, num_succ=38, num_remain=1\n",
      "[0.09097264 0.09049462 0.28398182 0.07938371 0.08335406 0.28855528\n",
      " 0.04201645 0.28699834 0.08571074 0.03837248 0.09419625 0.04917015\n",
      " 0.11417944 0.06946972 0.10200789 0.06024984 0.04814074 0.09525302\n",
      " 0.08663685 0.10712181 0.03862244 0.07829856 0.0187929  0.10770687\n",
      " 0.02500413 0.04717469 0.06770003 0.19371004 0.09595722 0.03517684\n",
      " 0.08815642 0.01507552 0.03682945 0.01493931 0.06519058 0.10196386\n",
      " 0.05365983 0.07585959 0.07784099 0.08708851 0.04960096 0.01643963\n",
      " 0.09513582 0.0575043  0.0718454  0.05849461 0.05604206 0.11221877\n",
      " 0.01757536 0.03678151 0.0418589  0.02598485 0.07706841 0.08736724\n",
      " 0.08665248 0.06826705 0.03041438 0.11830296 0.18980084 0.0250986\n",
      " 0.05023781 0.07888407 0.05920436 0.08174316 0.06524189 0.04003911\n",
      " 0.04139655 0.13322961 0.04066765 0.05385072 0.08053197 0.01819229\n",
      " 0.16980439 0.15359326 0.27913627 0.07696816 0.11390573 0.00298956\n",
      " 0.19488716 0.04555772 0.0729731  0.01566629 0.06995807 0.03914707\n",
      " 0.06651693 0.07767549 0.12749177 0.0417996  0.15923704 0.09157273\n",
      " 0.08381171 0.00035222 0.1126585  0.06674049 0.11361555 0.05695274\n",
      " 0.08922734 0.04037931 0.13779647 0.09765041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "initial_evaluation: score=0.5554, divergence=0.0000, diversity=1.1108, num_succ=0, num_remain=9\n",
      "   0-th evaluation: score=0.5561, divergence=0.0006, diversity=1.1110, num_succ=0, num_remain=88\n",
      " 100-th evaluation: score=0.5798, divergence=0.0268, diversity=1.1059, num_succ=1, num_remain=22\n",
      " 200-th evaluation: score=0.5876, divergence=0.0366, diversity=1.1019, num_succ=3, num_remain=20\n",
      " 300-th evaluation: score=0.5933, divergence=0.0438, diversity=1.0990, num_succ=5, num_remain=15\n",
      " 400-th evaluation: score=0.5941, divergence=0.0451, diversity=1.0981, num_succ=5, num_remain=12\n",
      " 500-th evaluation: score=0.5966, divergence=0.0480, diversity=1.0972, num_succ=5, num_remain=13\n",
      " 600-th evaluation: score=0.6003, divergence=0.0528, diversity=1.0951, num_succ=5, num_remain=17\n",
      " 700-th evaluation: score=0.6057, divergence=0.0592, diversity=1.0930, num_succ=6, num_remain=14\n",
      " 800-th evaluation: score=0.6101, divergence=0.0648, diversity=1.0906, num_succ=6, num_remain=13\n",
      " 900-th evaluation: score=0.6124, divergence=0.0681, diversity=1.0887, num_succ=7, num_remain=14\n",
      "1000-th evaluation: score=0.6153, divergence=0.0716, diversity=1.0874, num_succ=7, num_remain=16\n",
      "1100-th evaluation: score=0.6191, divergence=0.0768, diversity=1.0846, num_succ=7, num_remain=14\n",
      "1200-th evaluation: score=0.6252, divergence=0.0842, diversity=1.0821, num_succ=7, num_remain=16\n",
      "1300-th evaluation: score=0.6299, divergence=0.0905, diversity=1.0789, num_succ=7, num_remain=28\n",
      "1400-th evaluation: score=0.6344, divergence=0.0970, diversity=1.0748, num_succ=7, num_remain=20\n",
      "1500-th evaluation: score=0.6401, divergence=0.1053, diversity=1.0696, num_succ=7, num_remain=28\n",
      "1600-th evaluation: score=0.6446, divergence=0.1115, diversity=1.0662, num_succ=7, num_remain=26\n",
      "1700-th evaluation: score=0.6482, divergence=0.1169, diversity=1.0626, num_succ=7, num_remain=23\n",
      "1800-th evaluation: score=0.6505, divergence=0.1198, diversity=1.0614, num_succ=7, num_remain=18\n",
      "1900-th evaluation: score=0.6534, divergence=0.1238, diversity=1.0593, num_succ=8, num_remain=18\n",
      "2000-th evaluation: score=0.6561, divergence=0.1261, diversity=1.0600, num_succ=8, num_remain=20\n",
      "2100-th evaluation: score=0.6590, divergence=0.1295, diversity=1.0590, num_succ=8, num_remain=21\n",
      "2200-th evaluation: score=0.6608, divergence=0.1314, diversity=1.0588, num_succ=8, num_remain=15\n",
      "2300-th evaluation: score=0.6623, divergence=0.1325, diversity=1.0597, num_succ=8, num_remain=14\n",
      "2400-th evaluation: score=0.6643, divergence=0.1348, diversity=1.0591, num_succ=8, num_remain=21\n",
      "2500-th evaluation: score=0.6662, divergence=0.1367, diversity=1.0589, num_succ=8, num_remain=14\n",
      "2600-th evaluation: score=0.6673, divergence=0.1377, diversity=1.0594, num_succ=8, num_remain=13\n",
      "2700-th evaluation: score=0.6684, divergence=0.1385, diversity=1.0599, num_succ=8, num_remain=14\n",
      "2800-th evaluation: score=0.6689, divergence=0.1388, diversity=1.0601, num_succ=8, num_remain=13\n",
      "2900-th evaluation: score=0.6701, divergence=0.1402, diversity=1.0599, num_succ=8, num_remain=14\n",
      "3000-th evaluation: score=0.6713, divergence=0.1412, diversity=1.0602, num_succ=9, num_remain=13\n",
      "3100-th evaluation: score=0.6717, divergence=0.1416, diversity=1.0603, num_succ=9, num_remain=13\n",
      "3200-th evaluation: score=0.6725, divergence=0.1423, diversity=1.0603, num_succ=9, num_remain=14\n",
      "3300-th evaluation: score=0.6729, divergence=0.1425, diversity=1.0608, num_succ=9, num_remain=12\n",
      "3400-th evaluation: score=0.6733, divergence=0.1428, diversity=1.0610, num_succ=9, num_remain=12\n",
      "3500-th evaluation: score=0.6737, divergence=0.1430, diversity=1.0613, num_succ=9, num_remain=12\n",
      "3600-th evaluation: score=0.6741, divergence=0.1434, diversity=1.0614, num_succ=9, num_remain=13\n",
      "3700-th evaluation: score=0.6745, divergence=0.1437, diversity=1.0617, num_succ=9, num_remain=12\n",
      "3800-th evaluation: score=0.6750, divergence=0.1442, diversity=1.0617, num_succ=9, num_remain=12\n",
      "3900-th evaluation: score=0.6752, divergence=0.1443, diversity=1.0618, num_succ=9, num_remain=12\n",
      "4000-th evaluation: score=0.6754, divergence=0.1444, diversity=1.0619, num_succ=9, num_remain=12\n",
      "4100-th evaluation: score=0.6757, divergence=0.1448, diversity=1.0618, num_succ=9, num_remain=12\n",
      "4200-th evaluation: score=0.6763, divergence=0.1455, diversity=1.0616, num_succ=9, num_remain=12\n",
      "4300-th evaluation: score=0.6765, divergence=0.1456, diversity=1.0616, num_succ=9, num_remain=12\n",
      "4400-th evaluation: score=0.6766, divergence=0.1458, diversity=1.0615, num_succ=9, num_remain=12\n",
      "4500-th evaluation: score=0.6770, divergence=0.1465, diversity=1.0610, num_succ=9, num_remain=12\n",
      "4600-th evaluation: score=0.6781, divergence=0.1478, diversity=1.0606, num_succ=9, num_remain=15\n",
      "4700-th evaluation: score=0.6792, divergence=0.1488, diversity=1.0608, num_succ=10, num_remain=18\n",
      "4800-th evaluation: score=0.6806, divergence=0.1505, diversity=1.0603, num_succ=10, num_remain=18\n",
      "4900-th evaluation: score=0.6809, divergence=0.1510, diversity=1.0598, num_succ=10, num_remain=15\n",
      "5000-th evaluation: score=0.6810, divergence=0.1511, diversity=1.0598, num_succ=10, num_remain=17\n",
      "5100-th evaluation: score=0.6810, divergence=0.1511, diversity=1.0598, num_succ=10, num_remain=17\n",
      "5200-th evaluation: score=0.6810, divergence=0.1511, diversity=1.0599, num_succ=10, num_remain=15\n",
      "5300-th evaluation: score=0.6816, divergence=0.1519, diversity=1.0595, num_succ=10, num_remain=14\n",
      "5400-th evaluation: score=0.6823, divergence=0.1524, diversity=1.0598, num_succ=10, num_remain=15\n",
      "5500-th evaluation: score=0.6827, divergence=0.1527, diversity=1.0599, num_succ=10, num_remain=13\n",
      "5600-th evaluation: score=0.6832, divergence=0.1532, diversity=1.0600, num_succ=10, num_remain=13\n",
      "5700-th evaluation: score=0.6834, divergence=0.1533, diversity=1.0601, num_succ=10, num_remain=13\n",
      "5800-th evaluation: score=0.6838, divergence=0.1536, diversity=1.0602, num_succ=10, num_remain=13\n",
      "5900-th evaluation: score=0.6839, divergence=0.1537, diversity=1.0603, num_succ=10, num_remain=13\n",
      "6000-th evaluation: score=0.6840, divergence=0.1538, diversity=1.0604, num_succ=10, num_remain=13\n",
      "6100-th evaluation: score=0.6850, divergence=0.1548, diversity=1.0602, num_succ=10, num_remain=14\n",
      "6200-th evaluation: score=0.6852, divergence=0.1550, diversity=1.0603, num_succ=10, num_remain=13\n",
      "6300-th evaluation: score=0.6853, divergence=0.1551, diversity=1.0604, num_succ=10, num_remain=13\n",
      "6400-th evaluation: score=0.6854, divergence=0.1551, diversity=1.0605, num_succ=10, num_remain=13\n",
      "6500-th evaluation: score=0.6855, divergence=0.1552, diversity=1.0606, num_succ=10, num_remain=12\n",
      "6600-th evaluation: score=0.6856, divergence=0.1552, diversity=1.0606, num_succ=10, num_remain=12\n",
      "6700-th evaluation: score=0.6857, divergence=0.1553, diversity=1.0607, num_succ=10, num_remain=12\n",
      "6800-th evaluation: score=0.6858, divergence=0.1555, diversity=1.0607, num_succ=10, num_remain=12\n",
      "6900-th evaluation: score=0.6859, divergence=0.1555, diversity=1.0608, num_succ=10, num_remain=12\n",
      "7000-th evaluation: score=0.6860, divergence=0.1556, diversity=1.0607, num_succ=10, num_remain=12\n",
      "7100-th evaluation: score=0.6860, divergence=0.1556, diversity=1.0608, num_succ=10, num_remain=12\n",
      "7200-th evaluation: score=0.6861, divergence=0.1557, diversity=1.0608, num_succ=10, num_remain=12\n",
      "7300-th evaluation: score=0.6862, divergence=0.1558, diversity=1.0608, num_succ=10, num_remain=12\n",
      "7400-th evaluation: score=0.6866, divergence=0.1560, diversity=1.0611, num_succ=10, num_remain=12\n",
      "7500-th evaluation: score=0.6867, divergence=0.1561, diversity=1.0612, num_succ=10, num_remain=13\n",
      "7600-th evaluation: score=0.6867, divergence=0.1561, diversity=1.0612, num_succ=10, num_remain=12\n",
      "7700-th evaluation: score=0.6867, divergence=0.1561, diversity=1.0612, num_succ=10, num_remain=12\n",
      "7800-th evaluation: score=0.6868, divergence=0.1561, diversity=1.0613, num_succ=10, num_remain=12\n",
      "7900-th evaluation: score=0.6868, divergence=0.1562, diversity=1.0613, num_succ=10, num_remain=12\n",
      "8000-th evaluation: score=0.6868, divergence=0.1562, diversity=1.0613, num_succ=10, num_remain=12\n",
      "8100-th evaluation: score=0.6869, divergence=0.1562, diversity=1.0614, num_succ=10, num_remain=12\n",
      "8200-th evaluation: score=0.6869, divergence=0.1563, diversity=1.0614, num_succ=10, num_remain=12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8300-th evaluation: score=0.6870, divergence=0.1563, diversity=1.0614, num_succ=10, num_remain=12\n",
      "8400-th evaluation: score=0.6873, divergence=0.1566, diversity=1.0613, num_succ=10, num_remain=12\n",
      "8500-th evaluation: score=0.6873, divergence=0.1567, diversity=1.0613, num_succ=10, num_remain=12\n",
      "8600-th evaluation: score=0.6873, divergence=0.1567, diversity=1.0613, num_succ=10, num_remain=12\n",
      "8700-th evaluation: score=0.6873, divergence=0.1567, diversity=1.0613, num_succ=10, num_remain=12\n",
      "8800-th evaluation: score=0.6873, divergence=0.1567, diversity=1.0613, num_succ=10, num_remain=12\n",
      "8900-th evaluation: score=0.6874, divergence=0.1567, diversity=1.0613, num_succ=10, num_remain=12\n",
      "9000-th evaluation: score=0.6874, divergence=0.1567, diversity=1.0613, num_succ=10, num_remain=12\n",
      "9100-th evaluation: score=0.6874, divergence=0.1567, diversity=1.0613, num_succ=10, num_remain=12\n",
      "9200-th evaluation: score=0.6874, divergence=0.1568, diversity=1.0614, num_succ=10, num_remain=12\n",
      "9300-th evaluation: score=0.6874, divergence=0.1568, diversity=1.0614, num_succ=10, num_remain=12\n",
      "9400-th evaluation: score=0.6875, divergence=0.1568, diversity=1.0614, num_succ=10, num_remain=12\n",
      "9500-th evaluation: score=0.6875, divergence=0.1568, diversity=1.0614, num_succ=10, num_remain=12\n",
      "9600-th evaluation: score=0.6875, divergence=0.1568, diversity=1.0614, num_succ=10, num_remain=12\n",
      "9700-th evaluation: score=0.6875, divergence=0.1568, diversity=1.0614, num_succ=10, num_remain=12\n",
      "9800-th evaluation: score=0.6876, divergence=0.1568, diversity=1.0615, num_succ=10, num_remain=12\n",
      "9900-th evaluation: score=0.6876, divergence=0.1568, diversity=1.0615, num_succ=10, num_remain=12\n",
      "[1.61656230e-01 1.19021820e-01 9.19861475e-02 1.25413811e-01\n",
      " 6.67609477e-02 1.61345788e-05 3.96603055e-03 5.41452720e-03\n",
      " 2.93704375e-02 1.81093109e-02 4.08085587e-02 4.48356201e-02\n",
      " 2.35053292e-02 9.54908047e-04 6.81364880e-03 2.25106999e-01\n",
      " 1.98951767e-03 2.39978925e-03 8.08995334e-04 2.53782354e-02\n",
      " 5.45834419e-02 1.46769140e-01 1.41850360e-01 5.31405033e-03\n",
      " 5.87900341e-02 3.36883529e-02 6.22708402e-03 1.48887680e-01\n",
      " 5.59044268e-03 9.36820590e-02 4.11317360e-02 1.12032957e-01\n",
      " 1.47818535e-01 1.33165532e-01 5.13128710e-02 7.47484816e-02\n",
      " 3.88057665e-02 7.80956782e-03 8.04795487e-02 6.92488027e-02\n",
      " 1.04997795e-02 5.59970792e-02 7.75080342e-03 3.44065306e-02\n",
      " 1.31874550e-02 8.77942329e-03 1.00085220e-01 1.79282097e-01\n",
      " 3.71524848e-02 1.99723421e-02 1.20520771e-01 3.70550298e-03\n",
      " 7.65767074e-02 1.52289378e-02 2.51953589e-02 2.66214290e-01\n",
      " 3.17666652e-02 1.98706241e-02 4.98238491e-02 2.25544143e-03\n",
      " 3.50924390e-03 3.73556617e-01 1.11750575e-02 1.94333716e-02\n",
      " 3.91215509e-02 7.45487150e-02 2.06010727e-01 3.59095286e-02\n",
      " 5.57900278e-03 1.81686689e-02 1.00681660e-01 4.12475380e-02\n",
      " 1.45803386e-01 2.08851600e-02 1.41055071e-02 2.78903732e-02\n",
      " 4.76072601e-03 1.47183891e-01 1.80898847e-02 5.56774095e-02\n",
      " 3.71128768e-02 3.01343207e-02 9.56052037e-02 1.46872207e-01\n",
      " 1.02207970e-02 1.99264746e-03 1.77528932e-03 6.79621914e-03\n",
      " 1.67736808e-01 1.22602725e-01 1.76937511e-02 8.77849514e-02\n",
      " 1.16629369e-01 6.60066157e-03 1.50686119e-01 1.59580697e-02\n",
      " 8.38480063e-03 1.30131907e-01 4.30730981e-01 2.61337007e-04]\n",
      "52\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "initial_evaluation: score=0.5422, divergence=0.0000, diversity=1.0845, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.5433, divergence=0.0009, diversity=1.0848, num_succ=1, num_remain=92\n",
      " 100-th evaluation: score=0.5819, divergence=0.0436, diversity=1.0766, num_succ=4, num_remain=33\n",
      " 200-th evaluation: score=0.5970, divergence=0.0644, diversity=1.0653, num_succ=6, num_remain=29\n",
      " 300-th evaluation: score=0.6120, divergence=0.0830, diversity=1.0578, num_succ=6, num_remain=29\n",
      " 400-th evaluation: score=0.6205, divergence=0.0939, diversity=1.0532, num_succ=6, num_remain=28\n",
      " 500-th evaluation: score=0.6255, divergence=0.1009, diversity=1.0493, num_succ=7, num_remain=36\n",
      " 600-th evaluation: score=0.6315, divergence=0.1091, diversity=1.0448, num_succ=7, num_remain=25\n",
      " 700-th evaluation: score=0.6364, divergence=0.1150, diversity=1.0428, num_succ=7, num_remain=20\n",
      " 800-th evaluation: score=0.6398, divergence=0.1196, diversity=1.0404, num_succ=7, num_remain=21\n",
      " 900-th evaluation: score=0.6438, divergence=0.1245, diversity=1.0386, num_succ=7, num_remain=19\n",
      "1000-th evaluation: score=0.6481, divergence=0.1294, diversity=1.0374, num_succ=7, num_remain=18\n",
      "1100-th evaluation: score=0.6525, divergence=0.1345, diversity=1.0359, num_succ=7, num_remain=22\n",
      "1200-th evaluation: score=0.6557, divergence=0.1387, diversity=1.0341, num_succ=7, num_remain=17\n",
      "1300-th evaluation: score=0.6579, divergence=0.1417, diversity=1.0325, num_succ=7, num_remain=20\n",
      "1400-th evaluation: score=0.6609, divergence=0.1451, diversity=1.0315, num_succ=8, num_remain=20\n",
      "1500-th evaluation: score=0.6641, divergence=0.1497, diversity=1.0289, num_succ=8, num_remain=18\n",
      "1600-th evaluation: score=0.6658, divergence=0.1519, diversity=1.0278, num_succ=8, num_remain=20\n",
      "1700-th evaluation: score=0.6676, divergence=0.1548, diversity=1.0258, num_succ=8, num_remain=18\n",
      "1800-th evaluation: score=0.6723, divergence=0.1617, diversity=1.0212, num_succ=9, num_remain=21\n",
      "1900-th evaluation: score=0.6748, divergence=0.1648, diversity=1.0202, num_succ=9, num_remain=16\n",
      "2000-th evaluation: score=0.6761, divergence=0.1660, diversity=1.0203, num_succ=9, num_remain=17\n",
      "2100-th evaluation: score=0.6780, divergence=0.1689, diversity=1.0182, num_succ=9, num_remain=16\n",
      "2200-th evaluation: score=0.6789, divergence=0.1698, diversity=1.0183, num_succ=9, num_remain=15\n",
      "2300-th evaluation: score=0.6797, divergence=0.1708, diversity=1.0179, num_succ=9, num_remain=15\n",
      "2400-th evaluation: score=0.6812, divergence=0.1730, diversity=1.0163, num_succ=9, num_remain=18\n",
      "2500-th evaluation: score=0.6826, divergence=0.1747, diversity=1.0157, num_succ=9, num_remain=14\n",
      "2600-th evaluation: score=0.6835, divergence=0.1755, diversity=1.0160, num_succ=9, num_remain=15\n",
      "2700-th evaluation: score=0.6841, divergence=0.1759, diversity=1.0165, num_succ=9, num_remain=14\n",
      "2800-th evaluation: score=0.6844, divergence=0.1761, diversity=1.0168, num_succ=9, num_remain=14\n",
      "2900-th evaluation: score=0.6853, divergence=0.1771, diversity=1.0163, num_succ=9, num_remain=15\n",
      "3000-th evaluation: score=0.6857, divergence=0.1774, diversity=1.0166, num_succ=9, num_remain=14\n",
      "3100-th evaluation: score=0.6861, divergence=0.1776, diversity=1.0169, num_succ=9, num_remain=13\n",
      "3200-th evaluation: score=0.6866, divergence=0.1779, diversity=1.0173, num_succ=9, num_remain=13\n",
      "3300-th evaluation: score=0.6869, divergence=0.1781, diversity=1.0176, num_succ=9, num_remain=14\n",
      "3400-th evaluation: score=0.6872, divergence=0.1784, diversity=1.0175, num_succ=9, num_remain=14\n",
      "3500-th evaluation: score=0.6885, divergence=0.1802, diversity=1.0166, num_succ=9, num_remain=15\n",
      "3600-th evaluation: score=0.6887, divergence=0.1803, diversity=1.0167, num_succ=9, num_remain=15\n",
      "3700-th evaluation: score=0.6888, divergence=0.1804, diversity=1.0169, num_succ=9, num_remain=14\n",
      "3800-th evaluation: score=0.6890, divergence=0.1805, diversity=1.0171, num_succ=9, num_remain=13\n",
      "3900-th evaluation: score=0.6892, divergence=0.1808, diversity=1.0170, num_succ=9, num_remain=14\n",
      "4000-th evaluation: score=0.6895, divergence=0.1811, diversity=1.0168, num_succ=9, num_remain=14\n",
      "4100-th evaluation: score=0.6896, divergence=0.1812, diversity=1.0168, num_succ=9, num_remain=14\n",
      "4200-th evaluation: score=0.6899, divergence=0.1814, diversity=1.0169, num_succ=9, num_remain=14\n",
      "4300-th evaluation: score=0.6901, divergence=0.1816, diversity=1.0171, num_succ=9, num_remain=13\n",
      "4400-th evaluation: score=0.6903, divergence=0.1817, diversity=1.0171, num_succ=9, num_remain=13\n",
      "4500-th evaluation: score=0.6905, divergence=0.1819, diversity=1.0171, num_succ=9, num_remain=13\n",
      "4600-th evaluation: score=0.6906, divergence=0.1820, diversity=1.0172, num_succ=9, num_remain=13\n",
      "4700-th evaluation: score=0.6914, divergence=0.1835, diversity=1.0158, num_succ=9, num_remain=17\n",
      "4800-th evaluation: score=0.6916, divergence=0.1838, diversity=1.0155, num_succ=9, num_remain=15\n",
      "4900-th evaluation: score=0.6919, divergence=0.1842, diversity=1.0155, num_succ=9, num_remain=14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000-th evaluation: score=0.6920, divergence=0.1842, diversity=1.0156, num_succ=9, num_remain=13\n",
      "5100-th evaluation: score=0.6922, divergence=0.1843, diversity=1.0157, num_succ=9, num_remain=13\n",
      "5200-th evaluation: score=0.6923, divergence=0.1844, diversity=1.0158, num_succ=9, num_remain=13\n",
      "5300-th evaluation: score=0.6925, divergence=0.1845, diversity=1.0159, num_succ=9, num_remain=13\n",
      "5400-th evaluation: score=0.6926, divergence=0.1846, diversity=1.0159, num_succ=9, num_remain=13\n",
      "5500-th evaluation: score=0.6927, divergence=0.1847, diversity=1.0160, num_succ=9, num_remain=13\n",
      "5600-th evaluation: score=0.6927, divergence=0.1847, diversity=1.0161, num_succ=9, num_remain=13\n",
      "5700-th evaluation: score=0.6928, divergence=0.1847, diversity=1.0161, num_succ=9, num_remain=13\n",
      "5800-th evaluation: score=0.6929, divergence=0.1848, diversity=1.0161, num_succ=9, num_remain=13\n",
      "5900-th evaluation: score=0.6929, divergence=0.1849, diversity=1.0161, num_succ=9, num_remain=13\n",
      "6000-th evaluation: score=0.6931, divergence=0.1852, diversity=1.0159, num_succ=9, num_remain=13\n",
      "6100-th evaluation: score=0.6932, divergence=0.1852, diversity=1.0160, num_succ=9, num_remain=13\n",
      "6200-th evaluation: score=0.6933, divergence=0.1852, diversity=1.0160, num_succ=9, num_remain=13\n",
      "6300-th evaluation: score=0.6933, divergence=0.1853, diversity=1.0161, num_succ=9, num_remain=13\n",
      "6400-th evaluation: score=0.6934, divergence=0.1854, diversity=1.0161, num_succ=9, num_remain=13\n",
      "6500-th evaluation: score=0.6935, divergence=0.1854, diversity=1.0162, num_succ=9, num_remain=13\n",
      "6600-th evaluation: score=0.6936, divergence=0.1855, diversity=1.0162, num_succ=9, num_remain=13\n",
      "6700-th evaluation: score=0.6936, divergence=0.1855, diversity=1.0162, num_succ=9, num_remain=13\n",
      "6800-th evaluation: score=0.6937, divergence=0.1855, diversity=1.0163, num_succ=9, num_remain=13\n",
      "6900-th evaluation: score=0.6937, divergence=0.1855, diversity=1.0163, num_succ=9, num_remain=14\n",
      "7000-th evaluation: score=0.6937, divergence=0.1856, diversity=1.0163, num_succ=9, num_remain=13\n",
      "7100-th evaluation: score=0.6938, divergence=0.1856, diversity=1.0163, num_succ=9, num_remain=13\n",
      "7200-th evaluation: score=0.6938, divergence=0.1857, diversity=1.0164, num_succ=9, num_remain=13\n",
      "7300-th evaluation: score=0.6939, divergence=0.1857, diversity=1.0164, num_succ=9, num_remain=13\n",
      "7400-th evaluation: score=0.6939, divergence=0.1857, diversity=1.0165, num_succ=9, num_remain=13\n",
      "7500-th evaluation: score=0.6940, divergence=0.1857, diversity=1.0165, num_succ=9, num_remain=13\n",
      "7600-th evaluation: score=0.6940, divergence=0.1858, diversity=1.0165, num_succ=9, num_remain=13\n",
      "7700-th evaluation: score=0.6941, divergence=0.1858, diversity=1.0166, num_succ=9, num_remain=13\n",
      "7800-th evaluation: score=0.6941, divergence=0.1858, diversity=1.0166, num_succ=9, num_remain=13\n",
      "7900-th evaluation: score=0.6942, divergence=0.1858, diversity=1.0166, num_succ=9, num_remain=13\n",
      "8000-th evaluation: score=0.6942, divergence=0.1859, diversity=1.0167, num_succ=9, num_remain=13\n",
      "8100-th evaluation: score=0.6942, divergence=0.1859, diversity=1.0167, num_succ=9, num_remain=13\n",
      "8200-th evaluation: score=0.6943, divergence=0.1859, diversity=1.0167, num_succ=9, num_remain=13\n",
      "8300-th evaluation: score=0.6943, divergence=0.1859, diversity=1.0167, num_succ=9, num_remain=13\n",
      "8400-th evaluation: score=0.6944, divergence=0.1860, diversity=1.0167, num_succ=9, num_remain=13\n",
      "8500-th evaluation: score=0.6944, divergence=0.1860, diversity=1.0167, num_succ=9, num_remain=13\n",
      "8600-th evaluation: score=0.6944, divergence=0.1861, diversity=1.0167, num_succ=9, num_remain=13\n",
      "8700-th evaluation: score=0.6944, divergence=0.1861, diversity=1.0167, num_succ=9, num_remain=13\n",
      "8800-th evaluation: score=0.6945, divergence=0.1861, diversity=1.0167, num_succ=9, num_remain=13\n",
      "8900-th evaluation: score=0.6945, divergence=0.1861, diversity=1.0167, num_succ=9, num_remain=13\n",
      "9000-th evaluation: score=0.6945, divergence=0.1861, diversity=1.0168, num_succ=9, num_remain=13\n",
      "9100-th evaluation: score=0.6945, divergence=0.1862, diversity=1.0168, num_succ=9, num_remain=13\n",
      "9200-th evaluation: score=0.6946, divergence=0.1862, diversity=1.0168, num_succ=9, num_remain=13\n",
      "9300-th evaluation: score=0.6946, divergence=0.1862, diversity=1.0168, num_succ=9, num_remain=13\n",
      "9400-th evaluation: score=0.6946, divergence=0.1862, diversity=1.0168, num_succ=9, num_remain=13\n",
      "9500-th evaluation: score=0.6946, divergence=0.1862, diversity=1.0169, num_succ=9, num_remain=13\n",
      "9600-th evaluation: score=0.6947, divergence=0.1862, diversity=1.0169, num_succ=9, num_remain=13\n",
      "9700-th evaluation: score=0.6947, divergence=0.1862, diversity=1.0169, num_succ=9, num_remain=13\n",
      "9800-th evaluation: score=0.6947, divergence=0.1863, diversity=1.0169, num_succ=9, num_remain=13\n",
      "9900-th evaluation: score=0.6947, divergence=0.1863, diversity=1.0169, num_succ=9, num_remain=13\n",
      "[5.70696953e-02 5.83132784e-02 1.79362253e-01 4.46054195e-02\n",
      " 4.21250952e-02 2.36480982e-02 7.47433364e-02 5.87768188e-02\n",
      " 4.27654486e-02 1.47188800e-02 3.07161229e-02 6.45336647e-02\n",
      " 8.67131565e-03 2.13234910e-01 7.51292716e-02 5.16688195e-02\n",
      " 1.28958872e-02 2.22155386e-02 1.17440366e-02 2.46827492e-02\n",
      " 4.51087444e-02 9.64969817e-02 1.23085714e-01 7.26821433e-03\n",
      " 6.18811520e-02 1.05834942e-01 3.11735182e-02 1.60659155e-02\n",
      " 3.92435047e-03 9.82747417e-03 4.69035459e-02 2.14150524e-01\n",
      " 1.45462481e-02 1.39303228e-01 1.03625317e-01 1.08895816e-01\n",
      " 1.37790023e-02 1.16668115e-01 6.44563763e-02 1.67671494e-03\n",
      " 2.00987232e-02 4.08084682e-02 3.78834948e-01 9.00595544e-02\n",
      " 3.17187182e-02 9.69041395e-02 1.59689693e-01 9.21652833e-02\n",
      " 1.79394245e-01 6.85661556e-02 1.44830046e-01 5.40674842e-02\n",
      " 1.63409292e-01 1.89658779e-02 1.71398443e-02 6.16150771e-02\n",
      " 7.11648832e-02 1.55515168e-01 1.93658137e-03 4.78842851e-02\n",
      " 2.98007621e-02 4.99959057e-02 2.28187872e-01 2.21037871e-02\n",
      " 5.25789856e-02 1.54866959e-02 1.87388273e-02 4.99789909e-03\n",
      " 9.38484601e-02 8.10894747e-05 3.67546280e-02 6.60600474e-03\n",
      " 5.19954581e-03 3.83980202e-02 1.73222702e-01 1.48020600e-02\n",
      " 5.00600804e-04 2.76268039e-02 1.40582478e-01 1.65565322e-01\n",
      " 4.68431089e-03 8.87220215e-03 2.99710500e-02 5.84912318e-02\n",
      " 2.11309035e-02 2.11504346e-01 1.11088779e-02 3.89933943e-02\n",
      " 2.70393867e-01 1.01950376e-02 5.92148287e-02 3.79322625e-02\n",
      " 3.37128224e-02 3.35974219e-01 1.90785796e-02 6.90818973e-03\n",
      " 3.24689225e-02 1.24385426e-01 3.48871627e-02 4.35242054e-02]\n",
      "53\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "initial_evaluation: score=0.3523, divergence=0.0000, diversity=0.7046, num_succ=0, num_remain=5\n",
      "   0-th evaluation: score=0.3528, divergence=0.0006, diversity=0.7045, num_succ=0, num_remain=85\n",
      " 100-th evaluation: score=0.3963, divergence=0.0442, diversity=0.7041, num_succ=12, num_remain=26\n",
      " 200-th evaluation: score=0.4060, divergence=0.0532, diversity=0.7056, num_succ=15, num_remain=11\n",
      " 300-th evaluation: score=0.4125, divergence=0.0595, diversity=0.7060, num_succ=16, num_remain=3\n",
      " 400-th evaluation: score=0.4139, divergence=0.0607, diversity=0.7064, num_succ=16, num_remain=3\n",
      " 500-th evaluation: score=0.4174, divergence=0.0637, diversity=0.7074, num_succ=18, num_remain=3\n",
      " 600-th evaluation: score=0.4205, divergence=0.0669, diversity=0.7071, num_succ=18, num_remain=2\n",
      " 700-th evaluation: score=0.4211, divergence=0.0675, diversity=0.7072, num_succ=18, num_remain=2\n",
      " 800-th evaluation: score=0.4217, divergence=0.0680, diversity=0.7074, num_succ=18, num_remain=2\n",
      " 900-th evaluation: score=0.4221, divergence=0.0684, diversity=0.7076, num_succ=19, num_remain=2\n",
      "1000-th evaluation: score=0.4223, divergence=0.0684, diversity=0.7077, num_succ=19, num_remain=2\n",
      "1100-th evaluation: score=0.4230, divergence=0.0693, diversity=0.7075, num_succ=19, num_remain=2\n",
      "1200-th evaluation: score=0.4231, divergence=0.0693, diversity=0.7075, num_succ=19, num_remain=2\n",
      "1300-th evaluation: score=0.4236, divergence=0.0697, diversity=0.7078, num_succ=19, num_remain=2\n",
      "1400-th evaluation: score=0.4237, divergence=0.0698, diversity=0.7079, num_succ=19, num_remain=2\n",
      "1500-th evaluation: score=0.4246, divergence=0.0705, diversity=0.7082, num_succ=19, num_remain=2\n",
      "1600-th evaluation: score=0.4246, divergence=0.0705, diversity=0.7083, num_succ=19, num_remain=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700-th evaluation: score=0.4247, divergence=0.0705, diversity=0.7083, num_succ=19, num_remain=2\n",
      "1800-th evaluation: score=0.4247, divergence=0.0705, diversity=0.7084, num_succ=19, num_remain=2\n",
      "1900-th evaluation: score=0.4248, divergence=0.0706, diversity=0.7084, num_succ=19, num_remain=2\n",
      "2000-th evaluation: score=0.4248, divergence=0.0706, diversity=0.7084, num_succ=19, num_remain=2\n",
      "2100-th evaluation: score=0.4248, divergence=0.0706, diversity=0.7084, num_succ=19, num_remain=2\n",
      "2200-th evaluation: score=0.4248, divergence=0.0706, diversity=0.7085, num_succ=19, num_remain=2\n",
      "2300-th evaluation: score=0.4249, divergence=0.0706, diversity=0.7084, num_succ=19, num_remain=2\n",
      "2400-th evaluation: score=0.4249, divergence=0.0706, diversity=0.7085, num_succ=19, num_remain=2\n",
      "2500-th evaluation: score=0.4249, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "2600-th evaluation: score=0.4249, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "2700-th evaluation: score=0.4249, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "2800-th evaluation: score=0.4249, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "2900-th evaluation: score=0.4249, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "3000-th evaluation: score=0.4249, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "3100-th evaluation: score=0.4249, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "3200-th evaluation: score=0.4249, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "3300-th evaluation: score=0.4249, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "3400-th evaluation: score=0.4249, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "3500-th evaluation: score=0.4249, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "3600-th evaluation: score=0.4249, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "3700-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "3800-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "3900-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "4000-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "4100-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "4200-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "4300-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "4400-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "4500-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "4600-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "4700-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "4800-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "4900-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "5000-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "5100-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7085, num_succ=19, num_remain=2\n",
      "5200-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "5300-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "5400-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "5500-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "5600-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "5700-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "5800-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "5900-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "6000-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "6100-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "6200-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "6300-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "6400-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "6500-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "6600-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "6700-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "6800-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "6900-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "7000-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "7100-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "7200-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "7300-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "7400-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "7500-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "7600-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "7700-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "7800-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "7900-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "8000-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "8100-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "8200-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "8300-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "8400-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "8500-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "8600-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "8700-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "8800-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "8900-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "9000-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "9100-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "9200-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "9300-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "9400-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "9500-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "9600-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "9700-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "9800-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "9900-th evaluation: score=0.4250, divergence=0.0707, diversity=0.7086, num_succ=19, num_remain=2\n",
      "[1.70489876e-02 1.35436856e-02 6.26542948e-03 5.54037169e-03\n",
      " 4.16744154e-04 2.50718476e-02 2.00027207e-02 8.53205542e-03\n",
      " 1.03728062e-02 1.45729196e-02 8.51907229e-03 4.52169547e-03\n",
      " 4.24947779e-03 1.95851205e-02 3.59237313e-01 2.17390357e-02\n",
      " 5.12616710e-02 4.06273617e-01 1.10288251e-01 9.65231392e-03\n",
      " 1.27163322e-02 4.11747789e-02 1.37101836e-02 2.33439502e-03\n",
      " 4.25277350e-02 1.66330995e-02 1.02018855e-02 1.10502116e-02\n",
      " 3.08470570e-02 1.32513512e-02 1.15485070e-01 1.79098689e-02\n",
      " 4.01720819e-03 1.77312439e-03 2.94631411e-03 3.28845521e-02\n",
      " 1.86586102e-03 8.70668563e-03 7.39486748e-01 1.47362787e-02\n",
      " 1.24354116e-01 1.26606902e-02 5.41596194e-03 1.39269019e-02\n",
      " 1.77179754e-02 6.70261849e-02 2.28046510e-03 9.01713933e-03\n",
      " 2.76811711e-03 2.66739086e-02 3.08671737e-02 1.05000694e-02\n",
      " 1.03165935e-03 1.14251530e-02 2.24665190e-02 4.53232451e-02\n",
      " 9.90741099e-03 4.90419840e-03 9.50564737e-03 9.14440253e-03\n",
      " 1.27297434e-02 8.79499943e-03 5.96924294e-03 2.87669030e-02\n",
      " 7.48184874e-03 2.87228174e-02 6.33976145e-03 3.86298004e-03\n",
      " 1.90523842e-03 2.05344582e-02 5.34762217e-03 2.57279949e-03\n",
      " 1.59649677e-03 9.42218440e-03 4.21523657e-03 8.37754192e-03\n",
      " 1.13395499e-02 5.37444446e-04 1.30972658e-03 6.42379511e-03\n",
      " 6.74708927e-03 1.82049141e-04 6.02089011e-03 7.39895645e-04\n",
      " 2.22353907e-03 9.25839725e-03 2.78653603e-02 1.22055674e-03\n",
      " 1.78189442e-01 2.66904585e-02 3.65941600e-02 2.07416176e-03\n",
      " 6.37386000e-03 1.94219468e-01 1.81377157e-02 3.27901034e-02\n",
      " 1.24201172e-01 5.46047552e-03 5.41119670e-02 3.46777932e-03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "initial_evaluation: score=0.5957, divergence=0.0000, diversity=1.1914, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.5963, divergence=0.0006, diversity=1.1913, num_succ=0, num_remain=85\n",
      " 100-th evaluation: score=0.6121, divergence=0.0198, diversity=1.1846, num_succ=0, num_remain=45\n",
      " 200-th evaluation: score=0.6220, divergence=0.0347, diversity=1.1747, num_succ=1, num_remain=34\n",
      " 300-th evaluation: score=0.6317, divergence=0.0495, diversity=1.1642, num_succ=2, num_remain=37\n",
      " 400-th evaluation: score=0.6415, divergence=0.0639, diversity=1.1552, num_succ=3, num_remain=33\n",
      " 500-th evaluation: score=0.6536, divergence=0.0841, diversity=1.1391, num_succ=3, num_remain=46\n",
      " 600-th evaluation: score=0.6612, divergence=0.0968, diversity=1.1288, num_succ=4, num_remain=32\n",
      " 700-th evaluation: score=0.6733, divergence=0.1174, diversity=1.1118, num_succ=5, num_remain=40\n",
      " 800-th evaluation: score=0.6792, divergence=0.1284, diversity=1.1016, num_succ=7, num_remain=30\n",
      " 900-th evaluation: score=0.6874, divergence=0.1409, diversity=1.0931, num_succ=7, num_remain=31\n",
      "1000-th evaluation: score=0.6890, divergence=0.1449, diversity=1.0882, num_succ=7, num_remain=36\n",
      "1100-th evaluation: score=0.6934, divergence=0.1527, diversity=1.0816, num_succ=8, num_remain=38\n",
      "1200-th evaluation: score=0.7007, divergence=0.1679, diversity=1.0655, num_succ=9, num_remain=33\n",
      "1300-th evaluation: score=0.7080, divergence=0.1811, diversity=1.0538, num_succ=9, num_remain=38\n",
      "1400-th evaluation: score=0.7145, divergence=0.1887, diversity=1.0516, num_succ=9, num_remain=33\n",
      "1500-th evaluation: score=0.7241, divergence=0.2063, diversity=1.0356, num_succ=9, num_remain=30\n",
      "1600-th evaluation: score=0.7286, divergence=0.2149, diversity=1.0274, num_succ=9, num_remain=35\n",
      "1700-th evaluation: score=0.7316, divergence=0.2209, diversity=1.0215, num_succ=9, num_remain=28\n",
      "1800-th evaluation: score=0.7402, divergence=0.2313, diversity=1.0178, num_succ=10, num_remain=21\n",
      "1900-th evaluation: score=0.7433, divergence=0.2348, diversity=1.0170, num_succ=10, num_remain=23\n",
      "2000-th evaluation: score=0.7433, divergence=0.2348, diversity=1.0170, num_succ=10, num_remain=23\n",
      "2100-th evaluation: score=0.7433, divergence=0.2348, diversity=1.0170, num_succ=10, num_remain=23\n",
      "2200-th evaluation: score=0.7433, divergence=0.2348, diversity=1.0170, num_succ=10, num_remain=23\n",
      "2300-th evaluation: score=0.7433, divergence=0.2348, diversity=1.0170, num_succ=10, num_remain=23\n",
      "2400-th evaluation: score=0.7439, divergence=0.2361, diversity=1.0156, num_succ=10, num_remain=21\n",
      "2500-th evaluation: score=0.7439, divergence=0.2361, diversity=1.0156, num_succ=10, num_remain=21\n",
      "2600-th evaluation: score=0.7439, divergence=0.2361, diversity=1.0156, num_succ=10, num_remain=21\n",
      "2700-th evaluation: score=0.7439, divergence=0.2361, diversity=1.0156, num_succ=10, num_remain=21\n",
      "2800-th evaluation: score=0.7439, divergence=0.2361, diversity=1.0156, num_succ=10, num_remain=21\n",
      "2900-th evaluation: score=0.7439, divergence=0.2361, diversity=1.0156, num_succ=10, num_remain=21\n",
      "3000-th evaluation: score=0.7439, divergence=0.2361, diversity=1.0156, num_succ=10, num_remain=21\n",
      "3100-th evaluation: score=0.7439, divergence=0.2361, diversity=1.0156, num_succ=10, num_remain=21\n",
      "3200-th evaluation: score=0.7439, divergence=0.2361, diversity=1.0156, num_succ=10, num_remain=21\n",
      "3300-th evaluation: score=0.7439, divergence=0.2361, diversity=1.0156, num_succ=10, num_remain=21\n",
      "3400-th evaluation: score=0.7439, divergence=0.2361, diversity=1.0156, num_succ=10, num_remain=21\n",
      "3500-th evaluation: score=0.7439, divergence=0.2361, diversity=1.0156, num_succ=10, num_remain=21\n",
      "3600-th evaluation: score=0.7439, divergence=0.2361, diversity=1.0156, num_succ=10, num_remain=21\n",
      "3700-th evaluation: score=0.7439, divergence=0.2361, diversity=1.0156, num_succ=10, num_remain=21\n",
      "3800-th evaluation: score=0.7439, divergence=0.2361, diversity=1.0156, num_succ=10, num_remain=21\n",
      "3900-th evaluation: score=0.7439, divergence=0.2361, diversity=1.0156, num_succ=10, num_remain=21\n",
      "4000-th evaluation: score=0.7451, divergence=0.2377, diversity=1.0148, num_succ=10, num_remain=20\n",
      "4100-th evaluation: score=0.7475, divergence=0.2421, diversity=1.0107, num_succ=10, num_remain=19\n",
      "4200-th evaluation: score=0.7489, divergence=0.2440, diversity=1.0098, num_succ=10, num_remain=18\n",
      "4300-th evaluation: score=0.7511, divergence=0.2469, diversity=1.0084, num_succ=10, num_remain=19\n",
      "4400-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "4500-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "4600-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "4700-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "4800-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "4900-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "5000-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "5100-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "5200-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "5300-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "5400-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "5500-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "5600-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "5700-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "5800-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "5900-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "6000-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "6100-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "6200-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "6300-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "6400-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "6500-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "6600-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "6700-th evaluation: score=0.7519, divergence=0.2481, diversity=1.0076, num_succ=10, num_remain=19\n",
      "6800-th evaluation: score=0.7526, divergence=0.2491, diversity=1.0071, num_succ=10, num_remain=17\n",
      "6900-th evaluation: score=0.7539, divergence=0.2515, diversity=1.0048, num_succ=10, num_remain=18\n",
      "7000-th evaluation: score=0.7548, divergence=0.2528, diversity=1.0042, num_succ=10, num_remain=16\n",
      "7100-th evaluation: score=0.7554, divergence=0.2532, diversity=1.0044, num_succ=10, num_remain=16\n",
      "7200-th evaluation: score=0.7565, divergence=0.2550, diversity=1.0030, num_succ=10, num_remain=16\n",
      "7300-th evaluation: score=0.7571, divergence=0.2559, diversity=1.0024, num_succ=10, num_remain=16\n",
      "7400-th evaluation: score=0.7581, divergence=0.2575, diversity=1.0010, num_succ=10, num_remain=16\n",
      "7500-th evaluation: score=0.7588, divergence=0.2588, diversity=1.0000, num_succ=10, num_remain=17\n",
      "7600-th evaluation: score=0.7599, divergence=0.2614, diversity=0.9970, num_succ=10, num_remain=16\n",
      "7700-th evaluation: score=0.7643, divergence=0.2705, diversity=0.9876, num_succ=10, num_remain=16\n",
      "7800-th evaluation: score=0.7667, divergence=0.2757, diversity=0.9820, num_succ=10, num_remain=20\n",
      "7900-th evaluation: score=0.7667, divergence=0.2757, diversity=0.9820, num_succ=10, num_remain=20\n",
      "8000-th evaluation: score=0.7667, divergence=0.2757, diversity=0.9820, num_succ=10, num_remain=20\n",
      "8100-th evaluation: score=0.7667, divergence=0.2757, diversity=0.9820, num_succ=10, num_remain=20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8200-th evaluation: score=0.7667, divergence=0.2757, diversity=0.9820, num_succ=10, num_remain=20\n",
      "8300-th evaluation: score=0.7667, divergence=0.2757, diversity=0.9820, num_succ=10, num_remain=20\n",
      "8400-th evaluation: score=0.7667, divergence=0.2757, diversity=0.9820, num_succ=10, num_remain=20\n",
      "8500-th evaluation: score=0.7667, divergence=0.2757, diversity=0.9820, num_succ=10, num_remain=20\n",
      "8600-th evaluation: score=0.7667, divergence=0.2757, diversity=0.9820, num_succ=10, num_remain=20\n",
      "8700-th evaluation: score=0.7667, divergence=0.2757, diversity=0.9820, num_succ=10, num_remain=20\n",
      "8800-th evaluation: score=0.7667, divergence=0.2757, diversity=0.9820, num_succ=10, num_remain=20\n",
      "8900-th evaluation: score=0.7667, divergence=0.2757, diversity=0.9820, num_succ=10, num_remain=20\n",
      "9000-th evaluation: score=0.7667, divergence=0.2757, diversity=0.9820, num_succ=10, num_remain=20\n",
      "9100-th evaluation: score=0.7667, divergence=0.2757, diversity=0.9820, num_succ=10, num_remain=20\n",
      "9200-th evaluation: score=0.7667, divergence=0.2757, diversity=0.9820, num_succ=10, num_remain=20\n",
      "9300-th evaluation: score=0.7667, divergence=0.2757, diversity=0.9820, num_succ=10, num_remain=20\n",
      "9400-th evaluation: score=0.7685, divergence=0.2780, diversity=0.9810, num_succ=10, num_remain=12\n",
      "9500-th evaluation: score=0.7692, divergence=0.2794, diversity=0.9796, num_succ=10, num_remain=12\n",
      "9600-th evaluation: score=0.7701, divergence=0.2807, diversity=0.9788, num_succ=10, num_remain=11\n",
      "9700-th evaluation: score=0.7706, divergence=0.2811, diversity=0.9791, num_succ=10, num_remain=11\n",
      "9800-th evaluation: score=0.7711, divergence=0.2814, diversity=0.9794, num_succ=10, num_remain=11\n",
      "9900-th evaluation: score=0.7715, divergence=0.2817, diversity=0.9795, num_succ=10, num_remain=11\n",
      "[1.47377807e-01 9.89145405e-02 6.36289996e-02 9.37686304e-02\n",
      " 9.35718140e-04 1.92024473e-01 1.07887181e-01 7.31246706e-02\n",
      " 7.09100408e-02 2.78354145e-02 8.82601399e-03 7.35319197e-03\n",
      " 2.51677045e-02 7.52725879e-03 2.42806818e-02 3.96947078e-02\n",
      " 2.94947159e-02 1.43643528e-02 7.46189967e-02 1.72716880e-01\n",
      " 5.71570598e-02 1.12006624e-01 9.38381658e-02 1.61831830e-01\n",
      " 6.02966557e-02 9.12675977e-02 3.08717243e-02 8.62841722e-02\n",
      " 8.49929309e-02 8.46396081e-02 7.73644618e-02 1.20219356e-01\n",
      " 6.45383981e-02 7.01753319e-02 6.39019935e-03 1.69874356e-02\n",
      " 1.50049876e-01 3.15731808e-02 1.00958175e-01 4.05628417e-02\n",
      " 8.91509402e-02 1.46912398e-01 3.65065824e-02 1.37391279e-01\n",
      " 1.68353212e-01 1.50424288e-01 1.23461782e-01 1.22470850e-01\n",
      " 2.24796943e-02 1.19468042e-02 1.79090017e-01 1.75663022e-01\n",
      " 1.41085539e-01 1.74221751e-01 1.59745560e-01 4.97557120e-02\n",
      " 1.16131671e-01 3.39407470e-02 3.58174970e-02 5.81308875e-02\n",
      " 1.66304762e-01 9.49000439e-02 7.20302872e-02 4.90787071e-03\n",
      " 3.62543039e-02 3.24218448e-02 8.73003023e-02 2.28333492e-02\n",
      " 2.50900739e-02 3.63392824e-02 1.14090569e-01 9.78826767e-02\n",
      " 1.02735583e-01 8.08669702e-02 2.15544791e-02 1.03730541e-01\n",
      " 5.31999352e-02 7.02373533e-02 4.78378219e-02 4.46472888e-02\n",
      " 2.13053555e-02 2.08212356e-01 1.58416168e-04 6.25465722e-03\n",
      " 3.16906645e-02 1.02668829e-01 5.24701664e-02 9.75520618e-02\n",
      " 1.01270607e-01 1.92354756e-01 6.38400966e-02 9.58116842e-02\n",
      " 2.80129684e-02 2.07775092e-01 8.81304512e-02 1.04655134e-02\n",
      " 2.32135273e-01 4.31367308e-02 2.68400827e-02 2.44766181e-01]\n",
      "55\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "initial_evaluation: score=0.5765, divergence=0.0000, diversity=1.1530, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.5771, divergence=0.0006, diversity=1.1530, num_succ=0, num_remain=93\n",
      " 100-th evaluation: score=0.6031, divergence=0.0328, diversity=1.1405, num_succ=2, num_remain=49\n",
      " 200-th evaluation: score=0.6248, divergence=0.0593, diversity=1.1310, num_succ=4, num_remain=45\n",
      " 300-th evaluation: score=0.6350, divergence=0.0739, diversity=1.1222, num_succ=5, num_remain=39\n",
      " 400-th evaluation: score=0.6473, divergence=0.0924, diversity=1.1098, num_succ=5, num_remain=43\n",
      " 500-th evaluation: score=0.6583, divergence=0.1104, diversity=1.0958, num_succ=6, num_remain=39\n",
      " 600-th evaluation: score=0.6681, divergence=0.1254, diversity=1.0854, num_succ=7, num_remain=29\n",
      " 700-th evaluation: score=0.6755, divergence=0.1348, diversity=1.0814, num_succ=8, num_remain=27\n",
      " 800-th evaluation: score=0.6782, divergence=0.1385, diversity=1.0795, num_succ=8, num_remain=27\n",
      " 900-th evaluation: score=0.6797, divergence=0.1401, diversity=1.0792, num_succ=8, num_remain=25\n",
      "1000-th evaluation: score=0.6811, divergence=0.1420, diversity=1.0781, num_succ=8, num_remain=26\n",
      "1100-th evaluation: score=0.6823, divergence=0.1430, diversity=1.0786, num_succ=8, num_remain=25\n",
      "1200-th evaluation: score=0.6835, divergence=0.1450, diversity=1.0769, num_succ=8, num_remain=24\n",
      "1300-th evaluation: score=0.6845, divergence=0.1466, diversity=1.0760, num_succ=8, num_remain=24\n",
      "1400-th evaluation: score=0.6863, divergence=0.1498, diversity=1.0730, num_succ=8, num_remain=25\n",
      "1500-th evaluation: score=0.6902, divergence=0.1572, diversity=1.0661, num_succ=8, num_remain=21\n",
      "1600-th evaluation: score=0.6930, divergence=0.1617, diversity=1.0627, num_succ=9, num_remain=21\n",
      "1700-th evaluation: score=0.6958, divergence=0.1658, diversity=1.0598, num_succ=9, num_remain=19\n",
      "1800-th evaluation: score=0.6967, divergence=0.1673, diversity=1.0588, num_succ=9, num_remain=19\n",
      "1900-th evaluation: score=0.6975, divergence=0.1683, diversity=1.0583, num_succ=9, num_remain=18\n",
      "2000-th evaluation: score=0.6982, divergence=0.1690, diversity=1.0584, num_succ=9, num_remain=18\n",
      "2100-th evaluation: score=0.6988, divergence=0.1697, diversity=1.0581, num_succ=9, num_remain=18\n",
      "2200-th evaluation: score=0.7006, divergence=0.1725, diversity=1.0562, num_succ=9, num_remain=19\n",
      "2300-th evaluation: score=0.7021, divergence=0.1755, diversity=1.0533, num_succ=9, num_remain=18\n",
      "2400-th evaluation: score=0.7028, divergence=0.1769, diversity=1.0518, num_succ=9, num_remain=16\n",
      "2500-th evaluation: score=0.7033, divergence=0.1772, diversity=1.0522, num_succ=9, num_remain=16\n",
      "2600-th evaluation: score=0.7038, divergence=0.1778, diversity=1.0520, num_succ=9, num_remain=16\n",
      "2700-th evaluation: score=0.7042, divergence=0.1783, diversity=1.0518, num_succ=9, num_remain=16\n",
      "2800-th evaluation: score=0.7045, divergence=0.1790, diversity=1.0510, num_succ=9, num_remain=16\n",
      "2900-th evaluation: score=0.7053, divergence=0.1806, diversity=1.0496, num_succ=9, num_remain=16\n",
      "3000-th evaluation: score=0.7058, divergence=0.1810, diversity=1.0495, num_succ=9, num_remain=15\n",
      "3100-th evaluation: score=0.7060, divergence=0.1811, diversity=1.0497, num_succ=9, num_remain=15\n",
      "3200-th evaluation: score=0.7061, divergence=0.1812, diversity=1.0498, num_succ=9, num_remain=15\n",
      "3300-th evaluation: score=0.7062, divergence=0.1813, diversity=1.0499, num_succ=9, num_remain=15\n",
      "3400-th evaluation: score=0.7063, divergence=0.1813, diversity=1.0500, num_succ=9, num_remain=15\n",
      "3500-th evaluation: score=0.7064, divergence=0.1814, diversity=1.0501, num_succ=9, num_remain=15\n",
      "3600-th evaluation: score=0.7066, divergence=0.1815, diversity=1.0502, num_succ=9, num_remain=15\n",
      "3700-th evaluation: score=0.7067, divergence=0.1815, diversity=1.0503, num_succ=9, num_remain=15\n",
      "3800-th evaluation: score=0.7068, divergence=0.1816, diversity=1.0503, num_succ=9, num_remain=15\n",
      "3900-th evaluation: score=0.7069, divergence=0.1817, diversity=1.0504, num_succ=9, num_remain=15\n",
      "4000-th evaluation: score=0.7069, divergence=0.1817, diversity=1.0504, num_succ=9, num_remain=15\n",
      "4100-th evaluation: score=0.7070, divergence=0.1817, diversity=1.0505, num_succ=9, num_remain=15\n",
      "4200-th evaluation: score=0.7070, divergence=0.1817, diversity=1.0505, num_succ=9, num_remain=15\n",
      "4300-th evaluation: score=0.7075, divergence=0.1826, diversity=1.0497, num_succ=9, num_remain=15\n",
      "4400-th evaluation: score=0.7075, divergence=0.1826, diversity=1.0497, num_succ=9, num_remain=15\n",
      "4500-th evaluation: score=0.7076, divergence=0.1827, diversity=1.0498, num_succ=9, num_remain=15\n",
      "4600-th evaluation: score=0.7077, divergence=0.1829, diversity=1.0497, num_succ=9, num_remain=15\n",
      "4700-th evaluation: score=0.7077, divergence=0.1829, diversity=1.0497, num_succ=9, num_remain=15\n",
      "4800-th evaluation: score=0.7078, divergence=0.1829, diversity=1.0498, num_succ=9, num_remain=15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4900-th evaluation: score=0.7078, divergence=0.1829, diversity=1.0498, num_succ=9, num_remain=15\n",
      "5000-th evaluation: score=0.7079, divergence=0.1829, diversity=1.0498, num_succ=9, num_remain=15\n",
      "5100-th evaluation: score=0.7079, divergence=0.1829, diversity=1.0499, num_succ=9, num_remain=15\n",
      "5200-th evaluation: score=0.7079, divergence=0.1830, diversity=1.0499, num_succ=9, num_remain=15\n",
      "5300-th evaluation: score=0.7079, divergence=0.1830, diversity=1.0499, num_succ=9, num_remain=15\n",
      "5400-th evaluation: score=0.7080, divergence=0.1830, diversity=1.0499, num_succ=9, num_remain=15\n",
      "5500-th evaluation: score=0.7081, divergence=0.1832, diversity=1.0497, num_succ=9, num_remain=15\n",
      "5600-th evaluation: score=0.7081, divergence=0.1832, diversity=1.0498, num_succ=9, num_remain=15\n",
      "5700-th evaluation: score=0.7081, divergence=0.1832, diversity=1.0498, num_succ=9, num_remain=15\n",
      "5800-th evaluation: score=0.7081, divergence=0.1833, diversity=1.0498, num_succ=9, num_remain=15\n",
      "5900-th evaluation: score=0.7082, divergence=0.1833, diversity=1.0497, num_succ=9, num_remain=15\n",
      "6000-th evaluation: score=0.7082, divergence=0.1833, diversity=1.0498, num_succ=9, num_remain=15\n",
      "6100-th evaluation: score=0.7082, divergence=0.1833, diversity=1.0498, num_succ=9, num_remain=15\n",
      "6200-th evaluation: score=0.7082, divergence=0.1833, diversity=1.0498, num_succ=9, num_remain=15\n",
      "6300-th evaluation: score=0.7082, divergence=0.1833, diversity=1.0498, num_succ=9, num_remain=15\n",
      "6400-th evaluation: score=0.7083, divergence=0.1833, diversity=1.0498, num_succ=9, num_remain=15\n",
      "6500-th evaluation: score=0.7083, divergence=0.1834, diversity=1.0498, num_succ=9, num_remain=15\n",
      "6600-th evaluation: score=0.7083, divergence=0.1834, diversity=1.0498, num_succ=9, num_remain=15\n",
      "6700-th evaluation: score=0.7083, divergence=0.1834, diversity=1.0499, num_succ=9, num_remain=15\n",
      "6800-th evaluation: score=0.7083, divergence=0.1834, diversity=1.0499, num_succ=9, num_remain=15\n",
      "6900-th evaluation: score=0.7083, divergence=0.1834, diversity=1.0499, num_succ=9, num_remain=15\n",
      "7000-th evaluation: score=0.7083, divergence=0.1834, diversity=1.0499, num_succ=9, num_remain=15\n",
      "7100-th evaluation: score=0.7083, divergence=0.1834, diversity=1.0499, num_succ=9, num_remain=15\n",
      "7200-th evaluation: score=0.7083, divergence=0.1834, diversity=1.0499, num_succ=9, num_remain=15\n",
      "7300-th evaluation: score=0.7084, divergence=0.1834, diversity=1.0499, num_succ=9, num_remain=15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-39e53920e11b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     adv_inputs, saved_inputs = optimize_towards_goal(\n\u001b[1;32m     33\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_model_on_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_preds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         epsilon=0.2, lambda1=0.5, max_iters=10000, log_every=100, save_every=1000)\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0madv_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madv_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-119-2886af3f86ff>\u001b[0m in \u001b[0;36moptimize_towards_goal\u001b[0;34m(model, seed_inputs, seed_outputs, seed_preds, max_iters, epsilon, lambda1, log_every, save_every)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mmutate_right_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutate_right_eval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mmutate_left_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmutation_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mmutate_left_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutate_left_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0mmutate_left_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutate_left_eval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-119-2886af3f86ff>\u001b[0m in \u001b[0;36mevaluate_inputs\u001b[0;34m(model, inputs, seed_outputs, seed_preds, lambda1)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mdiversity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiversity_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mquantile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkthvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mdiversity_quantile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiversity_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.011\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;31m#     diversity = diversity ** 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivergence\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdiversity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-119-2886af3f86ff>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t, q)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mdiversity_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mdiversity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiversity_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mquantile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkthvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mdiversity_quantile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiversity_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.011\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m#     diversity = diversity ** 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "from utils import lazy_property, Utils\n",
    "import os\n",
    "\n",
    "\n",
    "def compute_ddv(model, normal_outputs, adv_outputs):\n",
    "    output_pairs = zip(normal_outputs, adv_outputs)\n",
    "    # print(list(output_pairs)[0])\n",
    "    ddv = []  # DDV is short for decision distance vector\n",
    "    for i, (ya, yb) in enumerate(output_pairs):\n",
    "        dist = spatial.distance.cosine(ya, yb)\n",
    "        ddv.append(dist)\n",
    "    ddv = Utils.normalize(np.array(ddv))\n",
    "    return ddv\n",
    "\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    if not model.torch_model_exists():\n",
    "        continue\n",
    "    model_name = model.__str__()\n",
    "    model_path = model.torch_model_path\n",
    "    if i < 6: # skip pretrained models\n",
    "        continue\n",
    "    if 'quantize' in model_name: # skip quantized models\n",
    "        continue\n",
    "    print(f'{i}\\t generating inputs for {model.__str__()}')\n",
    "    seed_inputs = model.get_seed_inputs(100, rand=False)\n",
    "    seed_inputs = torch.from_numpy(seed_inputs).to(DEVICE)\n",
    "    seed_outputs = model.batch_forward(seed_inputs)\n",
    "    _, seed_preds = seed_outputs.data.max(1)\n",
    "\n",
    "    adv_inputs, saved_inputs = optimize_towards_goal(\n",
    "        model.torch_model_on_device, seed_inputs, seed_outputs, seed_preds,\n",
    "        epsilon=0.2, lambda1=0.5, max_iters=10000, log_every=100, save_every=1000)\n",
    "    adv_outputs = model.batch_forward(adv_inputs).cpu()\n",
    "    _, adv_preds = adv_outputs.data.max(1)\n",
    "    \n",
    "    ddv = compute_ddv(model, seed_outputs.cpu().numpy(), adv_outputs.cpu().numpy())\n",
    "    print(ddv)\n",
    "    \n",
    "    out_path = os.path.join(model_path, 'inputs.npz')\n",
    "    np.savez(out_path, seed_inputs=seed_inputs.cpu().numpy(), adv_inputs=adv_inputs.cpu().numpy(), ddv=ddv, saved_inputs=saved_inputs)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "initial_evaluation: score=0.6370, divergence=0.0000, diversity=1.2739, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6371, divergence=0.0001, diversity=1.2740, num_succ=0, num_remain=84\n",
      " 100-th evaluation: score=0.6377, divergence=0.0006, diversity=1.2742, num_succ=0, num_remain=59\n",
      " 200-th evaluation: score=0.6381, divergence=0.0009, diversity=1.2744, num_succ=0, num_remain=44\n",
      " 300-th evaluation: score=0.6384, divergence=0.0011, diversity=1.2746, num_succ=0, num_remain=36\n",
      " 400-th evaluation: score=0.6386, divergence=0.0013, diversity=1.2747, num_succ=0, num_remain=45\n",
      " 500-th evaluation: score=0.6389, divergence=0.0015, diversity=1.2748, num_succ=0, num_remain=39\n",
      " 600-th evaluation: score=0.6390, divergence=0.0016, diversity=1.2749, num_succ=0, num_remain=34\n",
      " 700-th evaluation: score=0.6392, divergence=0.0017, diversity=1.2749, num_succ=0, num_remain=43\n",
      " 800-th evaluation: score=0.6394, divergence=0.0018, diversity=1.2750, num_succ=0, num_remain=32\n",
      " 900-th evaluation: score=0.6395, divergence=0.0019, diversity=1.2751, num_succ=0, num_remain=32\n",
      "evaluating inputs\n",
      "parent_sim: 0.1827 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.4417 gap=0.2589 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.3943 gap=0.2115 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.4271 gap=0.2444 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.6654 gap=0.4827 train(resnet18,Flower102)-\n",
      "ref_sim: 0.3883 gap=0.2056 train(resnet18,SDog120)-\n",
      "ref_sim: 0.2891 gap=0.1064 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.3646 gap=0.1819 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.4905 gap=0.3077 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.4519 gap=0.2691 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.5343 gap=0.3516 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.5753 gap=0.3926 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.5573 gap=0.3745 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.6348 gap=0.4520 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4732 gap=0.2904 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.5045 gap=0.3218 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.4967 gap=0.3140 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.3653 gap=0.1825 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.4408 gap=0.2580 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.3738 gap=0.1910 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.2995 gap=0.1168 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.6357 gap=0.4529 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.4645 gap=0.2817 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.5205 gap=0.3378 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.6990 gap=0.5163 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.6935 gap=0.5107 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.5307 gap=0.3480 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.6002 gap=0.4174 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.6651 gap=0.4823 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.5099 gap=0.3272 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.5247 gap=0.3420 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.4732 gap=0.2904 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.4500 gap=0.2673 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.4249 gap=0.2421 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.4389 gap=0.2561 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.4623 gap=0.2796 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.7705 gap=0.5877 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6440 gap=0.4613 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.5634 gap=0.3807 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.7109 gap=0.5281 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.6332 gap=0.4505 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6679 gap=0.4852 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.3414 gap=0.1587 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4620 gap=0.2793 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.6892 gap=0.5064 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.6860 gap=0.5032 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.4680 gap=0.2852 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5910 gap=0.4082 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.3931 gap=0.2104 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.4834 gap=0.3007 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.6931 gap=0.5104 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3984 gap=0.2157 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.5305 gap=0.3478 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.6140 gap=0.4313 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.6749 gap=0.4921 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.6702 gap=0.4874 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.6718 gap=0.4890 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.5053 gap=0.3225 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4701 gap=0.2874 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4625 gap=0.2798 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.4188 gap=0.2360 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.4631 gap=0.2803 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.7189 gap=0.5361 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.5294 gap=0.3466 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.6567 gap=0.4740 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.7687 gap=0.5859 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.7053 gap=0.5226 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5281 gap=0.3454 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.5347 gap=0.3520 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.6838 gap=0.5010 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.7377 gap=0.5549 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6096 gap=0.4268 train(resnet18,SDog120)-steal(resnet18)-\n",
      "7\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "initial_evaluation: score=0.6720, divergence=0.0000, diversity=1.3441, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6721, divergence=0.0001, diversity=1.3441, num_succ=0, num_remain=89\n",
      " 100-th evaluation: score=0.6724, divergence=0.0003, diversity=1.3442, num_succ=0, num_remain=60\n",
      " 200-th evaluation: score=0.6725, divergence=0.0004, diversity=1.3442, num_succ=0, num_remain=48\n",
      " 300-th evaluation: score=0.6726, divergence=0.0004, diversity=1.3443, num_succ=0, num_remain=45\n",
      " 400-th evaluation: score=0.6727, divergence=0.0005, diversity=1.3443, num_succ=0, num_remain=50\n",
      " 500-th evaluation: score=0.6727, divergence=0.0005, diversity=1.3443, num_succ=0, num_remain=38\n",
      " 600-th evaluation: score=0.6728, divergence=0.0006, diversity=1.3443, num_succ=0, num_remain=37\n",
      " 700-th evaluation: score=0.6728, divergence=0.0006, diversity=1.3444, num_succ=0, num_remain=30\n",
      " 800-th evaluation: score=0.6728, divergence=0.0007, diversity=1.3444, num_succ=0, num_remain=35\n",
      " 900-th evaluation: score=0.6729, divergence=0.0007, diversity=1.3444, num_succ=0, num_remain=38\n",
      "evaluating inputs\n",
      "parent_sim: 0.1611 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.3830 gap=0.2219 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.4310 gap=0.2699 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.6870 gap=0.5259 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.7968 gap=0.6357 train(resnet18,Flower102)-\n",
      "ref_sim: 0.7063 gap=0.5452 train(resnet18,SDog120)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.2199 gap=0.0588 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.2495 gap=0.0884 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.2846 gap=0.1235 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.4689 gap=0.3078 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.6568 gap=0.4957 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.5071 gap=0.3460 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.2496 gap=0.0885 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.2784 gap=0.1173 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.1786 gap=0.0175 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.2509 gap=0.0898 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2410 gap=0.0799 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.2225 gap=0.0614 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.3186 gap=0.1575 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.3048 gap=0.1437 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.2848 gap=0.1237 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.5270 gap=0.3659 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.5454 gap=0.3843 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4304 gap=0.2693 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.5878 gap=0.4267 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.5275 gap=0.3664 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4201 gap=0.2590 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.5218 gap=0.3607 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.5496 gap=0.3885 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.4798 gap=0.3187 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.3773 gap=0.2162 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.3607 gap=0.1996 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.4721 gap=0.3110 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.3977 gap=0.2366 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.4969 gap=0.3358 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.5416 gap=0.3805 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.7774 gap=0.6163 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.9267 gap=0.7656 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.9059 gap=0.7448 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.8588 gap=0.6977 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.8928 gap=0.7317 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8647 gap=0.7036 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.6133 gap=0.4522 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.7011 gap=0.5400 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.7207 gap=0.5596 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.7638 gap=0.6027 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.6269 gap=0.4658 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6494 gap=0.4882 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.3917 gap=0.2306 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.6283 gap=0.4672 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.4537 gap=0.2926 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.6510 gap=0.4899 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.6908 gap=0.5297 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.6993 gap=0.5382 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8166 gap=0.6554 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8092 gap=0.6481 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.8353 gap=0.6741 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.7131 gap=0.5520 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.7180 gap=0.5569 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.7592 gap=0.5981 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.9012 gap=0.7401 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.7927 gap=0.6316 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.8572 gap=0.6961 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.8522 gap=0.6911 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.8501 gap=0.6890 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8774 gap=0.7163 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.8793 gap=0.7182 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.8401 gap=0.6790 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.7881 gap=0.6270 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.9289 gap=0.7678 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6981 gap=0.5370 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.7148 gap=0.5537 train(resnet18,SDog120)-steal(resnet18)-\n",
      "8\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "initial_evaluation: score=0.6754, divergence=0.0000, diversity=1.3508, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6755, divergence=0.0001, diversity=1.3509, num_succ=0, num_remain=91\n",
      " 100-th evaluation: score=0.6757, divergence=0.0002, diversity=1.3509, num_succ=0, num_remain=57\n",
      " 200-th evaluation: score=0.6757, divergence=0.0003, diversity=1.3509, num_succ=0, num_remain=53\n",
      " 300-th evaluation: score=0.6758, divergence=0.0003, diversity=1.3510, num_succ=0, num_remain=48\n",
      " 400-th evaluation: score=0.6759, divergence=0.0004, diversity=1.3510, num_succ=0, num_remain=47\n",
      " 500-th evaluation: score=0.6759, divergence=0.0004, diversity=1.3510, num_succ=0, num_remain=42\n",
      " 600-th evaluation: score=0.6760, divergence=0.0005, diversity=1.3510, num_succ=0, num_remain=40\n",
      " 700-th evaluation: score=0.6760, divergence=0.0005, diversity=1.3510, num_succ=0, num_remain=44\n",
      " 800-th evaluation: score=0.6761, divergence=0.0005, diversity=1.3510, num_succ=0, num_remain=50\n",
      " 900-th evaluation: score=0.6761, divergence=0.0006, diversity=1.3511, num_succ=0, num_remain=40\n",
      "evaluating inputs\n",
      "parent_sim: 0.2325 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.5007 gap=0.2682 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.6842 gap=0.4516 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.7183 gap=0.4857 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.7371 gap=0.5045 train(resnet18,Flower102)-\n",
      "ref_sim: 0.7848 gap=0.5522 train(resnet18,SDog120)-\n",
      "ref_sim: 0.3821 gap=0.1496 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1425 gap=-0.0900 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2091 gap=-0.0234 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\u001b[0m\n",
      "ref_sim: 0.5219 gap=0.2894 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.6767 gap=0.4441 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.5601 gap=0.3275 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.2952 gap=0.0627 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.4408 gap=0.2083 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.2764 gap=0.0439 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1662 gap=-0.0663 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2026 gap=-0.0300 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\u001b[0m\n",
      "ref_sim: 0.3022 gap=0.0696 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1935 gap=-0.0390 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1801 gap=-0.0524 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2037 gap=-0.0289 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.6016 gap=0.3690 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.4721 gap=0.2396 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.6440 gap=0.4114 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.6899 gap=0.4574 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.6935 gap=0.4610 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.6805 gap=0.4479 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.6960 gap=0.4634 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.6646 gap=0.4321 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.6193 gap=0.3867 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.3368 gap=0.1042 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.4596 gap=0.2271 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.4403 gap=0.2078 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.4782 gap=0.2456 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.6050 gap=0.3724 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.6984 gap=0.4658 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.8260 gap=0.5935 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5048 gap=0.2722 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.6667 gap=0.4342 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.6276 gap=0.3950 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5224 gap=0.2899 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4992 gap=0.2666 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.5189 gap=0.2864 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5302 gap=0.2977 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.7466 gap=0.5141 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.6862 gap=0.4537 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.7634 gap=0.5309 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.7053 gap=0.4728 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.6841 gap=0.4516 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.6868 gap=0.4542 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.6255 gap=0.3930 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.7717 gap=0.5392 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.7273 gap=0.4948 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.6298 gap=0.3973 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.7339 gap=0.5014 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.7313 gap=0.4988 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.7424 gap=0.5099 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.7859 gap=0.5534 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.7886 gap=0.5561 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.7927 gap=0.5602 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.6051 gap=0.3726 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.7660 gap=0.5334 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.7599 gap=0.5274 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.7829 gap=0.5504 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.6320 gap=0.3994 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.7235 gap=0.4909 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6481 gap=0.4156 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.7836 gap=0.5510 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.6475 gap=0.4150 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.7411 gap=0.5086 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.7537 gap=0.5211 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.7669 gap=0.5344 train(resnet18,SDog120)-steal(resnet18)-\n",
      "9\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "initial_evaluation: score=0.4660, divergence=0.0000, diversity=0.9319, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.4667, divergence=0.0007, diversity=0.9319, num_succ=0, num_remain=82\n",
      " 100-th evaluation: score=0.4685, divergence=0.0024, diversity=0.9322, num_succ=1, num_remain=37\n",
      " 200-th evaluation: score=0.4692, divergence=0.0030, diversity=0.9324, num_succ=1, num_remain=30\n",
      " 300-th evaluation: score=0.4700, divergence=0.0036, diversity=0.9328, num_succ=1, num_remain=32\n",
      " 400-th evaluation: score=0.4707, divergence=0.0041, diversity=0.9331, num_succ=1, num_remain=33\n",
      " 500-th evaluation: score=0.4715, divergence=0.0048, diversity=0.9335, num_succ=1, num_remain=33\n",
      " 600-th evaluation: score=0.4721, divergence=0.0052, diversity=0.9337, num_succ=1, num_remain=28\n",
      " 700-th evaluation: score=0.4727, divergence=0.0057, diversity=0.9340, num_succ=1, num_remain=29\n",
      " 800-th evaluation: score=0.4737, divergence=0.0066, diversity=0.9343, num_succ=1, num_remain=34\n",
      " 900-th evaluation: score=0.4743, divergence=0.0070, diversity=0.9346, num_succ=1, num_remain=28\n",
      "evaluating inputs\n",
      "parent_sim: 0.2387 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.4103 gap=0.1715 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.2696 gap=0.0309 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.5268 gap=0.2880 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.8005 gap=0.5618 train(resnet18,Flower102)-\n",
      "ref_sim: 0.4626 gap=0.2238 train(resnet18,SDog120)-\n",
      "ref_sim: 0.3291 gap=0.0903 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.3302 gap=0.0915 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.3717 gap=0.1330 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1642 gap=-0.0745 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0996 gap=-0.1391 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0620 gap=-0.1768 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\u001b[0m\n",
      "ref_sim: 0.3215 gap=0.0828 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.4350 gap=0.1962 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4275 gap=0.1887 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.4004 gap=0.1617 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.4012 gap=0.1624 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4981 gap=0.2594 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.4149 gap=0.1762 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.4603 gap=0.2216 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.4803 gap=0.2416 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0753 gap=-0.1634 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0367 gap=-0.2020 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2125 gap=-0.0263 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0513 gap=-0.1875 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1080 gap=-0.1307 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1139 gap=-0.1248 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1854 gap=-0.0533 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0732 gap=-0.1655 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1981 gap=-0.0407 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.3847 gap=0.1460 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.3984 gap=0.1597 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.6674 gap=0.4286 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0862 gap=-0.1526 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1749 gap=-0.0638 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1474 gap=-0.0914 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\u001b[0m\n",
      "ref_sim: 0.3844 gap=0.1457 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.6031 gap=0.3644 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1603 gap=-0.0785 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\u001b[0m\n",
      "ref_sim: 0.6970 gap=0.4582 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5568 gap=0.3181 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8370 gap=0.5983 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1032 gap=-0.1355 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0859 gap=-0.1528 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1876 gap=-0.0511 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\u001b[0m\n",
      "ref_sim: 0.4562 gap=0.2174 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1647 gap=-0.0740 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0508 gap=-0.1880 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2320 gap=-0.0067 train(mbnetv2,Flower102)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2207 gap=-0.0180 train(mbnetv2,Flower102)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0798 gap=-0.1589 train(mbnetv2,Flower102)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.5485 gap=0.3098 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4540 gap=0.2153 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.5269 gap=0.2882 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8025 gap=0.5637 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8078 gap=0.5691 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.7519 gap=0.5132 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.4725 gap=0.2338 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.5003 gap=0.2616 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4661 gap=0.2273 train(resnet18,SDog120)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0948 gap=-0.1440 train(mbnetv2,Flower102)-distill()-\u001b[0m\n",
      "ref_sim: 0.3054 gap=0.0666 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.8047 gap=0.5660 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.6093 gap=0.3705 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.6937 gap=0.4549 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8597 gap=0.6210 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5146 gap=0.2758 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1008 gap=-0.1379 train(mbnetv2,SDog120)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.7200 gap=0.4813 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8389 gap=0.6002 train(resnet18,Flower102)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1229 gap=-0.1159 train(resnet18,SDog120)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1905 gap=-0.0482 train(resnet18,SDog120)-steal(resnet18)-\u001b[0m\n",
      "10\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "initial_evaluation: score=0.5442, divergence=0.0000, diversity=1.0883, num_succ=0, num_remain=7\n",
      "   0-th evaluation: score=0.5444, divergence=0.0003, diversity=1.0882, num_succ=0, num_remain=82\n",
      " 100-th evaluation: score=0.5459, divergence=0.0016, diversity=1.0886, num_succ=0, num_remain=38\n",
      " 200-th evaluation: score=0.5469, divergence=0.0023, diversity=1.0892, num_succ=0, num_remain=40\n",
      " 300-th evaluation: score=0.5479, divergence=0.0031, diversity=1.0897, num_succ=0, num_remain=43\n",
      " 400-th evaluation: score=0.5487, divergence=0.0036, diversity=1.0900, num_succ=0, num_remain=46\n",
      " 500-th evaluation: score=0.5497, divergence=0.0044, diversity=1.0907, num_succ=0, num_remain=39\n",
      " 600-th evaluation: score=0.5506, divergence=0.0051, diversity=1.0911, num_succ=0, num_remain=45\n",
      " 700-th evaluation: score=0.5514, divergence=0.0057, diversity=1.0916, num_succ=0, num_remain=41\n",
      " 800-th evaluation: score=0.5523, divergence=0.0063, diversity=1.0920, num_succ=0, num_remain=48\n",
      " 900-th evaluation: score=0.5531, divergence=0.0069, diversity=1.0924, num_succ=0, num_remain=45\n",
      "evaluating inputs\n",
      "parent_sim: 0.2789 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.2816 gap=0.0026 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.4619 gap=0.1830 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.5252 gap=0.2462 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.7376 gap=0.4586 train(resnet18,Flower102)-\n",
      "ref_sim: 0.4875 gap=0.2085 train(resnet18,SDog120)-\n",
      "ref_sim: 0.4468 gap=0.1679 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.4298 gap=0.1509 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.4511 gap=0.1721 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.2999 gap=0.0210 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.3084 gap=0.0294 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2789 gap=-0.0000 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\u001b[0m\n",
      "ref_sim: 0.4292 gap=0.1503 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.4488 gap=0.1699 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4365 gap=0.1576 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.4220 gap=0.1431 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.4525 gap=0.1735 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4874 gap=0.2084 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.4501 gap=0.1712 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.4597 gap=0.1808 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.4616 gap=0.1826 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2348 gap=-0.0441 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2308 gap=-0.0482 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\u001b[0m\n",
      "ref_sim: 0.3390 gap=0.0601 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3328 gap=0.0539 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.3014 gap=0.0225 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.3384 gap=0.0595 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2929 gap=0.0140 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2337 gap=-0.0453 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\u001b[0m\n",
      "ref_sim: 0.3833 gap=0.1044 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.3317 gap=0.0527 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.4965 gap=0.2176 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.5227 gap=0.2438 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.4056 gap=0.1267 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.3788 gap=0.0999 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.3438 gap=0.0649 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.5762 gap=0.2973 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5423 gap=0.2633 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.5438 gap=0.2649 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.5809 gap=0.3020 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.6918 gap=0.4128 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5529 gap=0.2739 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.6720 gap=0.3930 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4613 gap=0.1823 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.6610 gap=0.3820 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.4151 gap=0.1362 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.7113 gap=0.4324 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3766 gap=0.0976 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.4193 gap=0.1403 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.5148 gap=0.2359 train(mbnetv2,Flower102)-prune(0.5)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.6515 gap=0.3726 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.5245 gap=0.2456 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4850 gap=0.2060 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.5591 gap=0.2802 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.7381 gap=0.4592 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.7108 gap=0.4319 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.7176 gap=0.4386 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.4927 gap=0.2138 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4954 gap=0.2165 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4759 gap=0.1969 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.5798 gap=0.3009 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.5021 gap=0.2232 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.6970 gap=0.4181 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.4920 gap=0.2131 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.5536 gap=0.2746 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.6682 gap=0.3892 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6703 gap=0.3913 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2736 gap=-0.0053 train(mbnetv2,SDog120)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.5429 gap=0.2640 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.6637 gap=0.3848 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5818 gap=0.3029 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5467 gap=0.2677 train(resnet18,SDog120)-steal(resnet18)-\n",
      "11\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "initial_evaluation: score=0.5761, divergence=0.0000, diversity=1.1522, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.5768, divergence=0.0007, diversity=1.1522, num_succ=0, num_remain=86\n",
      " 100-th evaluation: score=0.5782, divergence=0.0018, diversity=1.1527, num_succ=0, num_remain=53\n",
      " 200-th evaluation: score=0.5787, divergence=0.0022, diversity=1.1529, num_succ=0, num_remain=50\n",
      " 300-th evaluation: score=0.5792, divergence=0.0026, diversity=1.1533, num_succ=0, num_remain=39\n",
      " 400-th evaluation: score=0.5796, divergence=0.0029, diversity=1.1535, num_succ=0, num_remain=43\n",
      " 500-th evaluation: score=0.5801, divergence=0.0032, diversity=1.1537, num_succ=0, num_remain=33\n",
      " 600-th evaluation: score=0.5804, divergence=0.0034, diversity=1.1539, num_succ=0, num_remain=32\n",
      " 700-th evaluation: score=0.5806, divergence=0.0036, diversity=1.1541, num_succ=0, num_remain=25\n",
      " 800-th evaluation: score=0.5808, divergence=0.0037, diversity=1.1541, num_succ=0, num_remain=23\n",
      " 900-th evaluation: score=0.5810, divergence=0.0039, diversity=1.1543, num_succ=0, num_remain=25\n",
      "evaluating inputs\n",
      "parent_sim: 0.1695 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.1865 gap=0.0171 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.5237 gap=0.3543 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.3939 gap=0.2244 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.8126 gap=0.6431 train(resnet18,Flower102)-\n",
      "ref_sim: 0.2940 gap=0.1245 train(resnet18,SDog120)-\n",
      "ref_sim: 0.4548 gap=0.2854 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.4034 gap=0.2339 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.3628 gap=0.1933 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1284 gap=-0.0411 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1649 gap=-0.0046 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\u001b[0m\n",
      "ref_sim: 0.2215 gap=0.0521 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.3311 gap=0.1616 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.4131 gap=0.2437 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4814 gap=0.3120 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3970 gap=0.2275 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.4423 gap=0.2728 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4265 gap=0.2570 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.3957 gap=0.2263 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.3952 gap=0.2257 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.3616 gap=0.1922 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.2231 gap=0.0537 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.1889 gap=0.0195 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.2607 gap=0.0912 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.2412 gap=0.0718 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2344 gap=0.0650 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.2068 gap=0.0373 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2424 gap=0.0730 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.2636 gap=0.0941 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.2016 gap=0.0322 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.3793 gap=0.2098 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.3442 gap=0.1748 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.4053 gap=0.2359 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.1969 gap=0.0274 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.1902 gap=0.0208 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.2847 gap=0.1152 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.3887 gap=0.2193 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3026 gap=0.1331 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.4099 gap=0.2404 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.5819 gap=0.4124 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.4069 gap=0.2375 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4972 gap=0.3277 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.3663 gap=0.1968 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.2064 gap=0.0369 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.4852 gap=0.3157 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.3625 gap=0.1930 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.4807 gap=0.3112 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.2692 gap=0.0998 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.4714 gap=0.3020 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.3967 gap=0.2272 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.5492 gap=0.3797 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3739 gap=0.2044 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.2513 gap=0.0818 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.3375 gap=0.1681 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.7693 gap=0.5999 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.7577 gap=0.5882 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.8165 gap=0.6470 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3086 gap=0.1391 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.3283 gap=0.1588 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.2936 gap=0.1242 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.6145 gap=0.4451 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.4105 gap=0.2410 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.8341 gap=0.6647 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.4666 gap=0.2972 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.4628 gap=0.2933 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.6827 gap=0.5132 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5970 gap=0.4276 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.2927 gap=0.1232 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.4020 gap=0.2325 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.7764 gap=0.6070 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5915 gap=0.4220 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.4348 gap=0.2653 train(resnet18,SDog120)-steal(resnet18)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\t generating inputs for pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "initial_evaluation: score=0.5766, divergence=0.0000, diversity=1.1533, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.5770, divergence=0.0004, diversity=1.1533, num_succ=0, num_remain=86\n",
      " 100-th evaluation: score=0.5781, divergence=0.0013, diversity=1.1536, num_succ=0, num_remain=48\n",
      " 200-th evaluation: score=0.5785, divergence=0.0017, diversity=1.1538, num_succ=0, num_remain=39\n",
      " 300-th evaluation: score=0.5791, divergence=0.0020, diversity=1.1540, num_succ=0, num_remain=43\n",
      " 400-th evaluation: score=0.5795, divergence=0.0024, diversity=1.1543, num_succ=0, num_remain=35\n",
      " 500-th evaluation: score=0.5798, divergence=0.0026, diversity=1.1545, num_succ=0, num_remain=35\n",
      " 600-th evaluation: score=0.5801, divergence=0.0028, diversity=1.1546, num_succ=0, num_remain=35\n",
      " 700-th evaluation: score=0.5804, divergence=0.0030, diversity=1.1548, num_succ=0, num_remain=33\n",
      " 800-th evaluation: score=0.5807, divergence=0.0032, diversity=1.1550, num_succ=0, num_remain=29\n",
      " 900-th evaluation: score=0.5808, divergence=0.0033, diversity=1.1551, num_succ=0, num_remain=30\n",
      "evaluating inputs\n",
      "parent_sim: 0.1327 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.2321 gap=0.0994 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.3739 gap=0.2411 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.4486 gap=0.3159 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.5574 gap=0.4247 train(resnet18,Flower102)-\n",
      "ref_sim: 0.5790 gap=0.4463 train(resnet18,SDog120)-\n",
      "ref_sim: 0.1750 gap=0.0423 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.3435 gap=0.2108 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.4521 gap=0.3194 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.2223 gap=0.0896 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.1340 gap=0.0013 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.1546 gap=0.0219 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.2197 gap=0.0870 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.3211 gap=0.1883 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4307 gap=0.2980 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3379 gap=0.2052 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.4812 gap=0.3485 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4390 gap=0.3063 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.4664 gap=0.3337 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.6184 gap=0.4856 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.4928 gap=0.3600 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.2575 gap=0.1248 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.2736 gap=0.1409 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.3314 gap=0.1987 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.1753 gap=0.0426 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.1723 gap=0.0396 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.2753 gap=0.1425 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2514 gap=0.1187 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.1512 gap=0.0185 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.3215 gap=0.1888 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.6958 gap=0.5631 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.7601 gap=0.6274 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.6610 gap=0.5283 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.5375 gap=0.4047 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.3735 gap=0.2408 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.4074 gap=0.2747 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.4790 gap=0.3463 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4679 gap=0.3352 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.3990 gap=0.2663 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.4212 gap=0.2884 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5211 gap=0.3884 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6159 gap=0.4832 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.5423 gap=0.4096 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.7816 gap=0.6489 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.5193 gap=0.3865 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.3341 gap=0.2014 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.4642 gap=0.3315 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3715 gap=0.2387 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.4029 gap=0.2702 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.4308 gap=0.2980 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.4328 gap=0.3000 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.4015 gap=0.2688 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.3166 gap=0.1839 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.3293 gap=0.1966 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.5650 gap=0.4323 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.5965 gap=0.4638 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.6590 gap=0.5263 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.5542 gap=0.4215 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.5094 gap=0.3767 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.5278 gap=0.3951 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.4215 gap=0.2888 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.5972 gap=0.4644 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.7268 gap=0.5941 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.6686 gap=0.5358 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.6301 gap=0.4974 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.6920 gap=0.5593 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.7289 gap=0.5962 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5037 gap=0.3710 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.3696 gap=0.2369 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8241 gap=0.6914 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.4143 gap=0.2816 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.7117 gap=0.5789 train(resnet18,SDog120)-steal(resnet18)-\n",
      "13\t generating inputs for pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "initial_evaluation: score=0.6698, divergence=0.0000, diversity=1.3395, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6699, divergence=0.0001, diversity=1.3395, num_succ=0, num_remain=88\n",
      " 100-th evaluation: score=0.6700, divergence=0.0002, diversity=1.3396, num_succ=0, num_remain=66\n",
      " 200-th evaluation: score=0.6701, divergence=0.0003, diversity=1.3397, num_succ=0, num_remain=50\n",
      " 300-th evaluation: score=0.6702, divergence=0.0004, diversity=1.3397, num_succ=0, num_remain=52\n",
      " 400-th evaluation: score=0.6703, divergence=0.0004, diversity=1.3398, num_succ=0, num_remain=46\n",
      " 500-th evaluation: score=0.6703, divergence=0.0005, diversity=1.3398, num_succ=0, num_remain=39\n",
      " 600-th evaluation: score=0.6704, divergence=0.0005, diversity=1.3398, num_succ=0, num_remain=40\n",
      " 700-th evaluation: score=0.6704, divergence=0.0005, diversity=1.3399, num_succ=0, num_remain=38\n",
      " 800-th evaluation: score=0.6705, divergence=0.0006, diversity=1.3399, num_succ=0, num_remain=42\n",
      " 900-th evaluation: score=0.6706, divergence=0.0006, diversity=1.3399, num_succ=0, num_remain=35\n",
      "evaluating inputs\n",
      "parent_sim: 0.0646 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.2530 gap=0.1884 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.3372 gap=0.2726 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.6218 gap=0.5571 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.7751 gap=0.7105 train(resnet18,Flower102)-\n",
      "ref_sim: 0.5716 gap=0.5070 train(resnet18,SDog120)-\n",
      "ref_sim: 0.2831 gap=0.2185 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.2412 gap=0.1765 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.4085 gap=0.3438 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.4785 gap=0.4139 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.5769 gap=0.5123 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.5959 gap=0.5313 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.3994 gap=0.3347 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.3172 gap=0.2526 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.2255 gap=0.1609 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.2634 gap=0.1988 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2206 gap=0.1560 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.1238 gap=0.0591 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.3492 gap=0.2845 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.3427 gap=0.2780 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.3824 gap=0.3177 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.5601 gap=0.4954 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.4466 gap=0.3819 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4728 gap=0.4082 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.5273 gap=0.4626 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.4714 gap=0.4067 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.6142 gap=0.5496 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.4160 gap=0.3513 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.5478 gap=0.4831 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.5256 gap=0.4610 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.3143 gap=0.2496 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.5792 gap=0.5145 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.7944 gap=0.7298 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.7566 gap=0.6920 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.5732 gap=0.5086 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.5132 gap=0.4485 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.8134 gap=0.7487 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8989 gap=0.8343 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.8281 gap=0.7635 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.8851 gap=0.8204 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.8599 gap=0.7952 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8598 gap=0.7952 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.6386 gap=0.5739 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5902 gap=0.5255 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.8263 gap=0.7617 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.6460 gap=0.5813 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.7870 gap=0.7223 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5636 gap=0.4990 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.3008 gap=0.2362 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.6572 gap=0.5926 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.1583 gap=0.0937 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.4971 gap=0.4325 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.6097 gap=0.5451 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.6856 gap=0.6210 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8024 gap=0.7377 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8007 gap=0.7361 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.7693 gap=0.7046 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.5287 gap=0.4640 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.5345 gap=0.4698 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.6369 gap=0.5723 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.6686 gap=0.6039 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.7018 gap=0.6372 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.8330 gap=0.7684 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.5151 gap=0.4504 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.9215 gap=0.8568 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8891 gap=0.8244 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6727 gap=0.6081 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6842 gap=0.6195 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.8625 gap=0.7979 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8784 gap=0.8138 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5781 gap=0.5135 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6371 gap=0.5725 train(resnet18,SDog120)-steal(resnet18)-\n",
      "14\t generating inputs for pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "initial_evaluation: score=0.6643, divergence=0.0000, diversity=1.3286, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6644, divergence=0.0001, diversity=1.3286, num_succ=0, num_remain=87\n",
      " 100-th evaluation: score=0.6646, divergence=0.0002, diversity=1.3287, num_succ=0, num_remain=55\n",
      " 200-th evaluation: score=0.6647, divergence=0.0003, diversity=1.3288, num_succ=0, num_remain=50\n",
      " 300-th evaluation: score=0.6647, divergence=0.0003, diversity=1.3288, num_succ=0, num_remain=45\n",
      " 400-th evaluation: score=0.6648, divergence=0.0003, diversity=1.3288, num_succ=0, num_remain=46\n",
      " 500-th evaluation: score=0.6648, divergence=0.0004, diversity=1.3289, num_succ=0, num_remain=43\n",
      " 600-th evaluation: score=0.6648, divergence=0.0004, diversity=1.3289, num_succ=0, num_remain=36\n",
      " 700-th evaluation: score=0.6649, divergence=0.0004, diversity=1.3289, num_succ=0, num_remain=40\n",
      " 800-th evaluation: score=0.6649, divergence=0.0004, diversity=1.3289, num_succ=0, num_remain=37\n",
      " 900-th evaluation: score=0.6650, divergence=0.0005, diversity=1.3290, num_succ=0, num_remain=43\n",
      "evaluating inputs\n",
      "parent_sim: 0.1774 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.2692 gap=0.0918 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.2764 gap=0.0990 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.3526 gap=0.1752 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.3682 gap=0.1907 train(resnet18,Flower102)-\n",
      "ref_sim: 0.2870 gap=0.1096 train(resnet18,SDog120)-\n",
      "ref_sim: 0.3270 gap=0.1496 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.3078 gap=0.1303 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.2746 gap=0.0972 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.2615 gap=0.0841 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.1852 gap=0.0078 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.2242 gap=0.0468 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.2744 gap=0.0969 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.3512 gap=0.1738 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.3947 gap=0.2173 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3062 gap=0.1288 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.3477 gap=0.1703 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.3956 gap=0.2182 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2894 gap=0.1120 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.3265 gap=0.1490 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.3474 gap=0.1700 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1462 gap=-0.0312 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\u001b[0m\n",
      "ref_sim: 0.2448 gap=0.0673 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.3804 gap=0.2029 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.1784 gap=0.0010 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2118 gap=0.0344 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4268 gap=0.2494 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2802 gap=0.1028 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.2924 gap=0.1150 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.3481 gap=0.1707 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.3963 gap=0.2189 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.3352 gap=0.1577 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.3341 gap=0.1567 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.3512 gap=0.1738 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.4832 gap=0.3057 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.3083 gap=0.1308 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.5784 gap=0.4009 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.2373 gap=0.0598 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.2871 gap=0.1096 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.3928 gap=0.2154 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.4577 gap=0.2802 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3955 gap=0.2180 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.6889 gap=0.5115 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.2631 gap=0.0857 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.5342 gap=0.3568 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.3795 gap=0.2021 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.6566 gap=0.4791 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3121 gap=0.1346 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.2309 gap=0.0535 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1619 gap=-0.0155 train(mbnetv2,Flower102)-prune(0.5)-\u001b[0m\n",
      "ref_sim: 0.3494 gap=0.1720 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3763 gap=0.1989 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4304 gap=0.2530 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4907 gap=0.3133 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.3627 gap=0.1853 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.3600 gap=0.1826 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.3937 gap=0.2163 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.2099 gap=0.0324 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.2514 gap=0.0739 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.2336 gap=0.0562 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.2780 gap=0.1005 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.4333 gap=0.2559 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.4323 gap=0.2549 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.3402 gap=0.1627 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.3302 gap=0.1528 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.3992 gap=0.2218 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.4588 gap=0.2814 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.3316 gap=0.1541 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.2857 gap=0.1083 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.3783 gap=0.2009 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5028 gap=0.3254 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5166 gap=0.3391 train(resnet18,SDog120)-steal(resnet18)-\n",
      "15\t generating inputs for pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "initial_evaluation: score=0.4377, divergence=0.0000, diversity=0.8754, num_succ=0, num_remain=7\n",
      "   0-th evaluation: score=0.4383, divergence=0.0007, diversity=0.8753, num_succ=0, num_remain=76\n",
      " 100-th evaluation: score=0.4400, divergence=0.0022, diversity=0.8757, num_succ=0, num_remain=49\n",
      " 200-th evaluation: score=0.4408, divergence=0.0027, diversity=0.8761, num_succ=0, num_remain=38\n",
      " 300-th evaluation: score=0.4417, divergence=0.0035, diversity=0.8764, num_succ=0, num_remain=41\n",
      " 400-th evaluation: score=0.4423, divergence=0.0040, diversity=0.8766, num_succ=0, num_remain=30\n",
      " 500-th evaluation: score=0.4430, divergence=0.0047, diversity=0.8767, num_succ=0, num_remain=32\n",
      " 600-th evaluation: score=0.4435, divergence=0.0051, diversity=0.8769, num_succ=0, num_remain=33\n",
      " 700-th evaluation: score=0.4441, divergence=0.0055, diversity=0.8771, num_succ=0, num_remain=30\n",
      " 800-th evaluation: score=0.4447, divergence=0.0060, diversity=0.8774, num_succ=0, num_remain=32\n",
      " 900-th evaluation: score=0.4452, divergence=0.0064, diversity=0.8775, num_succ=0, num_remain=35\n",
      "evaluating inputs\n",
      "parent_sim: 0.0961 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.2194 gap=0.1233 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.7780 gap=0.6819 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.3315 gap=0.2354 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.8361 gap=0.7400 train(resnet18,Flower102)-\n",
      "ref_sim: 0.5970 gap=0.5010 train(resnet18,SDog120)-\n",
      "ref_sim: 0.2649 gap=0.1688 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.4386 gap=0.3425 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0951 gap=-0.0010 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\u001b[0m\n",
      "ref_sim: 0.2474 gap=0.1513 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0349 gap=-0.0612 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0150 gap=-0.0811 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\u001b[0m\n",
      "ref_sim: 0.5158 gap=0.4197 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.5465 gap=0.4504 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.5439 gap=0.4478 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.2707 gap=0.1746 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.4372 gap=0.3411 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.6770 gap=0.5809 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0689 gap=-0.0272 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\u001b[0m\n",
      "ref_sim: 0.3180 gap=0.2219 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.1440 gap=0.0479 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0142 gap=-0.0819 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0142 gap=-0.0819 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\u001b[0m\n",
      "ref_sim: 0.1752 gap=0.0791 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0074 gap=-0.0887 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0124 gap=-0.0837 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\u001b[0m\n",
      "ref_sim: 0.5490 gap=0.4529 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0105 gap=-0.0855 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0120 gap=-0.0841 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\u001b[0m\n",
      "ref_sim: 0.3425 gap=0.2465 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.7926 gap=0.6965 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.8397 gap=0.7436 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.6411 gap=0.5450 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.4921 gap=0.3960 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.2577 gap=0.1616 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.7075 gap=0.6114 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.8049 gap=0.7088 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8038 gap=0.7077 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.7970 gap=0.7009 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.8713 gap=0.7752 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.8100 gap=0.7139 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8646 gap=0.7685 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.8950 gap=0.7989 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.7880 gap=0.6919 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.8510 gap=0.7550 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.8254 gap=0.7293 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.8333 gap=0.7372 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8099 gap=0.7138 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.8188 gap=0.7227 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.7856 gap=0.6895 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.6856 gap=0.5895 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.4379 gap=0.3418 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.2567 gap=0.1606 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4651 gap=0.3690 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8237 gap=0.7276 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8365 gap=0.7404 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.8508 gap=0.7547 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.6216 gap=0.5255 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.6692 gap=0.5731 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.6127 gap=0.5167 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.7857 gap=0.6896 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.6995 gap=0.6035 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.8896 gap=0.7935 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.7907 gap=0.6946 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.8127 gap=0.7166 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8413 gap=0.7452 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5779 gap=0.4818 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6977 gap=0.6017 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.8374 gap=0.7413 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.9194 gap=0.8233 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.3905 gap=0.2944 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.7128 gap=0.6167 train(resnet18,SDog120)-steal(resnet18)-\n",
      "16\t generating inputs for pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "initial_evaluation: score=0.5491, divergence=0.0000, diversity=1.0982, num_succ=0, num_remain=7\n",
      "   0-th evaluation: score=0.5497, divergence=0.0006, diversity=1.0984, num_succ=0, num_remain=81\n",
      " 100-th evaluation: score=0.5511, divergence=0.0017, diversity=1.0989, num_succ=0, num_remain=41\n",
      " 200-th evaluation: score=0.5516, divergence=0.0020, diversity=1.0993, num_succ=0, num_remain=39\n",
      " 300-th evaluation: score=0.5521, divergence=0.0023, diversity=1.0996, num_succ=0, num_remain=31\n",
      " 400-th evaluation: score=0.5525, divergence=0.0026, diversity=1.0998, num_succ=1, num_remain=28\n",
      " 500-th evaluation: score=0.5527, divergence=0.0028, diversity=1.1000, num_succ=1, num_remain=25\n",
      " 600-th evaluation: score=0.5530, divergence=0.0029, diversity=1.1002, num_succ=1, num_remain=24\n",
      " 700-th evaluation: score=0.5535, divergence=0.0033, diversity=1.1004, num_succ=1, num_remain=24\n",
      " 800-th evaluation: score=0.5537, divergence=0.0034, diversity=1.1006, num_succ=1, num_remain=24\n",
      " 900-th evaluation: score=0.5540, divergence=0.0037, diversity=1.1008, num_succ=1, num_remain=21\n",
      "evaluating inputs\n",
      "parent_sim: 0.3867 pretrain(resnet18,ImageNet)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2749 gap=-0.1117 pretrain(mbnetv2,ImageNet)-\u001b[0m\n",
      "ref_sim: 0.5902 gap=0.2035 train(mbnetv2,Flower102)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.3366 gap=-0.0500 train(mbnetv2,SDog120)-\u001b[0m\n",
      "ref_sim: 0.8397 gap=0.4531 train(resnet18,Flower102)-\n",
      "ref_sim: 0.4646 gap=0.0779 train(resnet18,SDog120)-\n",
      "ref_sim: 0.7430 gap=0.3564 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.3548 gap=-0.0319 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\u001b[0m\n",
      "ref_sim: 0.5485 gap=0.1618 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0219 gap=-0.3648 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0168 gap=-0.3699 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2279 gap=-0.1588 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\u001b[0m\n",
      "ref_sim: 0.6125 gap=0.2259 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.7223 gap=0.3356 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.7941 gap=0.4075 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.3856 gap=-0.0011 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\u001b[0m\n",
      "ref_sim: 0.6687 gap=0.2821 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.8215 gap=0.4348 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.5015 gap=0.1148 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.6407 gap=0.2540 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.7910 gap=0.4043 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0901 gap=-0.2965 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0450 gap=-0.3417 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0595 gap=-0.3272 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2115 gap=-0.1752 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1710 gap=-0.2157 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0259 gap=-0.3608 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2724 gap=-0.1142 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0676 gap=-0.3191 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0313 gap=-0.3554 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.8386 gap=0.4519 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.6348 gap=0.2482 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.7055 gap=0.3189 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0305 gap=-0.3562 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0358 gap=-0.3508 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0392 gap=-0.3475 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\u001b[0m\n",
      "ref_sim: 0.6601 gap=0.2734 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6756 gap=0.2889 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.7463 gap=0.3597 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.8141 gap=0.4274 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.6051 gap=0.2184 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.7959 gap=0.4093 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0561 gap=-0.3305 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2256 gap=-0.1611 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0655 gap=-0.3211 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0951 gap=-0.2915 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0602 gap=-0.3264 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0528 gap=-0.3338 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.6387 gap=0.2520 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.5845 gap=0.1978 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.5560 gap=0.1694 train(mbnetv2,Flower102)-prune(0.8)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m[ERROR] ref_sim: 0.1850 gap=-0.2016 train(mbnetv2,SDog120)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3147 gap=-0.0719 train(mbnetv2,SDog120)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3114 gap=-0.0753 train(mbnetv2,SDog120)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.8368 gap=0.4502 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8289 gap=0.4422 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.8472 gap=0.4605 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.5203 gap=0.1337 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4623 gap=0.0757 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.5196 gap=0.1329 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.7534 gap=0.3667 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.6321 gap=0.2454 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.8311 gap=0.4444 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.6959 gap=0.3092 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.6302 gap=0.2436 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8613 gap=0.4746 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.4080 gap=0.0214 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.7428 gap=0.3562 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.6096 gap=0.2229 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8478 gap=0.4611 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.3924 gap=0.0058 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1174 gap=-0.2692 train(resnet18,SDog120)-steal(resnet18)-\u001b[0m\n",
      "17\t generating inputs for pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "initial_evaluation: score=0.5354, divergence=0.0000, diversity=1.0707, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.5359, divergence=0.0005, diversity=1.0709, num_succ=0, num_remain=81\n",
      " 100-th evaluation: score=0.5369, divergence=0.0013, diversity=1.0711, num_succ=0, num_remain=47\n",
      " 200-th evaluation: score=0.5374, divergence=0.0017, diversity=1.0714, num_succ=0, num_remain=44\n",
      " 300-th evaluation: score=0.5379, divergence=0.0020, diversity=1.0717, num_succ=0, num_remain=46\n",
      " 400-th evaluation: score=0.5384, divergence=0.0024, diversity=1.0719, num_succ=0, num_remain=43\n",
      " 500-th evaluation: score=0.5388, divergence=0.0027, diversity=1.0721, num_succ=0, num_remain=42\n",
      " 600-th evaluation: score=0.5392, divergence=0.0031, diversity=1.0723, num_succ=0, num_remain=43\n",
      " 700-th evaluation: score=0.5396, divergence=0.0034, diversity=1.0725, num_succ=0, num_remain=42\n",
      " 800-th evaluation: score=0.5401, divergence=0.0037, diversity=1.0727, num_succ=0, num_remain=39\n",
      " 900-th evaluation: score=0.5405, divergence=0.0040, diversity=1.0729, num_succ=0, num_remain=40\n",
      "evaluating inputs\n",
      "parent_sim: 0.1314 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.2911 gap=0.1597 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.3916 gap=0.2602 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.2747 gap=0.1434 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.7403 gap=0.6090 train(resnet18,Flower102)-\n",
      "ref_sim: 0.3081 gap=0.1768 train(resnet18,SDog120)-\n",
      "ref_sim: 0.4906 gap=0.3593 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.6869 gap=0.5556 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.6796 gap=0.5483 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.4474 gap=0.3161 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.4334 gap=0.3020 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.5054 gap=0.3741 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.5863 gap=0.4549 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.7546 gap=0.6232 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.1831 gap=0.0518 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.6774 gap=0.5460 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.7885 gap=0.6572 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4160 gap=0.2847 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.6974 gap=0.5660 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.7064 gap=0.5751 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.1962 gap=0.0649 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.5326 gap=0.4012 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.4926 gap=0.3612 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.5331 gap=0.4017 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3822 gap=0.2508 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.3328 gap=0.2015 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.2941 gap=0.1627 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.3546 gap=0.2232 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.4893 gap=0.3580 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.3552 gap=0.2238 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.6966 gap=0.5652 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.7406 gap=0.6093 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.6998 gap=0.5684 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.2885 gap=0.1571 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.4967 gap=0.3653 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.1976 gap=0.0662 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.5674 gap=0.4361 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5312 gap=0.3998 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.5751 gap=0.4437 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.6980 gap=0.5667 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5045 gap=0.3731 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6828 gap=0.5514 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.3172 gap=0.1859 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.2375 gap=0.1061 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.4476 gap=0.3162 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.3250 gap=0.1936 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5224 gap=0.3910 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3609 gap=0.2295 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.5602 gap=0.4288 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.4875 gap=0.3561 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.6006 gap=0.4693 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.2249 gap=0.0936 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.2466 gap=0.1152 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4662 gap=0.3348 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.7396 gap=0.6083 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.7486 gap=0.6172 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.7650 gap=0.6336 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3448 gap=0.2134 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.3376 gap=0.2063 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4878 gap=0.3565 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.5772 gap=0.4459 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.3852 gap=0.2538 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.7872 gap=0.6559 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.6499 gap=0.5185 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.6384 gap=0.5070 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8197 gap=0.6883 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5483 gap=0.4170 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5931 gap=0.4617 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.6392 gap=0.5079 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8203 gap=0.6890 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.2870 gap=0.1557 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.3031 gap=0.1718 train(resnet18,SDog120)-steal(resnet18)-\n",
      "42\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_evaluation: score=0.6610, divergence=0.0000, diversity=1.3221, num_succ=0, num_remain=8\n",
      "   0-th evaluation: score=0.6612, divergence=0.0001, diversity=1.3221, num_succ=0, num_remain=91\n",
      " 100-th evaluation: score=0.6614, divergence=0.0003, diversity=1.3222, num_succ=0, num_remain=55\n",
      " 200-th evaluation: score=0.6616, divergence=0.0004, diversity=1.3223, num_succ=0, num_remain=51\n",
      " 300-th evaluation: score=0.6616, divergence=0.0005, diversity=1.3223, num_succ=0, num_remain=50\n",
      " 400-th evaluation: score=0.6617, divergence=0.0005, diversity=1.3224, num_succ=0, num_remain=49\n",
      " 500-th evaluation: score=0.6618, divergence=0.0006, diversity=1.3224, num_succ=0, num_remain=51\n",
      " 600-th evaluation: score=0.6619, divergence=0.0007, diversity=1.3224, num_succ=0, num_remain=44\n",
      " 700-th evaluation: score=0.6620, divergence=0.0008, diversity=1.3225, num_succ=0, num_remain=46\n",
      " 800-th evaluation: score=0.6621, divergence=0.0009, diversity=1.3225, num_succ=0, num_remain=50\n",
      " 900-th evaluation: score=0.6622, divergence=0.0009, diversity=1.3225, num_succ=0, num_remain=42\n",
      "evaluating inputs\n",
      "parent_sim: 0.0891 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.1093 gap=0.0203 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.8179 gap=0.7289 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.6984 gap=0.6094 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.8493 gap=0.7603 train(resnet18,Flower102)-\n",
      "ref_sim: 0.6995 gap=0.6104 train(resnet18,SDog120)-\n",
      "ref_sim: 0.1294 gap=0.0403 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.2069 gap=0.1178 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.3806 gap=0.2915 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.0914 gap=0.0023 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.1901 gap=0.1011 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.2169 gap=0.1278 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.2176 gap=0.1285 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.2185 gap=0.1294 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.2063 gap=0.1172 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.2369 gap=0.1479 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.3047 gap=0.2156 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.2512 gap=0.1622 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.3872 gap=0.2981 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.3619 gap=0.2729 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.4155 gap=0.3264 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.3190 gap=0.2299 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.1594 gap=0.0704 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.1321 gap=0.0430 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.4078 gap=0.3187 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.1643 gap=0.0752 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.1635 gap=0.0744 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2743 gap=0.1852 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.1400 gap=0.0509 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.2769 gap=0.1878 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.4103 gap=0.3212 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.6386 gap=0.5495 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.6950 gap=0.6059 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.1185 gap=0.0294 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.5533 gap=0.4643 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.4868 gap=0.3977 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.7377 gap=0.6486 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.7767 gap=0.6877 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.8488 gap=0.7597 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.8428 gap=0.7537 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.9289 gap=0.8399 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.7098 gap=0.6208 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.4681 gap=0.3790 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.2735 gap=0.1845 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.7093 gap=0.6202 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.5303 gap=0.4412 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.6887 gap=0.5996 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.7031 gap=0.6141 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.7788 gap=0.6898 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.7144 gap=0.6253 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.3026 gap=0.2136 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.7150 gap=0.6260 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.6605 gap=0.5714 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.6540 gap=0.5649 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8272 gap=0.7382 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8510 gap=0.7619 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.8581 gap=0.7690 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.6946 gap=0.6055 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.6981 gap=0.6090 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.6608 gap=0.5717 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8385 gap=0.7495 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.7248 gap=0.6358 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.9176 gap=0.8285 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.7804 gap=0.6913 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.9530 gap=0.8639 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8594 gap=0.7703 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.7175 gap=0.6285 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6220 gap=0.5329 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.7171 gap=0.6281 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8723 gap=0.7832 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.8612 gap=0.7722 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6520 gap=0.5629 train(resnet18,SDog120)-steal(resnet18)-\n",
      "43\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "initial_evaluation: score=0.6621, divergence=0.0000, diversity=1.3241, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6622, divergence=0.0001, diversity=1.3242, num_succ=0, num_remain=87\n",
      " 100-th evaluation: score=0.6625, divergence=0.0004, diversity=1.3243, num_succ=0, num_remain=41\n",
      " 200-th evaluation: score=0.6626, divergence=0.0005, diversity=1.3243, num_succ=0, num_remain=35\n",
      " 300-th evaluation: score=0.6627, divergence=0.0005, diversity=1.3243, num_succ=0, num_remain=34\n",
      " 400-th evaluation: score=0.6628, divergence=0.0006, diversity=1.3244, num_succ=0, num_remain=36\n",
      " 500-th evaluation: score=0.6629, divergence=0.0007, diversity=1.3244, num_succ=0, num_remain=39\n",
      " 600-th evaluation: score=0.6630, divergence=0.0008, diversity=1.3244, num_succ=0, num_remain=36\n",
      " 700-th evaluation: score=0.6630, divergence=0.0008, diversity=1.3244, num_succ=0, num_remain=30\n",
      " 800-th evaluation: score=0.6631, divergence=0.0009, diversity=1.3244, num_succ=0, num_remain=38\n",
      " 900-th evaluation: score=0.6632, divergence=0.0010, diversity=1.3244, num_succ=0, num_remain=36\n",
      "evaluating inputs\n",
      "parent_sim: 0.0891 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.3883 gap=0.2991 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.5986 gap=0.5095 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.7262 gap=0.6371 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.8647 gap=0.7756 train(resnet18,Flower102)-\n",
      "ref_sim: 0.8489 gap=0.7598 train(resnet18,SDog120)-\n",
      "ref_sim: 0.3573 gap=0.2682 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.2183 gap=0.1292 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.3093 gap=0.2202 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.2948 gap=0.2057 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.6768 gap=0.5877 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.2943 gap=0.2052 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.3801 gap=0.2910 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.3503 gap=0.2612 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.3336 gap=0.2445 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3059 gap=0.2168 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2626 gap=0.1735 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.2310 gap=0.1419 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.3255 gap=0.2364 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.3216 gap=0.2325 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.2255 gap=0.1364 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.3889 gap=0.2997 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.3839 gap=0.2948 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.2751 gap=0.1859 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.6256 gap=0.5364 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.6530 gap=0.5639 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4166 gap=0.3274 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.4803 gap=0.3911 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.5804 gap=0.4913 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.3831 gap=0.2940 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.3879 gap=0.2988 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.3466 gap=0.2575 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.5722 gap=0.4831 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.2710 gap=0.1819 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.6265 gap=0.5373 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.4160 gap=0.3269 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.6188 gap=0.5296 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6227 gap=0.5336 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.8341 gap=0.7449 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.8276 gap=0.7385 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.8430 gap=0.7539 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5955 gap=0.5064 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.4254 gap=0.3363 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4054 gap=0.3163 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.6259 gap=0.5368 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.6184 gap=0.5293 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.4910 gap=0.4019 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6000 gap=0.5109 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.4648 gap=0.3757 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.5445 gap=0.4554 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.6075 gap=0.5184 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.7476 gap=0.6584 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.6195 gap=0.5303 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.5255 gap=0.4364 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8697 gap=0.7805 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8627 gap=0.7736 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.8841 gap=0.7950 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.8197 gap=0.7306 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.8413 gap=0.7522 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.8037 gap=0.7145 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.7773 gap=0.6881 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.7715 gap=0.6824 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.9161 gap=0.8270 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.8879 gap=0.7988 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.6861 gap=0.5969 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8882 gap=0.7991 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6610 gap=0.5718 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.4254 gap=0.3363 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.8148 gap=0.7257 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8908 gap=0.8017 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5842 gap=0.4951 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6256 gap=0.5365 train(resnet18,SDog120)-steal(resnet18)-\n",
      "44\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "initial_evaluation: score=0.6194, divergence=0.0000, diversity=1.2389, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6197, divergence=0.0003, diversity=1.2389, num_succ=0, num_remain=90\n",
      " 100-th evaluation: score=0.6206, divergence=0.0010, diversity=1.2391, num_succ=0, num_remain=47\n",
      " 200-th evaluation: score=0.6209, divergence=0.0012, diversity=1.2392, num_succ=0, num_remain=45\n",
      " 300-th evaluation: score=0.6212, divergence=0.0015, diversity=1.2395, num_succ=0, num_remain=38\n",
      " 400-th evaluation: score=0.6215, divergence=0.0017, diversity=1.2396, num_succ=0, num_remain=42\n",
      " 500-th evaluation: score=0.6218, divergence=0.0019, diversity=1.2399, num_succ=0, num_remain=36\n",
      " 600-th evaluation: score=0.6220, divergence=0.0020, diversity=1.2399, num_succ=0, num_remain=34\n",
      " 700-th evaluation: score=0.6222, divergence=0.0022, diversity=1.2401, num_succ=0, num_remain=33\n",
      " 800-th evaluation: score=0.6224, divergence=0.0024, diversity=1.2402, num_succ=0, num_remain=35\n",
      " 900-th evaluation: score=0.6228, divergence=0.0026, diversity=1.2404, num_succ=0, num_remain=36\n",
      "evaluating inputs\n",
      "parent_sim: 0.2629 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.4016 gap=0.1387 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.7680 gap=0.5051 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.4243 gap=0.1614 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.8415 gap=0.5786 train(resnet18,Flower102)-\n",
      "ref_sim: 0.8472 gap=0.5843 train(resnet18,SDog120)-\n",
      "ref_sim: 0.4194 gap=0.1565 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.3650 gap=0.1022 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.4284 gap=0.1655 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.4165 gap=0.1536 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.4758 gap=0.2129 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.7641 gap=0.5012 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.4743 gap=0.2114 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.5176 gap=0.2547 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4036 gap=0.1407 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.4198 gap=0.1569 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.4139 gap=0.1510 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4154 gap=0.1526 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.4093 gap=0.1464 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.4333 gap=0.1704 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.2800 gap=0.0171 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.8017 gap=0.5388 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.6182 gap=0.3553 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.5694 gap=0.3065 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.8368 gap=0.5739 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.7723 gap=0.5094 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.6901 gap=0.4273 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.8380 gap=0.5751 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.8258 gap=0.5630 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.7727 gap=0.5099 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.4340 gap=0.1711 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.5247 gap=0.2618 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.5380 gap=0.2751 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.6070 gap=0.3441 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.6726 gap=0.4097 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.7643 gap=0.5014 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.7891 gap=0.5262 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6988 gap=0.4359 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.7836 gap=0.5207 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.9044 gap=0.6415 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.8726 gap=0.6097 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8291 gap=0.5662 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.4392 gap=0.1763 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5800 gap=0.3171 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.6053 gap=0.3424 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.6179 gap=0.3550 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5871 gap=0.3242 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8157 gap=0.5528 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.6686 gap=0.4057 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.6274 gap=0.3645 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.4971 gap=0.2342 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3747 gap=0.1119 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.5490 gap=0.2861 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.5987 gap=0.3358 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8491 gap=0.5862 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8568 gap=0.5939 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.8733 gap=0.6105 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.8418 gap=0.5789 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.8433 gap=0.5804 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.8287 gap=0.5658 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.7849 gap=0.5221 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.5425 gap=0.2796 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.9069 gap=0.6440 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.8188 gap=0.5559 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.7530 gap=0.4902 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.9177 gap=0.6548 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.4760 gap=0.2131 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.7405 gap=0.4776 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.8999 gap=0.6370 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.9018 gap=0.6390 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.7241 gap=0.4612 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5845 gap=0.3216 train(resnet18,SDog120)-steal(resnet18)-\n",
      "45\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "initial_evaluation: score=0.6831, divergence=0.0000, diversity=1.3662, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6831, divergence=0.0000, diversity=1.3662, num_succ=0, num_remain=90\n",
      " 100-th evaluation: score=0.6832, divergence=0.0001, diversity=1.3663, num_succ=0, num_remain=47\n",
      " 200-th evaluation: score=0.6833, divergence=0.0002, diversity=1.3663, num_succ=0, num_remain=44\n",
      " 300-th evaluation: score=0.6833, divergence=0.0002, diversity=1.3663, num_succ=0, num_remain=39\n",
      " 400-th evaluation: score=0.6834, divergence=0.0002, diversity=1.3663, num_succ=0, num_remain=47\n",
      " 500-th evaluation: score=0.6834, divergence=0.0003, diversity=1.3663, num_succ=0, num_remain=42\n",
      " 600-th evaluation: score=0.6835, divergence=0.0003, diversity=1.3663, num_succ=0, num_remain=42\n",
      " 700-th evaluation: score=0.6835, divergence=0.0003, diversity=1.3663, num_succ=0, num_remain=42\n",
      " 800-th evaluation: score=0.6835, divergence=0.0004, diversity=1.3663, num_succ=0, num_remain=40\n",
      " 900-th evaluation: score=0.6836, divergence=0.0004, diversity=1.3664, num_succ=0, num_remain=35\n",
      "evaluating inputs\n",
      "parent_sim: 0.0451 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.1318 gap=0.0867 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.3352 gap=0.2901 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.3873 gap=0.3422 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.4991 gap=0.4540 train(resnet18,Flower102)-\n",
      "ref_sim: 0.4528 gap=0.4077 train(resnet18,SDog120)-\n",
      "ref_sim: 0.2339 gap=0.1888 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.1683 gap=0.1232 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.2037 gap=0.1586 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.1994 gap=0.1543 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.2187 gap=0.1736 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.2378 gap=0.1927 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.1477 gap=0.1026 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.1444 gap=0.0993 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.2105 gap=0.1654 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.1580 gap=0.1129 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.1602 gap=0.1150 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.1810 gap=0.1359 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.1991 gap=0.1540 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.1690 gap=0.1239 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.2071 gap=0.1620 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.1758 gap=0.1307 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.2131 gap=0.1679 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.1925 gap=0.1474 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.2281 gap=0.1830 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2348 gap=0.1897 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.2096 gap=0.1644 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2181 gap=0.1730 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.2341 gap=0.1890 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.2472 gap=0.2021 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.1766 gap=0.1315 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.1945 gap=0.1494 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.2388 gap=0.1937 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.2777 gap=0.2326 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.2998 gap=0.2547 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.3562 gap=0.3111 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.4236 gap=0.3785 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3877 gap=0.3425 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.3986 gap=0.3535 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.4464 gap=0.4012 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5196 gap=0.4745 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.4199 gap=0.3748 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.4785 gap=0.4334 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4823 gap=0.4372 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.4976 gap=0.4524 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.5332 gap=0.4881 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.4776 gap=0.4325 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5357 gap=0.4906 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.3844 gap=0.3393 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.2031 gap=0.1580 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.3271 gap=0.2820 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.2820 gap=0.2369 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4318 gap=0.3867 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4583 gap=0.4132 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.4548 gap=0.4097 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.4388 gap=0.3936 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.5064 gap=0.4612 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.4583 gap=0.4132 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4263 gap=0.3812 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.3733 gap=0.3282 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.4580 gap=0.4129 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.4712 gap=0.4261 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.5956 gap=0.5504 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.4180 gap=0.3729 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.3232 gap=0.2781 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.6148 gap=0.5696 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6625 gap=0.6173 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5447 gap=0.4996 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.5062 gap=0.4611 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.6139 gap=0.5688 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.7791 gap=0.7339 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6522 gap=0.6071 train(resnet18,SDog120)-steal(resnet18)-\n",
      "46\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "initial_evaluation: score=0.6841, divergence=0.0000, diversity=1.3683, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6842, divergence=0.0000, diversity=1.3683, num_succ=0, num_remain=84\n",
      " 100-th evaluation: score=0.6843, divergence=0.0002, diversity=1.3683, num_succ=0, num_remain=55\n",
      " 200-th evaluation: score=0.6844, divergence=0.0002, diversity=1.3683, num_succ=0, num_remain=46\n",
      " 300-th evaluation: score=0.6845, divergence=0.0003, diversity=1.3683, num_succ=0, num_remain=43\n",
      " 400-th evaluation: score=0.6845, divergence=0.0004, diversity=1.3683, num_succ=0, num_remain=41\n",
      " 500-th evaluation: score=0.6846, divergence=0.0004, diversity=1.3684, num_succ=0, num_remain=36\n",
      " 600-th evaluation: score=0.6846, divergence=0.0004, diversity=1.3684, num_succ=0, num_remain=36\n",
      " 700-th evaluation: score=0.6846, divergence=0.0005, diversity=1.3684, num_succ=0, num_remain=34\n",
      " 800-th evaluation: score=0.6847, divergence=0.0005, diversity=1.3684, num_succ=0, num_remain=33\n",
      " 900-th evaluation: score=0.6847, divergence=0.0005, diversity=1.3684, num_succ=0, num_remain=47\n",
      "evaluating inputs\n",
      "parent_sim: 0.1590 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.4624 gap=0.3033 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.5453 gap=0.3863 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.5603 gap=0.4013 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.7789 gap=0.6199 train(resnet18,Flower102)-\n",
      "ref_sim: 0.6933 gap=0.5342 train(resnet18,SDog120)-\n",
      "ref_sim: 0.3393 gap=0.1802 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.2831 gap=0.1240 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.2208 gap=0.0617 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.3016 gap=0.1426 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.5769 gap=0.4178 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.3795 gap=0.2204 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.3987 gap=0.2397 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.5257 gap=0.3666 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.2858 gap=0.1268 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3438 gap=0.1847 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.3150 gap=0.1559 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.2944 gap=0.1354 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2452 gap=0.0861 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.2137 gap=0.0546 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.2327 gap=0.0736 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.5114 gap=0.3524 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.4419 gap=0.2829 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4230 gap=0.2639 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.6974 gap=0.5383 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.5831 gap=0.4240 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.3580 gap=0.1990 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.5959 gap=0.4368 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.5397 gap=0.3807 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.3004 gap=0.1414 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.2858 gap=0.1268 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.3213 gap=0.1622 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.3584 gap=0.1993 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.4080 gap=0.2490 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.4609 gap=0.3018 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.4369 gap=0.2778 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.4048 gap=0.2457 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5901 gap=0.4310 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.4806 gap=0.3215 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.6131 gap=0.4541 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5559 gap=0.3969 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6617 gap=0.5027 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.8499 gap=0.6909 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5403 gap=0.3812 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.5453 gap=0.3863 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.5565 gap=0.3975 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.7463 gap=0.5873 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5363 gap=0.3772 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.3550 gap=0.1960 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.4668 gap=0.3077 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.3009 gap=0.1419 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.4285 gap=0.2694 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.6223 gap=0.4633 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4497 gap=0.2906 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.7266 gap=0.5675 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.7510 gap=0.5920 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.7505 gap=0.5914 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.6879 gap=0.5289 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.6804 gap=0.5214 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.6091 gap=0.4501 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.3990 gap=0.2400 train(mbnetv2,Flower102)-distill()-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.5944 gap=0.4353 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.8482 gap=0.6892 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.7379 gap=0.5788 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.4124 gap=0.2533 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8813 gap=0.7223 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6579 gap=0.4988 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.7148 gap=0.5558 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.4237 gap=0.2647 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8447 gap=0.6856 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.8120 gap=0.6530 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6758 gap=0.5167 train(resnet18,SDog120)-steal(resnet18)-\n",
      "47\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "initial_evaluation: score=0.5990, divergence=0.0000, diversity=1.1980, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.5997, divergence=0.0006, diversity=1.1982, num_succ=0, num_remain=88\n",
      " 100-th evaluation: score=0.6010, divergence=0.0017, diversity=1.1986, num_succ=0, num_remain=52\n",
      " 200-th evaluation: score=0.6016, divergence=0.0022, diversity=1.1989, num_succ=0, num_remain=48\n",
      " 300-th evaluation: score=0.6020, divergence=0.0025, diversity=1.1990, num_succ=0, num_remain=44\n",
      " 400-th evaluation: score=0.6024, divergence=0.0028, diversity=1.1992, num_succ=0, num_remain=42\n",
      " 500-th evaluation: score=0.6027, divergence=0.0030, diversity=1.1993, num_succ=0, num_remain=37\n",
      " 600-th evaluation: score=0.6030, divergence=0.0033, diversity=1.1995, num_succ=0, num_remain=35\n",
      " 700-th evaluation: score=0.6033, divergence=0.0035, diversity=1.1995, num_succ=0, num_remain=35\n",
      " 800-th evaluation: score=0.6034, divergence=0.0036, diversity=1.1996, num_succ=0, num_remain=37\n",
      " 900-th evaluation: score=0.6036, divergence=0.0038, diversity=1.1997, num_succ=0, num_remain=34\n",
      "evaluating inputs\n",
      "parent_sim: 0.2926 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.4806 gap=0.1880 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.5212 gap=0.2286 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.5077 gap=0.2151 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.8156 gap=0.5230 train(resnet18,Flower102)-\n",
      "ref_sim: 0.6358 gap=0.3432 train(resnet18,SDog120)-\n",
      "ref_sim: 0.3826 gap=0.0900 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.3171 gap=0.0245 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.3530 gap=0.0604 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.4172 gap=0.1246 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.4938 gap=0.2012 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.5543 gap=0.2617 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.4285 gap=0.1359 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.4194 gap=0.1268 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4041 gap=0.1115 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3253 gap=0.0327 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.3303 gap=0.0377 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.3490 gap=0.0564 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.3544 gap=0.0618 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.3417 gap=0.0491 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.3404 gap=0.0478 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.5229 gap=0.2303 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.4040 gap=0.1114 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4199 gap=0.1273 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.5451 gap=0.2525 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.5425 gap=0.2500 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4670 gap=0.1744 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.5008 gap=0.2082 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.5552 gap=0.2626 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.4272 gap=0.1346 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.4778 gap=0.1852 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.3451 gap=0.0525 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.3742 gap=0.0816 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.4961 gap=0.2035 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.5094 gap=0.2168 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.3830 gap=0.0904 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.7250 gap=0.4324 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6004 gap=0.3078 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.7695 gap=0.4769 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.7703 gap=0.4777 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.7340 gap=0.4414 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.9225 gap=0.6299 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.6350 gap=0.3424 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5917 gap=0.2991 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.6645 gap=0.3719 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.4150 gap=0.1224 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.7100 gap=0.4174 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3434 gap=0.0508 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.6494 gap=0.3568 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.7782 gap=0.4856 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.4527 gap=0.1601 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3434 gap=0.0508 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4676 gap=0.1750 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.5845 gap=0.2919 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8368 gap=0.5442 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8491 gap=0.5565 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.8629 gap=0.5703 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.6106 gap=0.3180 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.6641 gap=0.3715 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.6476 gap=0.3550 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8554 gap=0.5628 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.4710 gap=0.1785 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.8926 gap=0.6000 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.7622 gap=0.4696 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.6902 gap=0.3976 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8751 gap=0.5825 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.3040 gap=0.0114 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5697 gap=0.2771 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.6323 gap=0.3397 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8781 gap=0.5855 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5491 gap=0.2565 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.4695 gap=0.1769 train(resnet18,SDog120)-steal(resnet18)-\n",
      "48\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "initial_evaluation: score=0.6831, divergence=0.0000, diversity=1.3662, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6831, divergence=0.0000, diversity=1.3662, num_succ=0, num_remain=86\n",
      " 100-th evaluation: score=0.6832, divergence=0.0001, diversity=1.3662, num_succ=0, num_remain=47\n",
      " 200-th evaluation: score=0.6832, divergence=0.0002, diversity=1.3662, num_succ=0, num_remain=41\n",
      " 300-th evaluation: score=0.6833, divergence=0.0002, diversity=1.3662, num_succ=0, num_remain=43\n",
      " 400-th evaluation: score=0.6833, divergence=0.0002, diversity=1.3662, num_succ=0, num_remain=53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 500-th evaluation: score=0.6834, divergence=0.0003, diversity=1.3662, num_succ=0, num_remain=39\n",
      " 600-th evaluation: score=0.6834, divergence=0.0003, diversity=1.3662, num_succ=0, num_remain=40\n",
      " 700-th evaluation: score=0.6835, divergence=0.0003, diversity=1.3663, num_succ=0, num_remain=38\n",
      " 800-th evaluation: score=0.6835, divergence=0.0004, diversity=1.3663, num_succ=0, num_remain=38\n",
      " 900-th evaluation: score=0.6835, divergence=0.0004, diversity=1.3663, num_succ=0, num_remain=37\n",
      "evaluating inputs\n",
      "parent_sim: 0.0226 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.2689 gap=0.2463 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.7917 gap=0.7691 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.6658 gap=0.6432 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.8900 gap=0.8674 train(resnet18,Flower102)-\n",
      "ref_sim: 0.8241 gap=0.8015 train(resnet18,SDog120)-\n",
      "ref_sim: 0.2478 gap=0.2251 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.3670 gap=0.3444 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.1828 gap=0.1602 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.2750 gap=0.2523 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.2989 gap=0.2763 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.3231 gap=0.3005 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.2487 gap=0.2261 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.3829 gap=0.3603 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.3568 gap=0.3342 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.2279 gap=0.2052 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2873 gap=0.2646 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.2805 gap=0.2579 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.1482 gap=0.1255 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.2074 gap=0.1847 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.1885 gap=0.1659 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.2662 gap=0.2436 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.2389 gap=0.2163 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.2312 gap=0.2086 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.2839 gap=0.2612 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2680 gap=0.2454 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.3769 gap=0.3543 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.3199 gap=0.2973 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.2791 gap=0.2565 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.3244 gap=0.3018 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.3650 gap=0.3424 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.4519 gap=0.4292 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.4625 gap=0.4399 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.3910 gap=0.3684 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.4511 gap=0.4285 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.5067 gap=0.4841 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.8248 gap=0.8022 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.7756 gap=0.7529 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.9123 gap=0.8897 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.9299 gap=0.9073 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.8100 gap=0.7874 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8712 gap=0.8486 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.8023 gap=0.7797 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5858 gap=0.5632 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.7675 gap=0.7449 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.5493 gap=0.5267 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.4707 gap=0.4480 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3273 gap=0.3047 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.6531 gap=0.6305 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.4385 gap=0.4158 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.1611 gap=0.1385 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.6920 gap=0.6694 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.6204 gap=0.5978 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.7044 gap=0.6817 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8805 gap=0.8579 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8693 gap=0.8467 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.8896 gap=0.8669 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.8408 gap=0.8182 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.8398 gap=0.8171 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.7499 gap=0.7273 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.5189 gap=0.4963 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.8156 gap=0.7930 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.9286 gap=0.9060 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.8754 gap=0.8528 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.8586 gap=0.8360 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.9490 gap=0.9264 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.7689 gap=0.7463 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.7423 gap=0.7197 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.9410 gap=0.9183 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.9402 gap=0.9176 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.7740 gap=0.7514 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.8058 gap=0.7832 train(resnet18,SDog120)-steal(resnet18)-\n",
      "49\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "initial_evaluation: score=0.6815, divergence=0.0000, diversity=1.3631, num_succ=0, num_remain=7\n",
      "   0-th evaluation: score=0.6816, divergence=0.0000, diversity=1.3631, num_succ=0, num_remain=84\n",
      " 100-th evaluation: score=0.6816, divergence=0.0001, diversity=1.3631, num_succ=0, num_remain=42\n",
      " 200-th evaluation: score=0.6817, divergence=0.0001, diversity=1.3631, num_succ=0, num_remain=48\n",
      " 300-th evaluation: score=0.6817, divergence=0.0002, diversity=1.3631, num_succ=0, num_remain=37\n",
      " 400-th evaluation: score=0.6818, divergence=0.0002, diversity=1.3631, num_succ=0, num_remain=33\n",
      " 500-th evaluation: score=0.6818, divergence=0.0002, diversity=1.3632, num_succ=0, num_remain=45\n",
      " 600-th evaluation: score=0.6818, divergence=0.0003, diversity=1.3632, num_succ=0, num_remain=36\n",
      " 700-th evaluation: score=0.6819, divergence=0.0003, diversity=1.3632, num_succ=0, num_remain=40\n",
      " 800-th evaluation: score=0.6819, divergence=0.0003, diversity=1.3632, num_succ=0, num_remain=39\n",
      " 900-th evaluation: score=0.6819, divergence=0.0003, diversity=1.3632, num_succ=0, num_remain=43\n",
      "evaluating inputs\n",
      "parent_sim: 0.0437 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.1772 gap=0.1335 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.5266 gap=0.4828 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.5191 gap=0.4754 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.8735 gap=0.8298 train(resnet18,Flower102)-\n",
      "ref_sim: 0.7217 gap=0.6780 train(resnet18,SDog120)-\n",
      "ref_sim: 0.2144 gap=0.1706 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.2801 gap=0.2364 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.3736 gap=0.3298 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.2439 gap=0.2001 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.3393 gap=0.2956 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.3442 gap=0.3004 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.2411 gap=0.1973 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.2510 gap=0.2072 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.3222 gap=0.2785 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3054 gap=0.2616 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.3123 gap=0.2686 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.3200 gap=0.2763 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.3349 gap=0.2912 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.3810 gap=0.3373 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.3153 gap=0.2715 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.4124 gap=0.3686 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.2723 gap=0.2286 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.2477 gap=0.2039 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3369 gap=0.2932 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.4159 gap=0.3722 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.2610 gap=0.2173 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.3496 gap=0.3058 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.4045 gap=0.3608 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.2762 gap=0.2324 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.2767 gap=0.2329 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.4330 gap=0.3893 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.4625 gap=0.4188 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.3530 gap=0.3093 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.5543 gap=0.5106 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.5197 gap=0.4760 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.5996 gap=0.5559 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6888 gap=0.6451 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.5936 gap=0.5499 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.7935 gap=0.7498 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.4796 gap=0.4358 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.7519 gap=0.7081 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.6483 gap=0.6046 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4883 gap=0.4446 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.4719 gap=0.4282 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.3200 gap=0.2763 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.4701 gap=0.4264 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5512 gap=0.5075 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.5560 gap=0.5123 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.6161 gap=0.5723 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.3826 gap=0.3388 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.5210 gap=0.4772 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.6056 gap=0.5618 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4649 gap=0.4211 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8481 gap=0.8043 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8584 gap=0.8146 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.8520 gap=0.8083 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.7279 gap=0.6842 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.7138 gap=0.6701 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.7305 gap=0.6868 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.7054 gap=0.6617 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.8299 gap=0.7862 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.8875 gap=0.8438 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.7480 gap=0.7043 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.6566 gap=0.6128 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8099 gap=0.7662 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6996 gap=0.6558 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.7115 gap=0.6678 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.6579 gap=0.6142 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8462 gap=0.8025 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6215 gap=0.5778 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6919 gap=0.6482 train(resnet18,SDog120)-steal(resnet18)-\n",
      "50\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "initial_evaluation: score=0.6168, divergence=0.0000, diversity=1.2335, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6170, divergence=0.0003, diversity=1.2334, num_succ=0, num_remain=84\n",
      " 100-th evaluation: score=0.6180, divergence=0.0012, diversity=1.2337, num_succ=0, num_remain=43\n",
      " 200-th evaluation: score=0.6183, divergence=0.0013, diversity=1.2338, num_succ=0, num_remain=42\n",
      " 300-th evaluation: score=0.6185, divergence=0.0015, diversity=1.2339, num_succ=0, num_remain=35\n",
      " 400-th evaluation: score=0.6186, divergence=0.0016, diversity=1.2340, num_succ=0, num_remain=33\n",
      " 500-th evaluation: score=0.6188, divergence=0.0017, diversity=1.2342, num_succ=0, num_remain=31\n",
      " 600-th evaluation: score=0.6190, divergence=0.0019, diversity=1.2342, num_succ=0, num_remain=33\n",
      " 700-th evaluation: score=0.6192, divergence=0.0020, diversity=1.2343, num_succ=0, num_remain=28\n",
      " 800-th evaluation: score=0.6193, divergence=0.0021, diversity=1.2343, num_succ=0, num_remain=27\n",
      " 900-th evaluation: score=0.6194, divergence=0.0022, diversity=1.2344, num_succ=0, num_remain=31\n",
      "evaluating inputs\n",
      "parent_sim: 0.5107 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2540 gap=-0.2567 pretrain(resnet18,ImageNet)-\u001b[0m\n",
      "ref_sim: 0.6999 gap=0.1892 train(mbnetv2,Flower102)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4725 gap=-0.0382 train(mbnetv2,SDog120)-\u001b[0m\n",
      "ref_sim: 0.8454 gap=0.3346 train(resnet18,Flower102)-\n",
      "ref_sim: 0.7366 gap=0.2259 train(resnet18,SDog120)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2407 gap=-0.2700 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5077 gap=-0.0030 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4283 gap=-0.0825 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2950 gap=-0.2158 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3572 gap=-0.1536 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3332 gap=-0.1776 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4637 gap=-0.0470 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4945 gap=-0.0163 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4977 gap=-0.0131 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.5137 gap=0.0030 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.5090 gap=-0.0018 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4537 gap=-0.0571 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3835 gap=-0.1272 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3865 gap=-0.1242 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3605 gap=-0.1503 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4089 gap=-0.1018 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4413 gap=-0.0694 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3741 gap=-0.1366 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3259 gap=-0.1848 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m[ERROR] ref_sim: 0.3630 gap=-0.1478 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3590 gap=-0.1518 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4084 gap=-0.1023 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3378 gap=-0.1729 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3564 gap=-0.1543 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3648 gap=-0.1459 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4406 gap=-0.0701 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\u001b[0m\n",
      "ref_sim: 0.6067 gap=0.0959 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4319 gap=-0.0789 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\u001b[0m\n",
      "ref_sim: 0.6609 gap=0.1502 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.5293 gap=0.0186 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.8394 gap=0.3286 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8318 gap=0.3210 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.8352 gap=0.3245 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.7938 gap=0.2831 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.8308 gap=0.3201 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8237 gap=0.3130 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.3109 gap=-0.1998 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2618 gap=-0.2490 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4287 gap=-0.0820 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3116 gap=-0.1992 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.5298 gap=0.0190 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4957 gap=-0.0150 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.6882 gap=0.1775 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.7726 gap=0.2619 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.6997 gap=0.1889 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4585 gap=-0.0522 train(mbnetv2,SDog120)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4901 gap=-0.0207 train(mbnetv2,SDog120)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3474 gap=-0.1634 train(mbnetv2,SDog120)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.8334 gap=0.3227 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8297 gap=0.3190 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.8324 gap=0.3217 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.7390 gap=0.2283 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.7221 gap=0.2114 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.7114 gap=0.2007 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8212 gap=0.3104 train(mbnetv2,Flower102)-distill()-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4524 gap=-0.0584 train(mbnetv2,SDog120)-distill()-\u001b[0m\n",
      "ref_sim: 0.8221 gap=0.3114 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.7937 gap=0.2830 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.8191 gap=0.3083 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8346 gap=0.3239 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.3161 gap=-0.1947 train(mbnetv2,SDog120)-steal(mbnetv2)-\u001b[0m\n",
      "ref_sim: 0.5815 gap=0.0708 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.8191 gap=0.3084 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8366 gap=0.3259 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5807 gap=0.0699 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5949 gap=0.0841 train(resnet18,SDog120)-steal(resnet18)-\n",
      "51\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "initial_evaluation: score=0.5602, divergence=0.0000, diversity=1.1204, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.5612, divergence=0.0010, diversity=1.1205, num_succ=0, num_remain=84\n",
      " 100-th evaluation: score=0.5628, divergence=0.0023, diversity=1.1211, num_succ=0, num_remain=44\n",
      " 200-th evaluation: score=0.5634, divergence=0.0027, diversity=1.1214, num_succ=0, num_remain=40\n",
      " 300-th evaluation: score=0.5639, divergence=0.0031, diversity=1.1216, num_succ=0, num_remain=38\n",
      " 400-th evaluation: score=0.5643, divergence=0.0034, diversity=1.1217, num_succ=0, num_remain=36\n",
      " 500-th evaluation: score=0.5646, divergence=0.0036, diversity=1.1219, num_succ=0, num_remain=39\n",
      " 600-th evaluation: score=0.5648, divergence=0.0038, diversity=1.1220, num_succ=0, num_remain=36\n",
      " 700-th evaluation: score=0.5652, divergence=0.0041, diversity=1.1222, num_succ=0, num_remain=32\n",
      " 800-th evaluation: score=0.5655, divergence=0.0043, diversity=1.1224, num_succ=0, num_remain=36\n",
      " 900-th evaluation: score=0.5658, divergence=0.0046, diversity=1.1225, num_succ=0, num_remain=31\n",
      "evaluating inputs\n",
      "parent_sim: 0.0392 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.4779 gap=0.4388 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.5118 gap=0.4727 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.4815 gap=0.4423 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.4644 gap=0.4252 train(resnet18,Flower102)-\n",
      "ref_sim: 0.3170 gap=0.2779 train(resnet18,SDog120)-\n",
      "ref_sim: 0.2766 gap=0.2375 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.4264 gap=0.3872 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.3270 gap=0.2878 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.1664 gap=0.1273 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.3248 gap=0.2856 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.4016 gap=0.3624 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.3873 gap=0.3482 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.3511 gap=0.3119 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4072 gap=0.3680 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3273 gap=0.2882 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.3152 gap=0.2760 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.3836 gap=0.3445 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2950 gap=0.2558 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.2764 gap=0.2372 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.3073 gap=0.2681 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.3973 gap=0.3582 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.3228 gap=0.2836 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.3233 gap=0.2841 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.4520 gap=0.4129 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.4734 gap=0.4343 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.1949 gap=0.1558 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.4735 gap=0.4344 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.3625 gap=0.3233 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.3066 gap=0.2674 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.2955 gap=0.2563 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.3042 gap=0.2651 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.4301 gap=0.3909 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.2563 gap=0.2172 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.1681 gap=0.1289 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.1838 gap=0.1446 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.5578 gap=0.5186 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4697 gap=0.4305 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.3994 gap=0.3603 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.4079 gap=0.3688 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5190 gap=0.4799 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3610 gap=0.3219 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.5569 gap=0.5178 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4576 gap=0.4184 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.5549 gap=0.5158 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.4271 gap=0.3879 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.3778 gap=0.3386 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6306 gap=0.5914 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.4634 gap=0.4242 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.5809 gap=0.5417 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.6271 gap=0.5880 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.5333 gap=0.4942 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.3855 gap=0.3463 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.6214 gap=0.5823 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.4479 gap=0.4087 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.4764 gap=0.4372 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.4406 gap=0.4015 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3317 gap=0.2925 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.3329 gap=0.2937 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.3405 gap=0.3014 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.5622 gap=0.5231 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.3997 gap=0.3606 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.5732 gap=0.5341 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.3296 gap=0.2904 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.6812 gap=0.6421 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.5873 gap=0.5482 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5661 gap=0.5269 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5057 gap=0.4665 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.4246 gap=0.3854 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.6266 gap=0.5874 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5568 gap=0.5177 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.3458 gap=0.3067 train(resnet18,SDog120)-steal(resnet18)-\n",
      "52\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "initial_evaluation: score=0.5343, divergence=0.0000, diversity=1.0685, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.5350, divergence=0.0007, diversity=1.0685, num_succ=0, num_remain=81\n",
      " 100-th evaluation: score=0.5365, divergence=0.0021, diversity=1.0690, num_succ=1, num_remain=39\n",
      " 200-th evaluation: score=0.5373, divergence=0.0026, diversity=1.0693, num_succ=1, num_remain=32\n",
      " 300-th evaluation: score=0.5376, divergence=0.0029, diversity=1.0694, num_succ=1, num_remain=29\n",
      " 400-th evaluation: score=0.5382, divergence=0.0034, diversity=1.0697, num_succ=1, num_remain=31\n",
      " 500-th evaluation: score=0.5386, divergence=0.0037, diversity=1.0699, num_succ=1, num_remain=27\n",
      " 600-th evaluation: score=0.5390, divergence=0.0040, diversity=1.0700, num_succ=1, num_remain=34\n",
      " 700-th evaluation: score=0.5394, divergence=0.0043, diversity=1.0702, num_succ=1, num_remain=27\n",
      " 800-th evaluation: score=0.5398, divergence=0.0046, diversity=1.0704, num_succ=1, num_remain=27\n",
      " 900-th evaluation: score=0.5402, divergence=0.0050, diversity=1.0705, num_succ=1, num_remain=28\n",
      "evaluating inputs\n",
      "parent_sim: 0.0354 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.1606 gap=0.1252 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.5432 gap=0.5078 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.3607 gap=0.3253 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.7343 gap=0.6989 train(resnet18,Flower102)-\n",
      "ref_sim: 0.4128 gap=0.3774 train(resnet18,SDog120)-\n",
      "ref_sim: 0.1018 gap=0.0664 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.1450 gap=0.1096 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.2434 gap=0.2080 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.2522 gap=0.2168 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.3107 gap=0.2753 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.3628 gap=0.3274 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.1563 gap=0.1209 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.1920 gap=0.1566 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.3653 gap=0.3299 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.1596 gap=0.1242 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.1570 gap=0.1216 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.3282 gap=0.2928 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2251 gap=0.1897 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.2678 gap=0.2324 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.3769 gap=0.3415 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.1684 gap=0.1330 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.2881 gap=0.2527 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.2641 gap=0.2287 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3423 gap=0.3069 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2980 gap=0.2626 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.2598 gap=0.2244 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.3925 gap=0.3571 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.3603 gap=0.3249 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.1731 gap=0.1377 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.2175 gap=0.1821 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.3262 gap=0.2908 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.5180 gap=0.4826 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.4932 gap=0.4578 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.3336 gap=0.2982 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.6253 gap=0.5899 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.6431 gap=0.6077 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3599 gap=0.3245 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.6741 gap=0.6387 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.7876 gap=0.7522 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5452 gap=0.5098 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5403 gap=0.5049 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.2236 gap=0.1882 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5057 gap=0.4703 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.4527 gap=0.4173 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.4688 gap=0.4334 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.6170 gap=0.5816 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8641 gap=0.8287 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.5411 gap=0.5057 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.5038 gap=0.4684 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.6114 gap=0.5760 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.2852 gap=0.2497 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4392 gap=0.4038 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4277 gap=0.3923 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.7524 gap=0.7170 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.7443 gap=0.7089 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.7673 gap=0.7319 train(resnet18,Flower102)-prune(0.8)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.4121 gap=0.3767 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4712 gap=0.4358 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4832 gap=0.4478 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.6263 gap=0.5909 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.6768 gap=0.6414 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.8094 gap=0.7740 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.6562 gap=0.6208 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.6611 gap=0.6256 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.7769 gap=0.7415 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6497 gap=0.6143 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5238 gap=0.4884 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.6004 gap=0.5650 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.7629 gap=0.7275 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5490 gap=0.5136 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.8220 gap=0.7866 train(resnet18,SDog120)-steal(resnet18)-\n",
      "53\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "initial_evaluation: score=0.3584, divergence=0.0000, diversity=0.7168, num_succ=0, num_remain=9\n",
      "   0-th evaluation: score=0.3593, divergence=0.0009, diversity=0.7167, num_succ=0, num_remain=77\n",
      " 100-th evaluation: score=0.3621, divergence=0.0033, diversity=0.7175, num_succ=0, num_remain=43\n",
      " 200-th evaluation: score=0.3633, divergence=0.0043, diversity=0.7181, num_succ=1, num_remain=30\n",
      " 300-th evaluation: score=0.3644, divergence=0.0052, diversity=0.7185, num_succ=1, num_remain=30\n",
      " 400-th evaluation: score=0.3655, divergence=0.0059, diversity=0.7191, num_succ=1, num_remain=33\n",
      " 500-th evaluation: score=0.3667, divergence=0.0069, diversity=0.7197, num_succ=1, num_remain=38\n",
      " 600-th evaluation: score=0.3677, divergence=0.0076, diversity=0.7203, num_succ=1, num_remain=32\n",
      " 700-th evaluation: score=0.3686, divergence=0.0083, diversity=0.7206, num_succ=1, num_remain=30\n",
      " 800-th evaluation: score=0.3695, divergence=0.0090, diversity=0.7211, num_succ=1, num_remain=32\n",
      " 900-th evaluation: score=0.3707, divergence=0.0098, diversity=0.7218, num_succ=1, num_remain=46\n",
      "evaluating inputs\n",
      "parent_sim: 0.4342 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.3239 gap=-0.1103 pretrain(resnet18,ImageNet)-\u001b[0m\n",
      "ref_sim: 0.7701 gap=0.3358 train(mbnetv2,Flower102)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2170 gap=-0.2173 train(mbnetv2,SDog120)-\u001b[0m\n",
      "ref_sim: 0.9081 gap=0.4739 train(resnet18,Flower102)-\n",
      "ref_sim: 0.5407 gap=0.1065 train(resnet18,SDog120)-\n",
      "ref_sim: 0.5635 gap=0.1293 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.4865 gap=0.0522 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4128 gap=-0.0214 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3675 gap=-0.0668 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3353 gap=-0.0990 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3782 gap=-0.0560 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\u001b[0m\n",
      "ref_sim: 0.4973 gap=0.0630 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.5052 gap=0.0709 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4001 gap=-0.0342 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.4697 gap=0.0354 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.5076 gap=0.0734 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4592 gap=0.0249 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4327 gap=-0.0015 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\u001b[0m\n",
      "ref_sim: 0.4461 gap=0.0119 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.5571 gap=0.1229 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.3723 gap=-0.0619 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3410 gap=-0.0932 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\u001b[0m\n",
      "ref_sim: 0.6707 gap=0.2364 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.3244 gap=-0.1098 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3624 gap=-0.0718 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\u001b[0m\n",
      "ref_sim: 0.5936 gap=0.1594 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2858 gap=-0.1484 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3150 gap=-0.1193 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4129 gap=-0.0214 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.5516 gap=0.1174 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.4958 gap=0.0616 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.6119 gap=0.1777 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.4970 gap=0.0628 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4258 gap=-0.0084 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\u001b[0m\n",
      "ref_sim: 0.5589 gap=0.1247 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.6668 gap=0.2326 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5419 gap=0.1077 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.8090 gap=0.3747 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.8733 gap=0.4391 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.8129 gap=0.3787 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.7998 gap=0.3655 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.7342 gap=0.3000 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.3707 gap=-0.0635 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3299 gap=-0.1044 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\u001b[0m\n",
      "ref_sim: 0.5066 gap=0.0724 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.6003 gap=0.1660 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4875 gap=0.0533 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.7799 gap=0.3456 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.7245 gap=0.2903 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.6718 gap=0.2375 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2025 gap=-0.2317 train(mbnetv2,SDog120)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2190 gap=-0.2153 train(mbnetv2,SDog120)-prune(0.5)-\u001b[0m\n",
      "ref_sim: 0.5392 gap=0.1049 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8854 gap=0.4511 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8828 gap=0.4485 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.8752 gap=0.4410 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.5647 gap=0.1304 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.5579 gap=0.1236 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4788 gap=0.0446 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8365 gap=0.4023 train(mbnetv2,Flower102)-distill()-\n",
      "\u001b[93m[ERROR] ref_sim: 0.3058 gap=-0.1285 train(mbnetv2,SDog120)-distill()-\u001b[0m\n",
      "ref_sim: 0.9098 gap=0.4756 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.6503 gap=0.2160 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.8617 gap=0.4274 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.9485 gap=0.5142 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6630 gap=0.2288 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4143 gap=-0.0199 train(mbnetv2,SDog120)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.9207 gap=0.4864 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.9158 gap=0.4816 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.4438 gap=0.0095 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5121 gap=0.0779 train(resnet18,SDog120)-steal(resnet18)-\n",
      "54\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_evaluation: score=0.6026, divergence=0.0000, diversity=1.2052, num_succ=0, num_remain=7\n",
      "   0-th evaluation: score=0.6029, divergence=0.0003, diversity=1.2052, num_succ=0, num_remain=90\n",
      " 100-th evaluation: score=0.6036, divergence=0.0010, diversity=1.2053, num_succ=0, num_remain=45\n",
      " 200-th evaluation: score=0.6039, divergence=0.0011, diversity=1.2055, num_succ=0, num_remain=40\n",
      " 300-th evaluation: score=0.6041, divergence=0.0013, diversity=1.2055, num_succ=0, num_remain=35\n",
      " 400-th evaluation: score=0.6043, divergence=0.0015, diversity=1.2056, num_succ=0, num_remain=29\n",
      " 500-th evaluation: score=0.6045, divergence=0.0016, diversity=1.2057, num_succ=0, num_remain=27\n",
      " 600-th evaluation: score=0.6047, divergence=0.0019, diversity=1.2058, num_succ=0, num_remain=29\n",
      " 700-th evaluation: score=0.6049, divergence=0.0020, diversity=1.2058, num_succ=0, num_remain=26\n",
      " 800-th evaluation: score=0.6051, divergence=0.0022, diversity=1.2059, num_succ=0, num_remain=28\n",
      " 900-th evaluation: score=0.6053, divergence=0.0024, diversity=1.2060, num_succ=0, num_remain=28\n",
      "evaluating inputs\n",
      "parent_sim: 0.1184 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.1835 gap=0.0651 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.6292 gap=0.5108 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.2850 gap=0.1666 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.4308 gap=0.3124 train(resnet18,Flower102)-\n",
      "ref_sim: 0.2409 gap=0.1225 train(resnet18,SDog120)-\n",
      "ref_sim: 0.3566 gap=0.2382 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.5028 gap=0.3844 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.3789 gap=0.2605 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.4409 gap=0.3225 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.3898 gap=0.2714 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.2889 gap=0.1705 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.3763 gap=0.2579 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.4165 gap=0.2981 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.3856 gap=0.2672 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.4587 gap=0.3403 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.4828 gap=0.3644 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.3947 gap=0.2763 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.4255 gap=0.3071 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.4144 gap=0.2959 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.4928 gap=0.3744 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.2234 gap=0.1050 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.4130 gap=0.2946 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4314 gap=0.3130 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3249 gap=0.2064 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.3894 gap=0.2710 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.5110 gap=0.3925 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2540 gap=0.1356 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.3029 gap=0.1845 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.4183 gap=0.2999 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.4639 gap=0.3455 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.2340 gap=0.1156 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.3437 gap=0.2252 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.4782 gap=0.3598 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.5256 gap=0.4071 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.4109 gap=0.2925 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.4363 gap=0.3178 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4692 gap=0.3508 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.3970 gap=0.2786 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.1600 gap=0.0416 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5193 gap=0.4009 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.1731 gap=0.0547 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.6373 gap=0.5189 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3988 gap=0.2803 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.6671 gap=0.5487 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.3624 gap=0.2440 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.7721 gap=0.6537 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3878 gap=0.2693 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.5420 gap=0.4236 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.4057 gap=0.2873 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.5451 gap=0.4267 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3076 gap=0.1892 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4484 gap=0.3300 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.7859 gap=0.6675 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.3989 gap=0.2805 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.3550 gap=0.2366 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.5652 gap=0.4468 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.2693 gap=0.1509 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.2665 gap=0.1481 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.3476 gap=0.2292 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.2581 gap=0.1397 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.6027 gap=0.4843 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.3995 gap=0.2810 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.6202 gap=0.5018 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.5356 gap=0.4172 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.3841 gap=0.2657 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.8797 gap=0.7612 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6767 gap=0.5583 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.3572 gap=0.2388 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.4738 gap=0.3554 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.8417 gap=0.7233 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6929 gap=0.5745 train(resnet18,SDog120)-steal(resnet18)-\n",
      "55\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "initial_evaluation: score=0.5747, divergence=0.0000, diversity=1.1495, num_succ=0, num_remain=9\n",
      "   0-th evaluation: score=0.5752, divergence=0.0006, diversity=1.1492, num_succ=0, num_remain=86\n",
      " 100-th evaluation: score=0.5765, divergence=0.0017, diversity=1.1494, num_succ=0, num_remain=47\n",
      " 200-th evaluation: score=0.5768, divergence=0.0021, diversity=1.1495, num_succ=0, num_remain=36\n",
      " 300-th evaluation: score=0.5771, divergence=0.0023, diversity=1.1497, num_succ=0, num_remain=35\n",
      " 400-th evaluation: score=0.5775, divergence=0.0026, diversity=1.1498, num_succ=0, num_remain=35\n",
      " 500-th evaluation: score=0.5779, divergence=0.0029, diversity=1.1500, num_succ=0, num_remain=35\n",
      " 600-th evaluation: score=0.5783, divergence=0.0032, diversity=1.1502, num_succ=0, num_remain=40\n",
      " 700-th evaluation: score=0.5786, divergence=0.0034, diversity=1.1504, num_succ=0, num_remain=33\n",
      " 800-th evaluation: score=0.5790, divergence=0.0037, diversity=1.1506, num_succ=0, num_remain=38\n",
      " 900-th evaluation: score=0.5794, divergence=0.0040, diversity=1.1507, num_succ=0, num_remain=39\n",
      "evaluating inputs\n",
      "parent_sim: 0.0918 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.1507 gap=0.0589 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.2801 gap=0.1883 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.5195 gap=0.4277 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.6981 gap=0.6063 train(resnet18,Flower102)-\n",
      "ref_sim: 0.6640 gap=0.5722 train(resnet18,SDog120)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.2066 gap=0.1148 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.2196 gap=0.1278 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.2045 gap=0.1127 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.2848 gap=0.1930 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.2548 gap=0.1630 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.1760 gap=0.0842 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.1619 gap=0.0701 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.1625 gap=0.0706 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.2070 gap=0.1152 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.2594 gap=0.1676 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2391 gap=0.1473 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.2559 gap=0.1641 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.1827 gap=0.0909 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.1722 gap=0.0803 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.2720 gap=0.1802 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.2100 gap=0.1182 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.2001 gap=0.1083 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.1372 gap=0.0454 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.1171 gap=0.0253 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.1196 gap=0.0278 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.1682 gap=0.0764 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.1231 gap=0.0313 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.1458 gap=0.0540 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.1506 gap=0.0588 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.2027 gap=0.1109 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.3309 gap=0.2391 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.4404 gap=0.3486 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.4944 gap=0.4026 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.2719 gap=0.1801 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.2913 gap=0.1995 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.4117 gap=0.3199 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4344 gap=0.3426 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.6457 gap=0.5538 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.6421 gap=0.5502 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5531 gap=0.4613 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6716 gap=0.5797 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.3197 gap=0.2278 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.2628 gap=0.1710 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.2947 gap=0.2029 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.5042 gap=0.4124 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5503 gap=0.4585 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4246 gap=0.3328 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.3011 gap=0.2093 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.3776 gap=0.2858 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.4975 gap=0.4056 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.4395 gap=0.3477 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4230 gap=0.3312 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4050 gap=0.3131 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.7218 gap=0.6300 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.7347 gap=0.6429 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.7137 gap=0.6219 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.6972 gap=0.6054 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.6247 gap=0.5329 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.6378 gap=0.5460 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.2771 gap=0.1853 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.5150 gap=0.4231 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.6581 gap=0.5662 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.7212 gap=0.6294 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.5767 gap=0.4849 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.6453 gap=0.5535 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5446 gap=0.4528 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6369 gap=0.5451 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.6556 gap=0.5638 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.6289 gap=0.5371 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.8657 gap=0.7739 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5465 gap=0.4547 train(resnet18,SDog120)-steal(resnet18)-\n",
      "56\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "initial_evaluation: score=0.3493, divergence=0.0000, diversity=0.6987, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.3502, divergence=0.0010, diversity=0.6985, num_succ=1, num_remain=87\n",
      " 100-th evaluation: score=0.3539, divergence=0.0044, diversity=0.6991, num_succ=1, num_remain=57\n",
      " 200-th evaluation: score=0.3558, divergence=0.0059, diversity=0.6999, num_succ=1, num_remain=55\n",
      " 300-th evaluation: score=0.3577, divergence=0.0074, diversity=0.7006, num_succ=1, num_remain=53\n",
      " 400-th evaluation: score=0.3597, divergence=0.0091, diversity=0.7013, num_succ=1, num_remain=63\n",
      " 500-th evaluation: score=0.3616, divergence=0.0107, diversity=0.7019, num_succ=1, num_remain=49\n",
      " 600-th evaluation: score=0.3632, divergence=0.0119, diversity=0.7025, num_succ=1, num_remain=56\n",
      " 700-th evaluation: score=0.3646, divergence=0.0131, diversity=0.7029, num_succ=2, num_remain=60\n",
      " 800-th evaluation: score=0.3660, divergence=0.0144, diversity=0.7032, num_succ=2, num_remain=50\n",
      " 900-th evaluation: score=0.3678, divergence=0.0160, diversity=0.7038, num_succ=2, num_remain=65\n",
      "evaluating inputs\n",
      "parent_sim: 0.5995 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4272 gap=-0.1723 pretrain(resnet18,ImageNet)-\u001b[0m\n",
      "ref_sim: 0.7325 gap=0.1330 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.7881 gap=0.1886 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.9674 gap=0.3680 train(resnet18,Flower102)-\n",
      "ref_sim: 0.7384 gap=0.1390 train(resnet18,SDog120)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4269 gap=-0.1726 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\u001b[0m\n",
      "ref_sim: 0.6224 gap=0.0229 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.7598 gap=0.1603 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1007 gap=-0.4988 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3037 gap=-0.2958 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3908 gap=-0.2087 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\u001b[0m\n",
      "ref_sim: 0.7654 gap=0.1660 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.7399 gap=0.1404 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.7513 gap=0.1519 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.7562 gap=0.1567 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.7389 gap=0.1394 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.7466 gap=0.1471 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.7655 gap=0.1660 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.7529 gap=0.1534 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.8160 gap=0.2166 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.5091 gap=-0.0904 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m[ERROR] ref_sim: 0.3389 gap=-0.2606 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5017 gap=-0.0977 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4976 gap=-0.1019 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4410 gap=-0.1585 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5397 gap=-0.0598 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4649 gap=-0.1345 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3846 gap=-0.2149 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5127 gap=-0.0867 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.6930 gap=0.0935 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.7442 gap=0.1448 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.7890 gap=0.1895 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2386 gap=-0.3608 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3425 gap=-0.2570 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4387 gap=-0.1607 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\u001b[0m\n",
      "ref_sim: 0.6720 gap=0.0725 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8668 gap=0.2673 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.7788 gap=0.1793 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.9069 gap=0.3075 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.6995 gap=0.1000 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8706 gap=0.2711 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0143 gap=-0.5852 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1392 gap=-0.4603 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.6513 gap=0.0519 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4156 gap=-0.1839 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5195 gap=-0.0799 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2479 gap=-0.3516 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.8125 gap=0.2131 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.7015 gap=0.1020 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.6712 gap=0.0718 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.5477 gap=-0.0518 train(mbnetv2,SDog120)-prune(0.2)-\u001b[0m\n",
      "ref_sim: 0.7898 gap=0.1903 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4068 gap=-0.1927 train(mbnetv2,SDog120)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.9667 gap=0.3672 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.9674 gap=0.3679 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.9760 gap=0.3766 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.7422 gap=0.1427 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.8153 gap=0.2158 train(resnet18,SDog120)-prune(0.5)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.5590 gap=-0.0405 train(resnet18,SDog120)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.7924 gap=0.1929 train(mbnetv2,Flower102)-distill()-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1864 gap=-0.4131 train(mbnetv2,SDog120)-distill()-\u001b[0m\n",
      "ref_sim: 0.9619 gap=0.3624 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.6505 gap=0.0510 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.9130 gap=0.3135 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.9575 gap=0.3580 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.5364 gap=-0.0630 train(mbnetv2,SDog120)-steal(mbnetv2)-\u001b[0m\n",
      "ref_sim: 0.7427 gap=0.1432 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.8632 gap=0.2637 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.9512 gap=0.3517 train(resnet18,Flower102)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0234 gap=-0.5761 train(resnet18,SDog120)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3114 gap=-0.2881 train(resnet18,SDog120)-steal(resnet18)-\u001b[0m\n",
      "57\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "initial_evaluation: score=0.6133, divergence=0.0000, diversity=1.2266, num_succ=0, num_remain=7\n",
      "   0-th evaluation: score=0.6138, divergence=0.0007, diversity=1.2263, num_succ=0, num_remain=90\n",
      " 100-th evaluation: score=0.6148, divergence=0.0015, diversity=1.2266, num_succ=0, num_remain=58\n",
      " 200-th evaluation: score=0.6152, divergence=0.0018, diversity=1.2268, num_succ=0, num_remain=46\n",
      " 300-th evaluation: score=0.6155, divergence=0.0021, diversity=1.2269, num_succ=0, num_remain=47\n",
      " 400-th evaluation: score=0.6159, divergence=0.0023, diversity=1.2271, num_succ=0, num_remain=42\n",
      " 500-th evaluation: score=0.6160, divergence=0.0025, diversity=1.2271, num_succ=0, num_remain=37\n",
      " 600-th evaluation: score=0.6163, divergence=0.0026, diversity=1.2272, num_succ=0, num_remain=35\n",
      " 700-th evaluation: score=0.6165, divergence=0.0028, diversity=1.2273, num_succ=0, num_remain=32\n",
      " 800-th evaluation: score=0.6166, divergence=0.0029, diversity=1.2274, num_succ=0, num_remain=35\n",
      " 900-th evaluation: score=0.6168, divergence=0.0031, diversity=1.2275, num_succ=0, num_remain=40\n",
      "evaluating inputs\n",
      "parent_sim: 0.0921 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.2416 gap=0.1495 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.4376 gap=0.3455 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.4482 gap=0.3561 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.6816 gap=0.5895 train(resnet18,Flower102)-\n",
      "ref_sim: 0.8016 gap=0.7095 train(resnet18,SDog120)-\n",
      "ref_sim: 0.4128 gap=0.3207 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.5510 gap=0.4589 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.5390 gap=0.4469 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.1776 gap=0.0856 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.3612 gap=0.2691 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.3032 gap=0.2111 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.4950 gap=0.4029 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.5305 gap=0.4384 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4798 gap=0.3877 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.4791 gap=0.3870 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.5055 gap=0.4134 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.3967 gap=0.3046 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.5301 gap=0.4380 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.5179 gap=0.4258 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.3909 gap=0.2988 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.2816 gap=0.1895 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.1221 gap=0.0300 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.2465 gap=0.1545 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.4281 gap=0.3360 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.3623 gap=0.2702 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.2463 gap=0.1542 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2818 gap=0.1898 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.3915 gap=0.2994 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.1626 gap=0.0705 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.5461 gap=0.4540 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.4033 gap=0.3112 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.6256 gap=0.5335 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.6141 gap=0.5220 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.6319 gap=0.5398 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.5203 gap=0.4282 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.3842 gap=0.2921 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5256 gap=0.4335 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.4317 gap=0.3396 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.7609 gap=0.6688 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5040 gap=0.4119 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8928 gap=0.8007 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.3852 gap=0.2931 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3402 gap=0.2481 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.7866 gap=0.6945 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.1846 gap=0.0925 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.6173 gap=0.5253 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3667 gap=0.2746 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.4943 gap=0.4022 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.5393 gap=0.4472 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.5423 gap=0.4503 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3708 gap=0.2787 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4612 gap=0.3691 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.5538 gap=0.4617 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.7233 gap=0.6312 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.7181 gap=0.6260 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.7223 gap=0.6302 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.7538 gap=0.6617 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.7642 gap=0.6721 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.7355 gap=0.6434 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.5018 gap=0.4097 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.7548 gap=0.6627 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.7929 gap=0.7008 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.6615 gap=0.5694 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.6200 gap=0.5279 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8662 gap=0.7741 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5041 gap=0.4120 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.4920 gap=0.3999 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.7887 gap=0.6966 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8594 gap=0.7673 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.4640 gap=0.3719 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6918 gap=0.5997 train(resnet18,SDog120)-steal(resnet18)-\n",
      "58\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "initial_evaluation: score=0.5776, divergence=0.0000, diversity=1.1552, num_succ=0, num_remain=9\n",
      "   0-th evaluation: score=0.5785, divergence=0.0007, diversity=1.1556, num_succ=0, num_remain=86\n",
      " 100-th evaluation: score=0.5796, divergence=0.0016, diversity=1.1560, num_succ=0, num_remain=47\n",
      " 200-th evaluation: score=0.5800, divergence=0.0019, diversity=1.1561, num_succ=0, num_remain=39\n",
      " 300-th evaluation: score=0.5802, divergence=0.0021, diversity=1.1563, num_succ=0, num_remain=41\n",
      " 400-th evaluation: score=0.5805, divergence=0.0023, diversity=1.1564, num_succ=0, num_remain=38\n",
      " 500-th evaluation: score=0.5807, divergence=0.0025, diversity=1.1565, num_succ=0, num_remain=37\n",
      " 600-th evaluation: score=0.5810, divergence=0.0027, diversity=1.1566, num_succ=0, num_remain=35\n",
      " 700-th evaluation: score=0.5813, divergence=0.0030, diversity=1.1567, num_succ=0, num_remain=39\n",
      " 800-th evaluation: score=0.5815, divergence=0.0031, diversity=1.1568, num_succ=0, num_remain=33\n",
      " 900-th evaluation: score=0.5817, divergence=0.0033, diversity=1.1569, num_succ=0, num_remain=32\n",
      "evaluating inputs\n",
      "parent_sim: 0.1402 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.2030 gap=0.0628 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.5754 gap=0.4352 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.4068 gap=0.2665 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.9072 gap=0.7670 train(resnet18,Flower102)-\n",
      "ref_sim: 0.6012 gap=0.4609 train(resnet18,SDog120)-\n",
      "ref_sim: 0.1797 gap=0.0394 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.2295 gap=0.0893 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.2729 gap=0.1327 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1302 gap=-0.0100 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\u001b[0m\n",
      "ref_sim: 0.2561 gap=0.1158 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.5269 gap=0.3867 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.2984 gap=0.1582 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.2788 gap=0.1386 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.3695 gap=0.2292 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.2821 gap=0.1418 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2821 gap=0.1419 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.3677 gap=0.2275 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2768 gap=0.1366 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.2328 gap=0.0926 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.3403 gap=0.2000 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.3849 gap=0.2446 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.1657 gap=0.0255 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4946 gap=0.3543 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.2955 gap=0.1553 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.4196 gap=0.2793 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4276 gap=0.2874 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.4458 gap=0.3055 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.4568 gap=0.3165 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.6277 gap=0.4874 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.2490 gap=0.1087 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.2937 gap=0.1535 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.3358 gap=0.1956 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.4447 gap=0.3045 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.5876 gap=0.4474 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.2873 gap=0.1470 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.3000 gap=0.1598 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4786 gap=0.3383 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.6505 gap=0.5102 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.8420 gap=0.7018 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5007 gap=0.3604 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8459 gap=0.7057 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.7719 gap=0.6316 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5687 gap=0.4284 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.4603 gap=0.3201 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.5902 gap=0.4499 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.7906 gap=0.6503 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5740 gap=0.4337 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.5720 gap=0.4318 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.6704 gap=0.5302 train(mbnetv2,Flower102)-prune(0.5)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.6316 gap=0.4913 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.4818 gap=0.3416 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4977 gap=0.3575 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.3755 gap=0.2352 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.9103 gap=0.7701 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.9155 gap=0.7753 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.9154 gap=0.7752 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.6246 gap=0.4844 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.6337 gap=0.4935 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.5931 gap=0.4528 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.5703 gap=0.4301 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.3250 gap=0.1848 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.9309 gap=0.7906 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.6434 gap=0.5032 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.7335 gap=0.5933 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.9402 gap=0.8000 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5982 gap=0.4580 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6714 gap=0.5312 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.4708 gap=0.3306 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.9432 gap=0.8030 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.7129 gap=0.5727 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6979 gap=0.5576 train(resnet18,SDog120)-steal(resnet18)-\n",
      "59\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "initial_evaluation: score=0.3538, divergence=0.0000, diversity=0.7076, num_succ=0, num_remain=9\n",
      "   0-th evaluation: score=0.3543, divergence=0.0005, diversity=0.7077, num_succ=0, num_remain=76\n",
      " 100-th evaluation: score=0.3569, divergence=0.0027, diversity=0.7084, num_succ=1, num_remain=49\n",
      " 200-th evaluation: score=0.3585, divergence=0.0039, diversity=0.7091, num_succ=1, num_remain=48\n",
      " 300-th evaluation: score=0.3600, divergence=0.0052, diversity=0.7096, num_succ=2, num_remain=44\n",
      " 400-th evaluation: score=0.3614, divergence=0.0063, diversity=0.7101, num_succ=2, num_remain=43\n",
      " 500-th evaluation: score=0.3630, divergence=0.0076, diversity=0.7108, num_succ=3, num_remain=47\n",
      " 600-th evaluation: score=0.3644, divergence=0.0086, diversity=0.7115, num_succ=3, num_remain=44\n",
      " 700-th evaluation: score=0.3664, divergence=0.0101, diversity=0.7125, num_succ=3, num_remain=49\n",
      " 800-th evaluation: score=0.3682, divergence=0.0115, diversity=0.7133, num_succ=3, num_remain=47\n",
      " 900-th evaluation: score=0.3695, divergence=0.0126, diversity=0.7139, num_succ=3, num_remain=44\n",
      "evaluating inputs\n",
      "parent_sim: 0.2155 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.3906 gap=0.1751 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.3211 gap=0.1056 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.3547 gap=0.1392 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.8876 gap=0.6721 train(resnet18,Flower102)-\n",
      "ref_sim: 0.4205 gap=0.2050 train(resnet18,SDog120)-\n",
      "ref_sim: 0.3575 gap=0.1420 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.5347 gap=0.3193 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.5120 gap=0.2966 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.3059 gap=0.0905 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.3495 gap=0.1340 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.3197 gap=0.1042 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.5285 gap=0.3131 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.5202 gap=0.3047 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.5762 gap=0.3607 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.5506 gap=0.3351 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.5049 gap=0.2894 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4025 gap=0.1870 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.5533 gap=0.3378 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.3983 gap=0.1829 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.4218 gap=0.2063 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.3630 gap=0.1476 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.3591 gap=0.1437 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4179 gap=0.2024 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.2954 gap=0.0800 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.3148 gap=0.0993 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.2207 gap=0.0053 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2986 gap=0.0831 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.3499 gap=0.1344 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.3449 gap=0.1294 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.2838 gap=0.0683 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.5052 gap=0.2897 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.5685 gap=0.3531 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.2260 gap=0.0105 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.3150 gap=0.0996 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.4888 gap=0.2733 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.5142 gap=0.2988 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5749 gap=0.3595 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.5128 gap=0.2973 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.7682 gap=0.5527 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.3738 gap=0.1584 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8217 gap=0.6062 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.4411 gap=0.2256 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3670 gap=0.1515 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.2722 gap=0.0567 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.4305 gap=0.2150 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.4990 gap=0.2836 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3568 gap=0.1413 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.2769 gap=0.0615 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.3477 gap=0.1322 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.3691 gap=0.1536 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3942 gap=0.1787 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.2368 gap=0.0213 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.3254 gap=0.1099 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8866 gap=0.6712 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8852 gap=0.6697 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.7837 gap=0.5682 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3980 gap=0.1826 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.3621 gap=0.1466 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4403 gap=0.2248 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.3250 gap=0.1096 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.5074 gap=0.2919 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.8506 gap=0.6351 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.4702 gap=0.2547 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.6200 gap=0.4045 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.9034 gap=0.6880 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.4032 gap=0.1877 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1485 gap=-0.0670 train(mbnetv2,SDog120)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.5802 gap=0.3648 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8678 gap=0.6524 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.4846 gap=0.2691 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.2993 gap=0.0839 train(resnet18,SDog120)-steal(resnet18)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\t generating inputs for pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "initial_evaluation: score=0.6660, divergence=0.0000, diversity=1.3320, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6661, divergence=0.0002, diversity=1.3318, num_succ=0, num_remain=90\n",
      " 100-th evaluation: score=0.6664, divergence=0.0004, diversity=1.3319, num_succ=0, num_remain=63\n",
      " 200-th evaluation: score=0.6665, divergence=0.0005, diversity=1.3320, num_succ=0, num_remain=53\n",
      " 300-th evaluation: score=0.6666, divergence=0.0006, diversity=1.3320, num_succ=0, num_remain=51\n",
      " 400-th evaluation: score=0.6667, divergence=0.0007, diversity=1.3320, num_succ=0, num_remain=55\n",
      " 500-th evaluation: score=0.6668, divergence=0.0007, diversity=1.3321, num_succ=0, num_remain=54\n",
      " 600-th evaluation: score=0.6669, divergence=0.0008, diversity=1.3321, num_succ=0, num_remain=52\n",
      " 700-th evaluation: score=0.6669, divergence=0.0009, diversity=1.3321, num_succ=0, num_remain=50\n",
      " 800-th evaluation: score=0.6670, divergence=0.0009, diversity=1.3322, num_succ=0, num_remain=48\n",
      " 900-th evaluation: score=0.6671, divergence=0.0010, diversity=1.3322, num_succ=0, num_remain=46\n",
      "evaluating inputs\n",
      "parent_sim: 0.0964 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.3385 gap=0.2420 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.1038 gap=0.0074 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.3732 gap=0.2768 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.2452 gap=0.1487 train(resnet18,Flower102)-\n",
      "ref_sim: 0.4567 gap=0.3603 train(resnet18,SDog120)-\n",
      "ref_sim: 0.3610 gap=0.2645 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.4488 gap=0.3523 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.4425 gap=0.3461 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.2759 gap=0.1795 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.3731 gap=0.2767 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.3633 gap=0.2668 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.4352 gap=0.3388 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.4400 gap=0.3436 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4054 gap=0.3090 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.4298 gap=0.3334 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.3386 gap=0.2422 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.3071 gap=0.2107 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.4395 gap=0.3431 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.4017 gap=0.3053 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.3947 gap=0.2983 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.2640 gap=0.1675 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.2514 gap=0.1550 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4957 gap=0.3993 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.2166 gap=0.1202 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.4070 gap=0.3105 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.5483 gap=0.4519 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2418 gap=0.1454 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.3470 gap=0.2506 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.4919 gap=0.3955 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.5744 gap=0.4780 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.1776 gap=0.0812 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.6153 gap=0.5189 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.6878 gap=0.5913 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.5879 gap=0.4915 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.4060 gap=0.3096 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.5271 gap=0.4307 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5341 gap=0.4377 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.6044 gap=0.5080 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.5737 gap=0.4773 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.4146 gap=0.3182 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5106 gap=0.4142 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.8020 gap=0.7056 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5398 gap=0.4434 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.7843 gap=0.6879 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.6699 gap=0.5735 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.4740 gap=0.3776 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6594 gap=0.5630 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.1186 gap=0.0221 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.1162 gap=0.0198 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.1767 gap=0.0803 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.5193 gap=0.4229 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4573 gap=0.3608 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.6080 gap=0.5115 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.2612 gap=0.1648 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.3091 gap=0.2127 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.2718 gap=0.1754 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3277 gap=0.2313 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.3407 gap=0.2443 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.2997 gap=0.2032 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.1444 gap=0.0479 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.5764 gap=0.4800 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.4832 gap=0.3868 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.4731 gap=0.3766 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.5521 gap=0.4557 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.6365 gap=0.5401 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5937 gap=0.4973 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5141 gap=0.4177 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.4745 gap=0.3781 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.5331 gap=0.4367 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.7420 gap=0.6456 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.7557 gap=0.6593 train(resnet18,SDog120)-steal(resnet18)-\n",
      "61\t generating inputs for pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "initial_evaluation: score=0.6648, divergence=0.0000, diversity=1.3295, num_succ=0, num_remain=9\n",
      "   0-th evaluation: score=0.6648, divergence=0.0001, diversity=1.3294, num_succ=0, num_remain=88\n",
      " 100-th evaluation: score=0.6650, divergence=0.0003, diversity=1.3295, num_succ=0, num_remain=52\n",
      " 200-th evaluation: score=0.6652, divergence=0.0004, diversity=1.3296, num_succ=0, num_remain=49\n",
      " 300-th evaluation: score=0.6653, divergence=0.0004, diversity=1.3297, num_succ=0, num_remain=48\n",
      " 400-th evaluation: score=0.6654, divergence=0.0005, diversity=1.3298, num_succ=0, num_remain=41\n",
      " 500-th evaluation: score=0.6655, divergence=0.0006, diversity=1.3298, num_succ=0, num_remain=45\n",
      " 600-th evaluation: score=0.6655, divergence=0.0006, diversity=1.3299, num_succ=0, num_remain=44\n",
      " 700-th evaluation: score=0.6656, divergence=0.0007, diversity=1.3299, num_succ=0, num_remain=53\n",
      " 800-th evaluation: score=0.6657, divergence=0.0007, diversity=1.3300, num_succ=0, num_remain=52\n",
      " 900-th evaluation: score=0.6658, divergence=0.0008, diversity=1.3301, num_succ=0, num_remain=46\n",
      "evaluating inputs\n",
      "parent_sim: 0.1164 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.2044 gap=0.0880 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.2392 gap=0.1229 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.3584 gap=0.2420 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.5246 gap=0.4083 train(resnet18,Flower102)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.4653 gap=0.3489 train(resnet18,SDog120)-\n",
      "ref_sim: 0.2077 gap=0.0913 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.3917 gap=0.2753 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.3794 gap=0.2630 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.1962 gap=0.0798 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.5529 gap=0.4365 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.5939 gap=0.4776 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.3702 gap=0.2538 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.3644 gap=0.2480 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4399 gap=0.3235 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.4156 gap=0.2992 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.3701 gap=0.2537 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.2603 gap=0.1439 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.3987 gap=0.2823 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.4170 gap=0.3006 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.2134 gap=0.0971 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.2920 gap=0.1756 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.3145 gap=0.1981 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.5404 gap=0.4241 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.2800 gap=0.1636 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2958 gap=0.1794 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4409 gap=0.3245 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.4463 gap=0.3299 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.3250 gap=0.2086 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.4133 gap=0.2969 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.5548 gap=0.4384 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.5582 gap=0.4418 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.4690 gap=0.3526 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.5759 gap=0.4595 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.6446 gap=0.5282 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.5570 gap=0.4406 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.5490 gap=0.4326 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5496 gap=0.4332 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.5140 gap=0.3976 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.5542 gap=0.4378 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5047 gap=0.3883 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5595 gap=0.4431 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.3869 gap=0.2705 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4448 gap=0.3284 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.4282 gap=0.3118 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.3729 gap=0.2565 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.4752 gap=0.3588 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4492 gap=0.3328 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.2626 gap=0.1462 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.2205 gap=0.1041 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.2287 gap=0.1123 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3875 gap=0.2711 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.3695 gap=0.2531 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4150 gap=0.2987 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.5222 gap=0.4058 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.5252 gap=0.4088 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.5234 gap=0.4070 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.4528 gap=0.3364 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4390 gap=0.3227 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4584 gap=0.3421 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.2894 gap=0.1730 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.4684 gap=0.3520 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.5713 gap=0.4549 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.4834 gap=0.3670 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.5449 gap=0.4286 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.5478 gap=0.4314 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.4600 gap=0.3436 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.4789 gap=0.3625 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.5390 gap=0.4226 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.5534 gap=0.4370 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5044 gap=0.3880 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5122 gap=0.3958 train(resnet18,SDog120)-steal(resnet18)-\n",
      "62\t generating inputs for pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "initial_evaluation: score=0.6560, divergence=0.0000, diversity=1.3121, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6561, divergence=0.0001, diversity=1.3120, num_succ=0, num_remain=80\n",
      " 100-th evaluation: score=0.6563, divergence=0.0003, diversity=1.3121, num_succ=0, num_remain=47\n",
      " 200-th evaluation: score=0.6564, divergence=0.0003, diversity=1.3121, num_succ=0, num_remain=40\n",
      " 300-th evaluation: score=0.6565, divergence=0.0004, diversity=1.3122, num_succ=0, num_remain=38\n",
      " 400-th evaluation: score=0.6565, divergence=0.0004, diversity=1.3122, num_succ=0, num_remain=32\n",
      " 500-th evaluation: score=0.6566, divergence=0.0005, diversity=1.3122, num_succ=0, num_remain=45\n",
      " 600-th evaluation: score=0.6567, divergence=0.0005, diversity=1.3123, num_succ=0, num_remain=36\n",
      " 700-th evaluation: score=0.6567, divergence=0.0006, diversity=1.3123, num_succ=0, num_remain=35\n",
      " 800-th evaluation: score=0.6568, divergence=0.0006, diversity=1.3124, num_succ=0, num_remain=36\n",
      " 900-th evaluation: score=0.6568, divergence=0.0007, diversity=1.3124, num_succ=0, num_remain=32\n",
      "evaluating inputs\n",
      "parent_sim: 0.1364 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.2620 gap=0.1256 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.4034 gap=0.2669 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.2760 gap=0.1396 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.6273 gap=0.4909 train(resnet18,Flower102)-\n",
      "ref_sim: 0.3658 gap=0.2293 train(resnet18,SDog120)-\n",
      "ref_sim: 0.2996 gap=0.1632 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.2112 gap=0.0748 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.2428 gap=0.1064 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.2140 gap=0.0776 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.3275 gap=0.1911 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.3999 gap=0.2635 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.3218 gap=0.1853 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.3634 gap=0.2270 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.3213 gap=0.1849 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.2878 gap=0.1513 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2905 gap=0.1541 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.3394 gap=0.2029 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2458 gap=0.1094 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.3735 gap=0.2371 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.2650 gap=0.1286 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.3651 gap=0.2286 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.2903 gap=0.1539 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.3743 gap=0.2379 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3819 gap=0.2455 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2794 gap=0.1430 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.5350 gap=0.3986 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.3607 gap=0.2243 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.3743 gap=0.2379 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.5810 gap=0.4446 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.7212 gap=0.5848 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.7112 gap=0.5747 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.6393 gap=0.5029 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.4428 gap=0.3064 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.5206 gap=0.3842 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.3808 gap=0.2443 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.6493 gap=0.5129 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4574 gap=0.3209 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.4594 gap=0.3230 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.5165 gap=0.3800 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5938 gap=0.4573 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5828 gap=0.4464 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.3189 gap=0.1825 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4219 gap=0.2854 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.4466 gap=0.3102 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.4208 gap=0.2844 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.4987 gap=0.3623 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5220 gap=0.3856 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.4963 gap=0.3599 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.3369 gap=0.2005 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.3195 gap=0.1830 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3617 gap=0.2253 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.2719 gap=0.1355 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.2415 gap=0.1051 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.6569 gap=0.5204 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.6507 gap=0.5143 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.6489 gap=0.5125 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.4053 gap=0.2689 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.3918 gap=0.2554 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4257 gap=0.2892 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.4875 gap=0.3511 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.5063 gap=0.3699 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.6746 gap=0.5382 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.6265 gap=0.4901 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.6367 gap=0.5003 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.6389 gap=0.5025 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5082 gap=0.3718 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6222 gap=0.4857 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.6767 gap=0.5403 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.6917 gap=0.5553 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.4106 gap=0.2741 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.4433 gap=0.3068 train(resnet18,SDog120)-steal(resnet18)-\n",
      "63\t generating inputs for pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "initial_evaluation: score=0.6657, divergence=0.0000, diversity=1.3314, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6657, divergence=0.0001, diversity=1.3313, num_succ=0, num_remain=86\n",
      " 100-th evaluation: score=0.6659, divergence=0.0002, diversity=1.3314, num_succ=0, num_remain=54\n",
      " 200-th evaluation: score=0.6660, divergence=0.0003, diversity=1.3314, num_succ=0, num_remain=49\n",
      " 300-th evaluation: score=0.6661, divergence=0.0003, diversity=1.3315, num_succ=0, num_remain=55\n",
      " 400-th evaluation: score=0.6661, divergence=0.0004, diversity=1.3315, num_succ=0, num_remain=46\n",
      " 500-th evaluation: score=0.6662, divergence=0.0004, diversity=1.3315, num_succ=0, num_remain=43\n",
      " 600-th evaluation: score=0.6662, divergence=0.0004, diversity=1.3315, num_succ=0, num_remain=38\n",
      " 700-th evaluation: score=0.6663, divergence=0.0005, diversity=1.3316, num_succ=0, num_remain=35\n",
      " 800-th evaluation: score=0.6663, divergence=0.0005, diversity=1.3316, num_succ=0, num_remain=39\n",
      " 900-th evaluation: score=0.6664, divergence=0.0005, diversity=1.3316, num_succ=0, num_remain=38\n",
      "evaluating inputs\n",
      "parent_sim: 0.0514 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.3117 gap=0.2603 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.5262 gap=0.4748 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.5094 gap=0.4580 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.5836 gap=0.5322 train(resnet18,Flower102)-\n",
      "ref_sim: 0.5785 gap=0.5271 train(resnet18,SDog120)-\n",
      "ref_sim: 0.1237 gap=0.0723 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.1753 gap=0.1239 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.1676 gap=0.1162 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.4257 gap=0.3743 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.2589 gap=0.2076 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.3831 gap=0.3317 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.3290 gap=0.2777 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.3324 gap=0.2810 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.1311 gap=0.0797 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.2352 gap=0.1838 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.3225 gap=0.2711 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.1858 gap=0.1345 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.1581 gap=0.1067 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.2638 gap=0.2124 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.2443 gap=0.1929 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.2261 gap=0.1748 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.2879 gap=0.2365 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.2456 gap=0.1942 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.2727 gap=0.2213 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.4594 gap=0.4080 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.3612 gap=0.3098 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.3939 gap=0.3425 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.2541 gap=0.2027 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.3932 gap=0.3418 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.4614 gap=0.4100 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.4506 gap=0.3992 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.4031 gap=0.3518 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.4980 gap=0.4467 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.6888 gap=0.6374 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.6504 gap=0.5991 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.2226 gap=0.1712 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6252 gap=0.5739 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.4199 gap=0.3686 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.6421 gap=0.5907 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.3509 gap=0.2995 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.9091 gap=0.8578 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.7775 gap=0.7261 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.7639 gap=0.7125 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.6771 gap=0.6257 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.7814 gap=0.7300 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.7275 gap=0.6761 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8247 gap=0.7734 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.4439 gap=0.3925 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.4773 gap=0.4259 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.5128 gap=0.4615 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.5288 gap=0.4774 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4298 gap=0.3784 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.5285 gap=0.4771 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.5821 gap=0.5308 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.5713 gap=0.5200 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.5572 gap=0.5059 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.5951 gap=0.5438 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.5387 gap=0.4873 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4849 gap=0.4335 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.6419 gap=0.5905 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.4392 gap=0.3878 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.6494 gap=0.5980 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.5339 gap=0.4826 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.3604 gap=0.3090 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8463 gap=0.7949 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6546 gap=0.6033 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5739 gap=0.5225 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.3304 gap=0.2791 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8489 gap=0.7975 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.7782 gap=0.7268 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.7300 gap=0.6786 train(resnet18,SDog120)-steal(resnet18)-\n",
      "64\t generating inputs for pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "initial_evaluation: score=0.6758, divergence=0.0000, diversity=1.3516, num_succ=0, num_remain=7\n",
      "   0-th evaluation: score=0.6758, divergence=0.0000, diversity=1.3516, num_succ=0, num_remain=83\n",
      " 100-th evaluation: score=0.6760, divergence=0.0002, diversity=1.3517, num_succ=0, num_remain=49\n",
      " 200-th evaluation: score=0.6761, divergence=0.0002, diversity=1.3517, num_succ=0, num_remain=47\n",
      " 300-th evaluation: score=0.6761, divergence=0.0002, diversity=1.3517, num_succ=0, num_remain=49\n",
      " 400-th evaluation: score=0.6762, divergence=0.0003, diversity=1.3518, num_succ=0, num_remain=51\n",
      " 500-th evaluation: score=0.6763, divergence=0.0003, diversity=1.3518, num_succ=0, num_remain=48\n",
      " 600-th evaluation: score=0.6763, divergence=0.0004, diversity=1.3519, num_succ=0, num_remain=44\n",
      " 700-th evaluation: score=0.6764, divergence=0.0004, diversity=1.3519, num_succ=0, num_remain=47\n",
      " 800-th evaluation: score=0.6765, divergence=0.0005, diversity=1.3520, num_succ=0, num_remain=44\n",
      " 900-th evaluation: score=0.6765, divergence=0.0005, diversity=1.3520, num_succ=0, num_remain=44\n",
      "evaluating inputs\n",
      "parent_sim: 0.0168 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.2495 gap=0.2327 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.4888 gap=0.4721 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.6176 gap=0.6008 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.8235 gap=0.8067 train(resnet18,Flower102)-\n",
      "ref_sim: 0.6480 gap=0.6312 train(resnet18,SDog120)-\n",
      "ref_sim: 0.0778 gap=0.0611 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.0945 gap=0.0778 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.1213 gap=0.1045 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.1242 gap=0.1074 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.3297 gap=0.3129 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.3020 gap=0.2852 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.1232 gap=0.1064 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.0968 gap=0.0800 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.0973 gap=0.0805 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.0989 gap=0.0822 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.0453 gap=0.0286 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.1137 gap=0.0970 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.0876 gap=0.0708 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.0830 gap=0.0662 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.0963 gap=0.0795 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.3342 gap=0.3174 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.4067 gap=0.3899 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.1403 gap=0.1235 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.2804 gap=0.2637 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.3919 gap=0.3752 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.2836 gap=0.2669 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.3369 gap=0.3201 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.3884 gap=0.3716 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.3718 gap=0.3550 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.1414 gap=0.1246 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.6299 gap=0.6131 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.1535 gap=0.1367 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.6159 gap=0.5992 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.3837 gap=0.3670 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.3908 gap=0.3740 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.0877 gap=0.0709 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3624 gap=0.3457 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.1407 gap=0.1239 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.4303 gap=0.4135 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.3667 gap=0.3499 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5085 gap=0.4917 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.3799 gap=0.3632 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3835 gap=0.3667 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.8149 gap=0.7981 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.6102 gap=0.5934 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.7259 gap=0.7092 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6454 gap=0.6287 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.4812 gap=0.4644 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.5456 gap=0.5288 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.5568 gap=0.5400 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.6422 gap=0.6255 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.7574 gap=0.7406 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4868 gap=0.4701 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8331 gap=0.8164 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8345 gap=0.8177 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.8198 gap=0.8030 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.6681 gap=0.6513 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.6727 gap=0.6560 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.6844 gap=0.6676 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.2317 gap=0.2150 train(mbnetv2,Flower102)-distill()-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.7276 gap=0.7108 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.8848 gap=0.8680 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.7718 gap=0.7550 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.4883 gap=0.4715 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8790 gap=0.8622 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6859 gap=0.6691 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.7305 gap=0.7137 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.5567 gap=0.5399 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8517 gap=0.8350 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.7372 gap=0.7204 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5540 gap=0.5373 train(resnet18,SDog120)-steal(resnet18)-\n",
      "65\t generating inputs for pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "initial_evaluation: score=0.6614, divergence=0.0000, diversity=1.3229, num_succ=0, num_remain=9\n",
      "   0-th evaluation: score=0.6615, divergence=0.0001, diversity=1.3228, num_succ=0, num_remain=88\n",
      " 100-th evaluation: score=0.6618, divergence=0.0003, diversity=1.3229, num_succ=0, num_remain=58\n",
      " 200-th evaluation: score=0.6619, divergence=0.0004, diversity=1.3229, num_succ=0, num_remain=52\n",
      " 300-th evaluation: score=0.6620, divergence=0.0005, diversity=1.3230, num_succ=0, num_remain=53\n",
      " 400-th evaluation: score=0.6621, divergence=0.0006, diversity=1.3231, num_succ=0, num_remain=50\n",
      " 500-th evaluation: score=0.6622, divergence=0.0006, diversity=1.3231, num_succ=0, num_remain=52\n",
      " 600-th evaluation: score=0.6623, divergence=0.0007, diversity=1.3232, num_succ=0, num_remain=49\n",
      " 700-th evaluation: score=0.6624, divergence=0.0008, diversity=1.3233, num_succ=0, num_remain=45\n",
      " 800-th evaluation: score=0.6625, divergence=0.0009, diversity=1.3233, num_succ=0, num_remain=45\n",
      " 900-th evaluation: score=0.6626, divergence=0.0009, diversity=1.3233, num_succ=0, num_remain=40\n",
      "evaluating inputs\n",
      "parent_sim: 0.1315 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.2018 gap=0.0703 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.4250 gap=0.2935 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.3817 gap=0.2501 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.6902 gap=0.5587 train(resnet18,Flower102)-\n",
      "ref_sim: 0.5263 gap=0.3948 train(resnet18,SDog120)-\n",
      "ref_sim: 0.1442 gap=0.0127 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.1946 gap=0.0631 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.1945 gap=0.0630 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.2065 gap=0.0750 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.3938 gap=0.2623 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.3143 gap=0.1828 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.1862 gap=0.0547 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.1936 gap=0.0621 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.3823 gap=0.2508 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.1961 gap=0.0646 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2107 gap=0.0792 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.3287 gap=0.1972 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2309 gap=0.0994 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.2376 gap=0.1060 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.2652 gap=0.1337 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.2383 gap=0.1067 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.2220 gap=0.0905 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.2968 gap=0.1653 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3174 gap=0.1859 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2455 gap=0.1140 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.2990 gap=0.1675 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2306 gap=0.0991 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.2684 gap=0.1369 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.6230 gap=0.4915 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.3266 gap=0.1951 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.4052 gap=0.2736 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.3870 gap=0.2555 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.4838 gap=0.3523 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.3411 gap=0.2096 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.3667 gap=0.2352 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.6542 gap=0.5227 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5056 gap=0.3740 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.5261 gap=0.3946 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.4894 gap=0.3579 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.6439 gap=0.5124 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5836 gap=0.4521 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.5029 gap=0.3713 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3131 gap=0.1816 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.3337 gap=0.2021 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.3354 gap=0.2039 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.2732 gap=0.1416 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4829 gap=0.3513 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.4241 gap=0.2926 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.4996 gap=0.3681 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.3755 gap=0.2440 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.4219 gap=0.2904 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4178 gap=0.2863 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4483 gap=0.3168 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.6594 gap=0.5279 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.6713 gap=0.5398 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.6926 gap=0.5610 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.5423 gap=0.4108 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.5710 gap=0.4395 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.6438 gap=0.5123 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.3970 gap=0.2655 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.5018 gap=0.3703 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.7013 gap=0.5698 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.7056 gap=0.5741 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.5937 gap=0.4622 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.7327 gap=0.6012 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.4826 gap=0.3511 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5333 gap=0.4018 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.3764 gap=0.2449 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.7415 gap=0.6100 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5365 gap=0.4049 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.4506 gap=0.3191 train(resnet18,SDog120)-steal(resnet18)-\n",
      "66\t generating inputs for pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "initial_evaluation: score=0.6805, divergence=0.0000, diversity=1.3609, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6805, divergence=0.0001, diversity=1.3609, num_succ=0, num_remain=88\n",
      " 100-th evaluation: score=0.6807, divergence=0.0002, diversity=1.3610, num_succ=0, num_remain=53\n",
      " 200-th evaluation: score=0.6807, divergence=0.0002, diversity=1.3610, num_succ=0, num_remain=50\n",
      " 300-th evaluation: score=0.6808, divergence=0.0002, diversity=1.3611, num_succ=0, num_remain=40\n",
      " 400-th evaluation: score=0.6808, divergence=0.0003, diversity=1.3611, num_succ=0, num_remain=44\n",
      " 500-th evaluation: score=0.6809, divergence=0.0003, diversity=1.3611, num_succ=0, num_remain=36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 600-th evaluation: score=0.6809, divergence=0.0003, diversity=1.3611, num_succ=0, num_remain=36\n",
      " 700-th evaluation: score=0.6809, divergence=0.0004, diversity=1.3612, num_succ=0, num_remain=41\n",
      " 800-th evaluation: score=0.6810, divergence=0.0004, diversity=1.3612, num_succ=0, num_remain=33\n",
      " 900-th evaluation: score=0.6810, divergence=0.0004, diversity=1.3612, num_succ=0, num_remain=35\n",
      "evaluating inputs\n",
      "parent_sim: 0.0253 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.2897 gap=0.2644 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.2272 gap=0.2018 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.4317 gap=0.4064 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.3768 gap=0.3515 train(resnet18,Flower102)-\n",
      "ref_sim: 0.2124 gap=0.1871 train(resnet18,SDog120)-\n",
      "ref_sim: 0.1979 gap=0.1726 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.2769 gap=0.2516 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.3011 gap=0.2758 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.3081 gap=0.2828 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.2771 gap=0.2518 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.2016 gap=0.1763 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.2546 gap=0.2293 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.2420 gap=0.2167 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.2976 gap=0.2723 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3137 gap=0.2883 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2905 gap=0.2652 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.3095 gap=0.2842 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.3360 gap=0.3106 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.3076 gap=0.2823 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.3340 gap=0.3087 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.2545 gap=0.2292 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.2679 gap=0.2425 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.5038 gap=0.4785 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.2701 gap=0.2448 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2393 gap=0.2140 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4397 gap=0.4144 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2651 gap=0.2398 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.2779 gap=0.2526 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.3145 gap=0.2892 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.7637 gap=0.7384 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.5585 gap=0.5332 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.8132 gap=0.7879 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.7301 gap=0.7048 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.7793 gap=0.7540 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.3850 gap=0.3597 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.3246 gap=0.2993 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3499 gap=0.3246 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.3699 gap=0.3446 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.3897 gap=0.3644 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.3655 gap=0.3401 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.2864 gap=0.2611 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.6077 gap=0.5823 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5733 gap=0.5480 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.7251 gap=0.6998 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.4926 gap=0.4673 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.6973 gap=0.6720 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6883 gap=0.6630 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.2496 gap=0.2243 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.3429 gap=0.3176 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.2811 gap=0.2558 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3028 gap=0.2774 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.3667 gap=0.3414 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.2790 gap=0.2537 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.3796 gap=0.3543 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.3776 gap=0.3523 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.3660 gap=0.3407 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.2313 gap=0.2060 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.2499 gap=0.2246 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.3141 gap=0.2888 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.5158 gap=0.4905 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.5295 gap=0.5042 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.4072 gap=0.3819 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.3724 gap=0.3471 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.3584 gap=0.3331 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.4155 gap=0.3902 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6712 gap=0.6459 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5290 gap=0.5036 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.2867 gap=0.2614 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.4017 gap=0.3764 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.7493 gap=0.7240 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.3994 gap=0.3741 train(resnet18,SDog120)-steal(resnet18)-\n",
      "67\t generating inputs for pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "initial_evaluation: score=0.6791, divergence=0.0000, diversity=1.3582, num_succ=0, num_remain=7\n",
      "   0-th evaluation: score=0.6791, divergence=0.0000, diversity=1.3581, num_succ=0, num_remain=85\n",
      " 100-th evaluation: score=0.6792, divergence=0.0002, diversity=1.3582, num_succ=0, num_remain=49\n",
      " 200-th evaluation: score=0.6793, divergence=0.0002, diversity=1.3582, num_succ=0, num_remain=38\n",
      " 300-th evaluation: score=0.6793, divergence=0.0002, diversity=1.3582, num_succ=0, num_remain=37\n",
      " 400-th evaluation: score=0.6794, divergence=0.0002, diversity=1.3583, num_succ=0, num_remain=33\n",
      " 500-th evaluation: score=0.6794, divergence=0.0003, diversity=1.3583, num_succ=0, num_remain=31\n",
      " 600-th evaluation: score=0.6794, divergence=0.0003, diversity=1.3583, num_succ=0, num_remain=32\n",
      " 700-th evaluation: score=0.6795, divergence=0.0003, diversity=1.3583, num_succ=0, num_remain=33\n",
      " 800-th evaluation: score=0.6795, divergence=0.0003, diversity=1.3583, num_succ=0, num_remain=29\n",
      " 900-th evaluation: score=0.6795, divergence=0.0003, diversity=1.3583, num_succ=0, num_remain=29\n",
      "evaluating inputs\n",
      "parent_sim: 0.0226 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.2027 gap=0.1801 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.6785 gap=0.6559 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.5226 gap=0.5000 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.6251 gap=0.6025 train(resnet18,Flower102)-\n",
      "ref_sim: 0.6568 gap=0.6342 train(resnet18,SDog120)-\n",
      "ref_sim: 0.1048 gap=0.0822 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.0797 gap=0.0571 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.0879 gap=0.0653 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.2739 gap=0.2513 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.5532 gap=0.5306 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.3816 gap=0.3590 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.0746 gap=0.0520 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.0941 gap=0.0715 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.1150 gap=0.0924 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.0937 gap=0.0711 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.0699 gap=0.0473 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.2053 gap=0.1827 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.0896 gap=0.0670 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.1984 gap=0.1758 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.3792 gap=0.3566 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.3835 gap=0.3609 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.5219 gap=0.4993 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.5419 gap=0.5193 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.5149 gap=0.4923 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.4604 gap=0.4378 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.5613 gap=0.5387 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.3804 gap=0.3579 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.3791 gap=0.3565 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.6081 gap=0.5855 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.2836 gap=0.2610 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.4571 gap=0.4345 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.4246 gap=0.4020 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.7202 gap=0.6976 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.5071 gap=0.4845 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.4024 gap=0.3798 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.5485 gap=0.5259 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6039 gap=0.5813 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.6029 gap=0.5803 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.6460 gap=0.6234 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5623 gap=0.5397 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6973 gap=0.6747 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.7179 gap=0.6953 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6842 gap=0.6616 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.6749 gap=0.6523 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.6685 gap=0.6459 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5587 gap=0.5361 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5943 gap=0.5717 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.6293 gap=0.6067 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.5499 gap=0.5273 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.3579 gap=0.3354 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.5896 gap=0.5670 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4411 gap=0.4185 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.6750 gap=0.6524 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.5953 gap=0.5727 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.5953 gap=0.5727 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.5884 gap=0.5658 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.6695 gap=0.6469 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.6512 gap=0.6286 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.6601 gap=0.6375 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.5950 gap=0.5724 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.5897 gap=0.5671 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.6854 gap=0.6628 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.6489 gap=0.6263 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.7232 gap=0.7006 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.7111 gap=0.6885 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6960 gap=0.6734 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.7059 gap=0.6833 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.2668 gap=0.2442 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.7801 gap=0.7575 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6707 gap=0.6481 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6387 gap=0.6161 train(resnet18,SDog120)-steal(resnet18)-\n",
      "68\t generating inputs for pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "initial_evaluation: score=0.6639, divergence=0.0000, diversity=1.3279, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6640, divergence=0.0001, diversity=1.3279, num_succ=0, num_remain=87\n",
      " 100-th evaluation: score=0.6642, divergence=0.0002, diversity=1.3279, num_succ=0, num_remain=49\n",
      " 200-th evaluation: score=0.6643, divergence=0.0003, diversity=1.3280, num_succ=0, num_remain=42\n",
      " 300-th evaluation: score=0.6643, divergence=0.0003, diversity=1.3280, num_succ=0, num_remain=36\n",
      " 400-th evaluation: score=0.6643, divergence=0.0003, diversity=1.3280, num_succ=0, num_remain=39\n",
      " 500-th evaluation: score=0.6644, divergence=0.0004, diversity=1.3280, num_succ=0, num_remain=34\n",
      " 600-th evaluation: score=0.6644, divergence=0.0004, diversity=1.3281, num_succ=0, num_remain=38\n",
      " 700-th evaluation: score=0.6645, divergence=0.0005, diversity=1.3281, num_succ=0, num_remain=32\n",
      " 800-th evaluation: score=0.6645, divergence=0.0005, diversity=1.3281, num_succ=0, num_remain=29\n",
      " 900-th evaluation: score=0.6645, divergence=0.0005, diversity=1.3281, num_succ=0, num_remain=28\n",
      "evaluating inputs\n",
      "parent_sim: 0.0535 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.1680 gap=0.1145 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.3481 gap=0.2946 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.3517 gap=0.2982 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.6229 gap=0.5694 train(resnet18,Flower102)-\n",
      "ref_sim: 0.5017 gap=0.4482 train(resnet18,SDog120)-\n",
      "ref_sim: 0.2640 gap=0.2105 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.1905 gap=0.1370 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.1701 gap=0.1166 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.3416 gap=0.2881 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.3788 gap=0.3253 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.3796 gap=0.3261 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.2069 gap=0.1534 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.2146 gap=0.1611 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.2572 gap=0.2037 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.1993 gap=0.1458 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2298 gap=0.1763 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.1945 gap=0.1410 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2012 gap=0.1477 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.2277 gap=0.1742 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.2927 gap=0.2392 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.3041 gap=0.2506 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.2747 gap=0.2213 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.3197 gap=0.2662 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3151 gap=0.2616 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.3836 gap=0.3301 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4177 gap=0.3642 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.4393 gap=0.3858 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.3811 gap=0.3276 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.3729 gap=0.3194 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.4980 gap=0.4445 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.3333 gap=0.2798 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.3216 gap=0.2681 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.4544 gap=0.4009 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.2832 gap=0.2298 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.3498 gap=0.2963 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.3826 gap=0.3291 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5204 gap=0.4669 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.3010 gap=0.2475 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.7098 gap=0.6563 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5013 gap=0.4478 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5669 gap=0.5134 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.6506 gap=0.5971 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3591 gap=0.3056 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.4989 gap=0.4454 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.3814 gap=0.3279 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.4548 gap=0.4013 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4795 gap=0.4260 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.2701 gap=0.2166 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.2527 gap=0.1992 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.3089 gap=0.2554 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3378 gap=0.2843 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.3305 gap=0.2770 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.3612 gap=0.3077 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.6012 gap=0.5477 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.6105 gap=0.5570 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.6271 gap=0.5736 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.5569 gap=0.5034 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.5273 gap=0.4738 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.5227 gap=0.4692 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.3181 gap=0.2646 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.3720 gap=0.3185 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.7033 gap=0.6499 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.4931 gap=0.4396 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.3320 gap=0.2785 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.6806 gap=0.6271 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5043 gap=0.4508 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.4151 gap=0.3616 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.4662 gap=0.4127 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.6101 gap=0.5566 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.4247 gap=0.3712 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5168 gap=0.4634 train(resnet18,SDog120)-steal(resnet18)-\n",
      "69\t generating inputs for pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "initial_evaluation: score=0.5430, divergence=0.0000, diversity=1.0861, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.5435, divergence=0.0005, diversity=1.0862, num_succ=0, num_remain=82\n",
      " 100-th evaluation: score=0.5446, divergence=0.0014, diversity=1.0865, num_succ=0, num_remain=37\n",
      " 200-th evaluation: score=0.5451, divergence=0.0017, diversity=1.0867, num_succ=0, num_remain=34\n",
      " 300-th evaluation: score=0.5453, divergence=0.0019, diversity=1.0869, num_succ=0, num_remain=28\n",
      " 400-th evaluation: score=0.5457, divergence=0.0021, diversity=1.0871, num_succ=0, num_remain=30\n",
      " 500-th evaluation: score=0.5460, divergence=0.0023, diversity=1.0873, num_succ=0, num_remain=27\n",
      " 600-th evaluation: score=0.5464, divergence=0.0026, diversity=1.0876, num_succ=0, num_remain=35\n",
      " 700-th evaluation: score=0.5467, divergence=0.0028, diversity=1.0877, num_succ=0, num_remain=29\n",
      " 800-th evaluation: score=0.5470, divergence=0.0030, diversity=1.0879, num_succ=0, num_remain=31\n",
      " 900-th evaluation: score=0.5474, divergence=0.0033, diversity=1.0882, num_succ=0, num_remain=35\n",
      "evaluating inputs\n",
      "parent_sim: 0.1186 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.4685 gap=0.3499 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.6884 gap=0.5698 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.5385 gap=0.4199 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.9030 gap=0.7845 train(resnet18,Flower102)-\n",
      "ref_sim: 0.6949 gap=0.5763 train(resnet18,SDog120)-\n",
      "ref_sim: 0.5883 gap=0.4697 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.6157 gap=0.4971 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.6715 gap=0.5530 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.3970 gap=0.2784 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.1465 gap=0.0280 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.2103 gap=0.0917 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.6306 gap=0.5120 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.6515 gap=0.5329 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.8714 gap=0.7528 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.6279 gap=0.5093 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.6338 gap=0.5153 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.5824 gap=0.4639 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.6632 gap=0.5446 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.7118 gap=0.5932 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.6376 gap=0.5190 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.3319 gap=0.2134 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.4644 gap=0.3459 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.5688 gap=0.4502 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.2407 gap=0.1221 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.3939 gap=0.2753 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4520 gap=0.3335 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2385 gap=0.1200 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.1302 gap=0.0116 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.6765 gap=0.5579 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.6223 gap=0.5038 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.6144 gap=0.4958 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.6452 gap=0.5266 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.7328 gap=0.6142 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.6769 gap=0.5583 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.7433 gap=0.6247 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.5073 gap=0.3887 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.7197 gap=0.6012 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.5932 gap=0.4746 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.7063 gap=0.5877 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.6062 gap=0.4876 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8385 gap=0.7199 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.5174 gap=0.3988 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5339 gap=0.4153 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.3325 gap=0.2140 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.2537 gap=0.1351 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.4839 gap=0.3653 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3155 gap=0.1969 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.7473 gap=0.6287 train(mbnetv2,Flower102)-prune(0.2)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.7122 gap=0.5936 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.8037 gap=0.6851 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.5527 gap=0.4341 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4981 gap=0.3795 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.5382 gap=0.4196 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8879 gap=0.7694 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8879 gap=0.7693 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.8855 gap=0.7669 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.6815 gap=0.5629 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.6364 gap=0.5179 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.6989 gap=0.5803 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.6167 gap=0.4981 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.5704 gap=0.4518 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.8789 gap=0.7604 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.7987 gap=0.6801 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.6524 gap=0.5339 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8851 gap=0.7665 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5792 gap=0.4606 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6624 gap=0.5438 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.5605 gap=0.4420 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.9251 gap=0.8065 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5772 gap=0.4586 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.4925 gap=0.3739 train(resnet18,SDog120)-steal(resnet18)-\n",
      "70\t generating inputs for pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "initial_evaluation: score=0.4774, divergence=0.0000, diversity=0.9549, num_succ=0, num_remain=7\n",
      "   0-th evaluation: score=0.4778, divergence=0.0003, diversity=0.9549, num_succ=0, num_remain=81\n",
      " 100-th evaluation: score=0.4791, divergence=0.0014, diversity=0.9552, num_succ=0, num_remain=35\n",
      " 200-th evaluation: score=0.4794, divergence=0.0018, diversity=0.9554, num_succ=0, num_remain=29\n",
      " 300-th evaluation: score=0.4801, divergence=0.0022, diversity=0.9558, num_succ=1, num_remain=39\n",
      " 400-th evaluation: score=0.4807, divergence=0.0026, diversity=0.9561, num_succ=1, num_remain=35\n",
      " 500-th evaluation: score=0.4812, divergence=0.0031, diversity=0.9563, num_succ=2, num_remain=32\n",
      " 600-th evaluation: score=0.4817, divergence=0.0034, diversity=0.9566, num_succ=2, num_remain=27\n",
      " 700-th evaluation: score=0.4822, divergence=0.0038, diversity=0.9568, num_succ=2, num_remain=33\n",
      " 800-th evaluation: score=0.4825, divergence=0.0040, diversity=0.9570, num_succ=2, num_remain=38\n",
      " 900-th evaluation: score=0.4831, divergence=0.0044, diversity=0.9573, num_succ=2, num_remain=40\n",
      "evaluating inputs\n",
      "parent_sim: 0.0273 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.0909 gap=0.0636 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.6920 gap=0.6648 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.2081 gap=0.1808 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.9319 gap=0.9046 train(resnet18,Flower102)-\n",
      "ref_sim: 0.4290 gap=0.4017 train(resnet18,SDog120)-\n",
      "ref_sim: 0.2214 gap=0.1941 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.3886 gap=0.3613 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.3903 gap=0.3630 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.0733 gap=0.0460 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.3343 gap=0.3070 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.0734 gap=0.0461 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.1888 gap=0.1615 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.3257 gap=0.2985 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4110 gap=0.3837 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.4387 gap=0.4114 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.5804 gap=0.5531 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.7197 gap=0.6924 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.3903 gap=0.3630 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.4706 gap=0.4433 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.7507 gap=0.7234 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.1064 gap=0.0791 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.1004 gap=0.0731 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.1436 gap=0.1163 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3157 gap=0.2884 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.1040 gap=0.0767 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4682 gap=0.4409 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.0604 gap=0.0331 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.2599 gap=0.2326 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.3539 gap=0.3266 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.6101 gap=0.5829 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.0848 gap=0.0575 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.8235 gap=0.7962 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.0542 gap=0.0269 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.3531 gap=0.3258 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.1629 gap=0.1356 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.7223 gap=0.6950 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8282 gap=0.8010 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.8022 gap=0.7749 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.9258 gap=0.8985 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.8133 gap=0.7860 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.9190 gap=0.8917 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.3657 gap=0.3384 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.1023 gap=0.0750 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.1458 gap=0.1185 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.1913 gap=0.1640 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.4495 gap=0.4222 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.0992 gap=0.0719 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.6575 gap=0.6302 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.7946 gap=0.7673 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.5066 gap=0.4793 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.2077 gap=0.1804 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4581 gap=0.4308 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.1425 gap=0.1152 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.9260 gap=0.8987 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.9237 gap=0.8964 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.9166 gap=0.8893 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.5174 gap=0.4901 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4693 gap=0.4420 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.3348 gap=0.3075 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.7742 gap=0.7469 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.3241 gap=0.2968 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.9346 gap=0.9073 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.3847 gap=0.3574 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.7690 gap=0.7417 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.9127 gap=0.8854 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6316 gap=0.6043 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.4857 gap=0.4584 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.6057 gap=0.5784 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.9214 gap=0.8941 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6724 gap=0.6451 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5738 gap=0.5465 train(resnet18,SDog120)-steal(resnet18)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\t generating inputs for pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "initial_evaluation: score=0.5185, divergence=0.0000, diversity=1.0369, num_succ=0, num_remain=9\n",
      "   0-th evaluation: score=0.5188, divergence=0.0003, diversity=1.0369, num_succ=0, num_remain=82\n",
      " 100-th evaluation: score=0.5199, divergence=0.0014, diversity=1.0372, num_succ=0, num_remain=38\n",
      " 200-th evaluation: score=0.5204, divergence=0.0017, diversity=1.0374, num_succ=0, num_remain=34\n",
      " 300-th evaluation: score=0.5207, divergence=0.0019, diversity=1.0376, num_succ=0, num_remain=29\n",
      " 400-th evaluation: score=0.5210, divergence=0.0021, diversity=1.0377, num_succ=0, num_remain=29\n",
      " 500-th evaluation: score=0.5213, divergence=0.0024, diversity=1.0378, num_succ=0, num_remain=31\n",
      " 600-th evaluation: score=0.5215, divergence=0.0026, diversity=1.0379, num_succ=0, num_remain=26\n",
      " 700-th evaluation: score=0.5218, divergence=0.0028, diversity=1.0381, num_succ=0, num_remain=24\n",
      " 800-th evaluation: score=0.5221, divergence=0.0030, diversity=1.0382, num_succ=0, num_remain=26\n",
      " 900-th evaluation: score=0.5224, divergence=0.0032, diversity=1.0384, num_succ=0, num_remain=28\n",
      "evaluating inputs\n",
      "parent_sim: 0.0678 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.4453 gap=0.3776 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.5265 gap=0.4587 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.2334 gap=0.1656 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.7172 gap=0.6494 train(resnet18,Flower102)-\n",
      "ref_sim: 0.4779 gap=0.4102 train(resnet18,SDog120)-\n",
      "ref_sim: 0.6504 gap=0.5826 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.6772 gap=0.6094 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.6384 gap=0.5706 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.4505 gap=0.3827 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.3166 gap=0.2488 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.4570 gap=0.3892 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.6472 gap=0.5795 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.6730 gap=0.6052 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.6411 gap=0.5733 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.6247 gap=0.5569 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.6774 gap=0.6096 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.6695 gap=0.6018 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.6256 gap=0.5579 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.6824 gap=0.6146 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.6194 gap=0.5516 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.4453 gap=0.3775 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.2349 gap=0.1672 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0656 gap=-0.0022 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.4628 gap=0.3950 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.3302 gap=0.2624 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4781 gap=0.4103 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.4816 gap=0.4138 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.4100 gap=0.3422 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.1677 gap=0.0999 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.6333 gap=0.5655 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.6080 gap=0.5402 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.5476 gap=0.4798 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.0998 gap=0.0320 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.1299 gap=0.0622 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.1952 gap=0.1274 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.5139 gap=0.4461 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.7287 gap=0.6609 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.5651 gap=0.4973 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.6193 gap=0.5515 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.6473 gap=0.5795 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6980 gap=0.6302 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.6766 gap=0.6088 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5276 gap=0.4598 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.2238 gap=0.1560 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.2358 gap=0.1680 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.1354 gap=0.0676 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3057 gap=0.2380 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.5116 gap=0.4438 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.4752 gap=0.4074 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.5750 gap=0.5072 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.2177 gap=0.1499 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.1898 gap=0.1220 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.2936 gap=0.2258 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.7174 gap=0.6496 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.6886 gap=0.6208 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.6251 gap=0.5573 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.4148 gap=0.3470 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.3302 gap=0.2624 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4477 gap=0.3799 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.6349 gap=0.5671 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.2199 gap=0.1521 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.6554 gap=0.5876 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.6512 gap=0.5834 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.6333 gap=0.5656 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.6883 gap=0.6205 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.1853 gap=0.1176 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.2720 gap=0.2042 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.5969 gap=0.5291 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8018 gap=0.7340 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.3224 gap=0.2546 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.2669 gap=0.1991 train(resnet18,SDog120)-steal(resnet18)-\n",
      "72\t generating inputs for pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "initial_evaluation: score=0.5856, divergence=0.0000, diversity=1.1712, num_succ=0, num_remain=8\n",
      "   0-th evaluation: score=0.5860, divergence=0.0005, diversity=1.1709, num_succ=0, num_remain=82\n",
      " 100-th evaluation: score=0.5870, divergence=0.0014, diversity=1.1713, num_succ=0, num_remain=44\n",
      " 200-th evaluation: score=0.5873, divergence=0.0016, diversity=1.1713, num_succ=0, num_remain=38\n",
      " 300-th evaluation: score=0.5874, divergence=0.0017, diversity=1.1714, num_succ=0, num_remain=39\n",
      " 400-th evaluation: score=0.5876, divergence=0.0019, diversity=1.1715, num_succ=0, num_remain=36\n",
      " 500-th evaluation: score=0.5879, divergence=0.0021, diversity=1.1716, num_succ=0, num_remain=38\n",
      " 600-th evaluation: score=0.5880, divergence=0.0022, diversity=1.1717, num_succ=0, num_remain=33\n",
      " 700-th evaluation: score=0.5882, divergence=0.0023, diversity=1.1718, num_succ=0, num_remain=37\n",
      " 800-th evaluation: score=0.5884, divergence=0.0025, diversity=1.1719, num_succ=0, num_remain=39\n",
      " 900-th evaluation: score=0.5887, divergence=0.0027, diversity=1.1720, num_succ=0, num_remain=34\n",
      "evaluating inputs\n",
      "parent_sim: 0.0560 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.1585 gap=0.1025 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.4719 gap=0.4158 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.2726 gap=0.2165 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.7023 gap=0.6463 train(resnet18,Flower102)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.3359 gap=0.2799 train(resnet18,SDog120)-\n",
      "ref_sim: 0.4351 gap=0.3790 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.6142 gap=0.5581 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.7549 gap=0.6989 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.1589 gap=0.1028 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.1260 gap=0.0700 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.3355 gap=0.2794 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.5415 gap=0.4854 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.6180 gap=0.5620 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.6036 gap=0.5475 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.6608 gap=0.6048 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.6858 gap=0.6297 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.6410 gap=0.5849 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.7408 gap=0.6847 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.7080 gap=0.6519 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.5212 gap=0.4651 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.4155 gap=0.3595 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.3032 gap=0.2472 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.2285 gap=0.1724 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3485 gap=0.2925 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2948 gap=0.2387 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.2973 gap=0.2413 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.4770 gap=0.4210 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.2083 gap=0.1522 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.2969 gap=0.2409 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.4453 gap=0.3893 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.4069 gap=0.3508 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.6606 gap=0.6046 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.1358 gap=0.0797 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.1502 gap=0.0941 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.4424 gap=0.3863 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.4462 gap=0.3902 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3893 gap=0.3333 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.3535 gap=0.2975 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.3604 gap=0.3044 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.2859 gap=0.2298 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5943 gap=0.5383 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.3455 gap=0.2895 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.2427 gap=0.1867 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.2680 gap=0.2120 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.3656 gap=0.3095 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.2718 gap=0.2157 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3474 gap=0.2913 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.4520 gap=0.3959 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.5122 gap=0.4562 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.6233 gap=0.5673 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.2788 gap=0.2227 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.2353 gap=0.1792 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4023 gap=0.3463 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.6700 gap=0.6139 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.6590 gap=0.6030 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.7066 gap=0.6506 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3595 gap=0.3034 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.3405 gap=0.2845 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.3150 gap=0.2590 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.5416 gap=0.4856 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.3002 gap=0.2442 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.6964 gap=0.6404 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.3848 gap=0.3288 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.5416 gap=0.4855 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.6530 gap=0.5970 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6748 gap=0.6188 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.3302 gap=0.2742 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.5359 gap=0.4799 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.7638 gap=0.7077 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.3176 gap=0.2615 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.3432 gap=0.2871 train(resnet18,SDog120)-steal(resnet18)-\n",
      "73\t generating inputs for pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "initial_evaluation: score=0.5591, divergence=0.0000, diversity=1.1181, num_succ=0, num_remain=9\n",
      "   0-th evaluation: score=0.5592, divergence=0.0002, diversity=1.1181, num_succ=0, num_remain=84\n",
      " 100-th evaluation: score=0.5604, divergence=0.0011, diversity=1.1186, num_succ=0, num_remain=34\n",
      " 200-th evaluation: score=0.5608, divergence=0.0013, diversity=1.1188, num_succ=0, num_remain=30\n",
      " 300-th evaluation: score=0.5612, divergence=0.0017, diversity=1.1191, num_succ=0, num_remain=32\n",
      " 400-th evaluation: score=0.5617, divergence=0.0020, diversity=1.1193, num_succ=0, num_remain=35\n",
      " 500-th evaluation: score=0.5620, divergence=0.0022, diversity=1.1195, num_succ=0, num_remain=29\n",
      " 600-th evaluation: score=0.5625, divergence=0.0026, diversity=1.1198, num_succ=0, num_remain=32\n",
      " 700-th evaluation: score=0.5628, divergence=0.0028, diversity=1.1201, num_succ=0, num_remain=31\n",
      " 800-th evaluation: score=0.5632, divergence=0.0030, diversity=1.1203, num_succ=0, num_remain=35\n",
      " 900-th evaluation: score=0.5636, divergence=0.0033, diversity=1.1206, num_succ=0, num_remain=31\n",
      "evaluating inputs\n",
      "parent_sim: 0.0715 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.3259 gap=0.2544 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.5688 gap=0.4974 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.4252 gap=0.3537 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.8003 gap=0.7288 train(resnet18,Flower102)-\n",
      "ref_sim: 0.6658 gap=0.5943 train(resnet18,SDog120)-\n",
      "ref_sim: 0.4111 gap=0.3397 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.3464 gap=0.2750 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.2898 gap=0.2184 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.1470 gap=0.0756 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0606 gap=-0.0109 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\u001b[0m\n",
      "ref_sim: 0.1610 gap=0.0895 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.3405 gap=0.2690 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.1773 gap=0.1058 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.3165 gap=0.2451 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.2826 gap=0.2111 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2130 gap=0.1415 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4926 gap=0.4211 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2115 gap=0.1401 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.2239 gap=0.1524 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.4200 gap=0.3485 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.1971 gap=0.1257 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.3266 gap=0.2551 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.2983 gap=0.2269 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.1848 gap=0.1133 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.1531 gap=0.0816 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.2561 gap=0.1847 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.0877 gap=0.0163 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.1264 gap=0.0550 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.2459 gap=0.1744 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.5722 gap=0.5007 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.5601 gap=0.4886 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.4114 gap=0.3399 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.2277 gap=0.1563 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.3930 gap=0.3215 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.3138 gap=0.2423 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.6061 gap=0.5346 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6779 gap=0.6064 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.5556 gap=0.4841 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.7257 gap=0.6543 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.6602 gap=0.5888 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.7317 gap=0.6603 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.2870 gap=0.2156 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.1958 gap=0.1243 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.3419 gap=0.2704 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.4565 gap=0.3851 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.2979 gap=0.2264 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4326 gap=0.3611 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.6289 gap=0.5575 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.6662 gap=0.5948 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.4986 gap=0.4271 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.4312 gap=0.3597 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4297 gap=0.3582 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.6133 gap=0.5419 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8094 gap=0.7379 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8173 gap=0.7458 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.7917 gap=0.7202 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.6949 gap=0.6235 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.7269 gap=0.6554 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.7311 gap=0.6597 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.5800 gap=0.5086 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.4585 gap=0.3870 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.8586 gap=0.7872 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.6575 gap=0.5861 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.7763 gap=0.7049 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8981 gap=0.8266 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6285 gap=0.5571 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.4103 gap=0.3388 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.6627 gap=0.5912 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8995 gap=0.8280 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.8194 gap=0.7479 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6135 gap=0.5421 train(resnet18,SDog120)-steal(resnet18)-\n",
      "74\t generating inputs for pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "initial_evaluation: score=0.5471, divergence=0.0000, diversity=1.0942, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.5475, divergence=0.0005, diversity=1.0942, num_succ=0, num_remain=83\n",
      " 100-th evaluation: score=0.5488, divergence=0.0015, diversity=1.0945, num_succ=0, num_remain=53\n",
      " 200-th evaluation: score=0.5494, divergence=0.0020, diversity=1.0948, num_succ=0, num_remain=44\n",
      " 300-th evaluation: score=0.5501, divergence=0.0025, diversity=1.0951, num_succ=0, num_remain=48\n",
      " 400-th evaluation: score=0.5508, divergence=0.0031, diversity=1.0954, num_succ=0, num_remain=40\n",
      " 500-th evaluation: score=0.5514, divergence=0.0035, diversity=1.0957, num_succ=0, num_remain=47\n",
      " 600-th evaluation: score=0.5521, divergence=0.0041, diversity=1.0961, num_succ=0, num_remain=43\n",
      " 700-th evaluation: score=0.5526, divergence=0.0044, diversity=1.0963, num_succ=0, num_remain=46\n",
      " 800-th evaluation: score=0.5531, divergence=0.0048, diversity=1.0966, num_succ=0, num_remain=45\n",
      " 900-th evaluation: score=0.5538, divergence=0.0053, diversity=1.0970, num_succ=0, num_remain=43\n",
      "evaluating inputs\n",
      "parent_sim: 0.1221 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.1551 gap=0.0330 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.5328 gap=0.4107 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.6532 gap=0.5311 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.9018 gap=0.7796 train(resnet18,Flower102)-\n",
      "ref_sim: 0.8618 gap=0.7396 train(resnet18,SDog120)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0869 gap=-0.0352 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\u001b[0m\n",
      "ref_sim: 0.2265 gap=0.1044 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.3395 gap=0.2174 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.2130 gap=0.0909 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.2262 gap=0.1041 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.2753 gap=0.1532 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.3307 gap=0.2086 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.2937 gap=0.1716 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.5295 gap=0.4074 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.2963 gap=0.1742 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2231 gap=0.1010 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.1603 gap=0.0382 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2771 gap=0.1550 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.3152 gap=0.1931 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.2050 gap=0.0829 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1206 gap=-0.0015 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1063 gap=-0.0158 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\u001b[0m\n",
      "ref_sim: 0.2682 gap=0.1461 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1217 gap=-0.0004 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1112 gap=-0.0109 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\u001b[0m\n",
      "ref_sim: 0.3056 gap=0.1835 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1144 gap=-0.0077 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\u001b[0m\n",
      "ref_sim: 0.1885 gap=0.0663 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.5526 gap=0.4305 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.2230 gap=0.1009 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.1375 gap=0.0153 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.4900 gap=0.3679 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.1509 gap=0.0288 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.2069 gap=0.0848 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.1357 gap=0.0136 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.5967 gap=0.4745 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8730 gap=0.7509 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.4836 gap=0.3615 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.7393 gap=0.6172 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.2636 gap=0.1415 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.7212 gap=0.5991 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.6664 gap=0.5443 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5242 gap=0.4021 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.6064 gap=0.4843 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.7885 gap=0.6664 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.6600 gap=0.5379 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6991 gap=0.5770 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.7764 gap=0.6543 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.6434 gap=0.5213 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.4628 gap=0.3407 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.6706 gap=0.5485 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.3794 gap=0.2573 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.5737 gap=0.4516 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8982 gap=0.7761 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.9040 gap=0.7819 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.9093 gap=0.7872 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.8724 gap=0.7503 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.8586 gap=0.7365 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.8506 gap=0.7285 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.6318 gap=0.5097 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.4607 gap=0.3386 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.8833 gap=0.7612 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.8431 gap=0.7210 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.6119 gap=0.4898 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8753 gap=0.7532 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6697 gap=0.5476 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.8999 gap=0.7778 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.3639 gap=0.2418 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8759 gap=0.7538 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.7879 gap=0.6658 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.8126 gap=0.6904 train(resnet18,SDog120)-steal(resnet18)-\n",
      "75\t generating inputs for pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "initial_evaluation: score=0.5670, divergence=0.0000, diversity=1.1340, num_succ=0, num_remain=7\n",
      "   0-th evaluation: score=0.5677, divergence=0.0007, diversity=1.1340, num_succ=0, num_remain=84\n",
      " 100-th evaluation: score=0.5685, divergence=0.0014, diversity=1.1342, num_succ=0, num_remain=51\n",
      " 200-th evaluation: score=0.5689, divergence=0.0016, diversity=1.1345, num_succ=0, num_remain=43\n",
      " 300-th evaluation: score=0.5692, divergence=0.0019, diversity=1.1346, num_succ=0, num_remain=36\n",
      " 400-th evaluation: score=0.5695, divergence=0.0021, diversity=1.1347, num_succ=0, num_remain=34\n",
      " 500-th evaluation: score=0.5698, divergence=0.0024, diversity=1.1349, num_succ=0, num_remain=38\n",
      " 600-th evaluation: score=0.5700, divergence=0.0025, diversity=1.1350, num_succ=0, num_remain=33\n",
      " 700-th evaluation: score=0.5703, divergence=0.0027, diversity=1.1351, num_succ=0, num_remain=29\n",
      " 800-th evaluation: score=0.5705, divergence=0.0029, diversity=1.1352, num_succ=0, num_remain=25\n",
      " 900-th evaluation: score=0.5706, divergence=0.0030, diversity=1.1353, num_succ=0, num_remain=31\n",
      "evaluating inputs\n",
      "parent_sim: 0.0469 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.1330 gap=0.0860 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.5977 gap=0.5508 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.4429 gap=0.3960 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.8743 gap=0.8274 train(resnet18,Flower102)-\n",
      "ref_sim: 0.7584 gap=0.7115 train(resnet18,SDog120)-\n",
      "ref_sim: 0.2181 gap=0.1712 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.1578 gap=0.1109 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.1543 gap=0.1074 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.1569 gap=0.1100 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.1282 gap=0.0813 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.1892 gap=0.1423 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.2359 gap=0.1890 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.2959 gap=0.2490 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.5148 gap=0.4679 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.1218 gap=0.0749 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2129 gap=0.1660 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4741 gap=0.4272 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.1512 gap=0.1043 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.1539 gap=0.1069 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.3076 gap=0.2606 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.0815 gap=0.0346 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.1579 gap=0.1110 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.2380 gap=0.1911 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.1215 gap=0.0746 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.1229 gap=0.0760 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.2241 gap=0.1772 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.1682 gap=0.1213 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.1672 gap=0.1203 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.2361 gap=0.1892 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.3469 gap=0.3000 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.1406 gap=0.0937 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.1912 gap=0.1443 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.1959 gap=0.1490 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.2176 gap=0.1707 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.2023 gap=0.1554 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.5911 gap=0.5442 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.7859 gap=0.7390 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.4839 gap=0.4370 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.7842 gap=0.7372 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.6639 gap=0.6170 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8281 gap=0.7812 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.2140 gap=0.1671 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3839 gap=0.3370 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.5682 gap=0.5213 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.2445 gap=0.1976 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.2321 gap=0.1852 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3671 gap=0.3202 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.7567 gap=0.7098 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.6412 gap=0.5943 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.6753 gap=0.6284 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.4821 gap=0.4352 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4628 gap=0.4159 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4932 gap=0.4463 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8735 gap=0.8266 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8774 gap=0.8305 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.8726 gap=0.8257 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.7748 gap=0.7279 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.7290 gap=0.6821 train(resnet18,SDog120)-prune(0.5)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.6743 gap=0.6274 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.6921 gap=0.6452 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.7085 gap=0.6616 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.8904 gap=0.8435 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.7391 gap=0.6922 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.7038 gap=0.6569 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8733 gap=0.8263 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.2120 gap=0.1651 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6185 gap=0.5716 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.8646 gap=0.8177 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8858 gap=0.8388 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6281 gap=0.5812 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.2598 gap=0.2129 train(resnet18,SDog120)-steal(resnet18)-\n",
      "76\t generating inputs for pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "initial_evaluation: score=0.5566, divergence=0.0000, diversity=1.1133, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.5570, divergence=0.0003, diversity=1.1133, num_succ=0, num_remain=82\n",
      " 100-th evaluation: score=0.5585, divergence=0.0015, diversity=1.1140, num_succ=0, num_remain=50\n",
      " 200-th evaluation: score=0.5592, divergence=0.0020, diversity=1.1144, num_succ=0, num_remain=42\n",
      " 300-th evaluation: score=0.5600, divergence=0.0026, diversity=1.1148, num_succ=0, num_remain=52\n",
      " 400-th evaluation: score=0.5607, divergence=0.0031, diversity=1.1152, num_succ=0, num_remain=45\n",
      " 500-th evaluation: score=0.5616, divergence=0.0037, diversity=1.1158, num_succ=0, num_remain=46\n",
      " 600-th evaluation: score=0.5622, divergence=0.0041, diversity=1.1162, num_succ=0, num_remain=42\n",
      " 700-th evaluation: score=0.5631, divergence=0.0047, diversity=1.1168, num_succ=0, num_remain=43\n",
      " 800-th evaluation: score=0.5636, divergence=0.0051, diversity=1.1170, num_succ=0, num_remain=56\n",
      " 900-th evaluation: score=0.5642, divergence=0.0055, diversity=1.1174, num_succ=0, num_remain=46\n",
      "evaluating inputs\n",
      "parent_sim: 0.0049 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.4710 gap=0.4661 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.3675 gap=0.3626 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.1918 gap=0.1869 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.1250 gap=0.1201 train(resnet18,Flower102)-\n",
      "ref_sim: 0.6178 gap=0.6129 train(resnet18,SDog120)-\n",
      "ref_sim: 0.6624 gap=0.6575 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.6731 gap=0.6682 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.7621 gap=0.7572 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.6298 gap=0.6249 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.3044 gap=0.2996 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.2934 gap=0.2885 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.6910 gap=0.6861 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.5981 gap=0.5933 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.6719 gap=0.6671 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.7206 gap=0.7158 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.7032 gap=0.6984 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.6892 gap=0.6844 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.7701 gap=0.7653 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.7834 gap=0.7786 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.6970 gap=0.6921 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.4925 gap=0.4876 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.4023 gap=0.3974 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.5605 gap=0.5557 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.4388 gap=0.4340 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2995 gap=0.2946 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.7762 gap=0.7714 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2678 gap=0.2630 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.1204 gap=0.1156 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.7740 gap=0.7692 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.8599 gap=0.8551 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.7973 gap=0.7924 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.6039 gap=0.5991 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.5462 gap=0.5414 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.8127 gap=0.8078 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.3251 gap=0.3203 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.2392 gap=0.2343 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6532 gap=0.6484 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.1786 gap=0.1737 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.4778 gap=0.4730 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.1332 gap=0.1283 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4275 gap=0.4226 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.5611 gap=0.5563 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.0561 gap=0.0512 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.1727 gap=0.1679 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.6985 gap=0.6936 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.4477 gap=0.4428 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.1249 gap=0.1200 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.3983 gap=0.3934 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.4679 gap=0.4631 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.5879 gap=0.5831 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.1955 gap=0.1907 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.1407 gap=0.1358 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.3944 gap=0.3895 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.1111 gap=0.1063 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.1829 gap=0.1781 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.1325 gap=0.1277 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.5786 gap=0.5737 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.6225 gap=0.6177 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.5045 gap=0.4996 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.3261 gap=0.3212 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.4136 gap=0.4087 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.1700 gap=0.1652 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.2463 gap=0.2414 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.3535 gap=0.3486 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.6672 gap=0.6623 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6831 gap=0.6783 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.2828 gap=0.2779 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.4836 gap=0.4787 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.5095 gap=0.5046 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.7412 gap=0.7364 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6933 gap=0.6885 train(resnet18,SDog120)-steal(resnet18)-\n",
      "77\t generating inputs for pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "initial_evaluation: score=0.5266, divergence=0.0000, diversity=1.0531, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.5269, divergence=0.0004, diversity=1.0531, num_succ=0, num_remain=80\n",
      " 100-th evaluation: score=0.5279, divergence=0.0012, diversity=1.0534, num_succ=0, num_remain=36\n",
      " 200-th evaluation: score=0.5282, divergence=0.0014, diversity=1.0535, num_succ=0, num_remain=30\n",
      " 300-th evaluation: score=0.5284, divergence=0.0016, diversity=1.0536, num_succ=0, num_remain=29\n",
      " 400-th evaluation: score=0.5287, divergence=0.0018, diversity=1.0537, num_succ=0, num_remain=29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 500-th evaluation: score=0.5290, divergence=0.0021, diversity=1.0538, num_succ=0, num_remain=28\n",
      " 600-th evaluation: score=0.5291, divergence=0.0022, diversity=1.0539, num_succ=0, num_remain=32\n",
      " 700-th evaluation: score=0.5294, divergence=0.0023, diversity=1.0540, num_succ=0, num_remain=28\n",
      " 800-th evaluation: score=0.5296, divergence=0.0026, diversity=1.0541, num_succ=0, num_remain=30\n",
      " 900-th evaluation: score=0.5300, divergence=0.0029, diversity=1.0542, num_succ=0, num_remain=30\n",
      "evaluating inputs\n",
      "parent_sim: 0.0780 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.1938 gap=0.1159 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.6377 gap=0.5597 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.3090 gap=0.2310 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.7519 gap=0.6740 train(resnet18,Flower102)-\n",
      "ref_sim: 0.3242 gap=0.2462 train(resnet18,SDog120)-\n",
      "ref_sim: 0.3447 gap=0.2668 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.3744 gap=0.2964 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.3983 gap=0.3203 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.1439 gap=0.0660 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.1331 gap=0.0551 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.3235 gap=0.2455 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.5619 gap=0.4840 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.4460 gap=0.3681 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.7221 gap=0.6441 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.4889 gap=0.4109 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.3549 gap=0.2769 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.1746 gap=0.0966 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.5277 gap=0.4497 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.4578 gap=0.3798 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.6239 gap=0.5460 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.1577 gap=0.0797 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.1427 gap=0.0647 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.1226 gap=0.0446 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.1537 gap=0.0757 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.1696 gap=0.0916 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.1890 gap=0.1110 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2211 gap=0.1432 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.1639 gap=0.0859 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.1887 gap=0.1107 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.4845 gap=0.4065 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.5259 gap=0.4479 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.5447 gap=0.4667 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.3278 gap=0.2498 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.6266 gap=0.5486 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.3859 gap=0.3079 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.5787 gap=0.5007 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4953 gap=0.4173 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.5917 gap=0.5137 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.7231 gap=0.6451 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5012 gap=0.4232 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6861 gap=0.6082 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.5731 gap=0.4952 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.2216 gap=0.1437 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.3262 gap=0.2482 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.4470 gap=0.3690 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5708 gap=0.4928 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3541 gap=0.2762 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.6058 gap=0.5278 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.5501 gap=0.4722 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.5330 gap=0.4551 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3187 gap=0.2407 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.2513 gap=0.1733 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4047 gap=0.3267 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.7572 gap=0.6792 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.7400 gap=0.6620 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.7102 gap=0.6322 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3442 gap=0.2663 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.2906 gap=0.2127 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.2779 gap=0.1999 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.7649 gap=0.6869 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.4770 gap=0.3991 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.8409 gap=0.7630 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.5655 gap=0.4875 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.5489 gap=0.4710 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.7847 gap=0.7067 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5748 gap=0.4968 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.2609 gap=0.1829 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.5935 gap=0.5155 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8268 gap=0.7488 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5450 gap=0.4670 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.4060 gap=0.3280 train(resnet18,SDog120)-steal(resnet18)-\n",
      "78\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "initial_evaluation: score=0.6498, divergence=0.0000, diversity=1.2996, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6498, divergence=0.0000, diversity=1.2996, num_succ=0, num_remain=85\n",
      " 100-th evaluation: score=0.6500, divergence=0.0002, diversity=1.2997, num_succ=0, num_remain=63\n",
      " 200-th evaluation: score=0.6502, divergence=0.0003, diversity=1.2998, num_succ=0, num_remain=56\n",
      " 300-th evaluation: score=0.6503, divergence=0.0004, diversity=1.2999, num_succ=0, num_remain=56\n",
      " 400-th evaluation: score=0.6505, divergence=0.0005, diversity=1.3000, num_succ=0, num_remain=54\n",
      " 500-th evaluation: score=0.6506, divergence=0.0006, diversity=1.3000, num_succ=0, num_remain=59\n",
      " 600-th evaluation: score=0.6507, divergence=0.0007, diversity=1.3001, num_succ=0, num_remain=49\n",
      " 700-th evaluation: score=0.6508, divergence=0.0007, diversity=1.3002, num_succ=0, num_remain=59\n",
      " 800-th evaluation: score=0.6509, divergence=0.0008, diversity=1.3003, num_succ=0, num_remain=48\n",
      " 900-th evaluation: score=0.6511, divergence=0.0009, diversity=1.3003, num_succ=0, num_remain=53\n",
      "evaluating inputs\n",
      "parent_sim: 0.1985 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.2727 gap=0.0742 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.4868 gap=0.2883 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.5596 gap=0.3611 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.7117 gap=0.5132 train(resnet18,Flower102)-\n",
      "ref_sim: 0.4908 gap=0.2924 train(resnet18,SDog120)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1733 gap=-0.0252 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\u001b[0m\n",
      "ref_sim: 0.2796 gap=0.0812 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.2652 gap=0.0667 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.3806 gap=0.1821 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.5741 gap=0.3756 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.3151 gap=0.1166 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1645 gap=-0.0340 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1958 gap=-0.0027 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.2263 gap=0.0278 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.2901 gap=0.0916 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.3165 gap=0.1180 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.3973 gap=0.1988 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2224 gap=0.0239 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.2008 gap=0.0023 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.3071 gap=0.1086 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.2582 gap=0.0597 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.2793 gap=0.0808 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.3062 gap=0.1077 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1871 gap=-0.0114 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\u001b[0m\n",
      "ref_sim: 0.2993 gap=0.1008 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4013 gap=0.2028 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1778 gap=-0.0207 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1982 gap=-0.0002 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\u001b[0m\n",
      "ref_sim: 0.2081 gap=0.0096 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.2766 gap=0.0781 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.5060 gap=0.3075 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.4740 gap=0.2755 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1313 gap=-0.0672 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\u001b[0m\n",
      "ref_sim: 0.6161 gap=0.4176 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.6294 gap=0.4309 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.7804 gap=0.5819 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6459 gap=0.4474 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.6732 gap=0.4747 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.6812 gap=0.4828 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.6299 gap=0.4314 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6651 gap=0.4667 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.6097 gap=0.4112 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6148 gap=0.4163 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.8619 gap=0.6634 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.6812 gap=0.4827 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.7905 gap=0.5920 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6502 gap=0.4517 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.4975 gap=0.2990 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.5568 gap=0.3583 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.4418 gap=0.2433 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.5576 gap=0.3591 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.5248 gap=0.3263 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.6098 gap=0.4113 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.7442 gap=0.5457 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.7002 gap=0.5017 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.6843 gap=0.4858 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.4935 gap=0.2950 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4867 gap=0.2882 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.6419 gap=0.4434 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.2227 gap=0.0242 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.6210 gap=0.4225 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.6982 gap=0.4997 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.7432 gap=0.5447 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.6654 gap=0.4669 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.7335 gap=0.5350 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5945 gap=0.3960 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6378 gap=0.4393 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.5993 gap=0.4008 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.7981 gap=0.5996 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.7345 gap=0.5360 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6367 gap=0.4382 train(resnet18,SDog120)-steal(resnet18)-\n",
      "79\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "initial_evaluation: score=0.6456, divergence=0.0000, diversity=1.2911, num_succ=0, num_remain=7\n",
      "   0-th evaluation: score=0.6456, divergence=0.0001, diversity=1.2911, num_succ=0, num_remain=89\n",
      " 100-th evaluation: score=0.6458, divergence=0.0002, diversity=1.2912, num_succ=0, num_remain=58\n",
      " 200-th evaluation: score=0.6459, divergence=0.0003, diversity=1.2912, num_succ=0, num_remain=48\n",
      " 300-th evaluation: score=0.6460, divergence=0.0003, diversity=1.2913, num_succ=0, num_remain=50\n",
      " 400-th evaluation: score=0.6460, divergence=0.0004, diversity=1.2913, num_succ=0, num_remain=49\n",
      " 500-th evaluation: score=0.6461, divergence=0.0004, diversity=1.2914, num_succ=0, num_remain=46\n",
      " 600-th evaluation: score=0.6462, divergence=0.0005, diversity=1.2914, num_succ=0, num_remain=55\n",
      " 700-th evaluation: score=0.6463, divergence=0.0005, diversity=1.2915, num_succ=0, num_remain=48\n",
      " 800-th evaluation: score=0.6464, divergence=0.0006, diversity=1.2916, num_succ=0, num_remain=56\n",
      " 900-th evaluation: score=0.6465, divergence=0.0007, diversity=1.2916, num_succ=0, num_remain=51\n",
      "evaluating inputs\n",
      "parent_sim: 0.7388 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.9008 gap=0.1620 pretrain(resnet18,ImageNet)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.7215 gap=-0.0173 train(mbnetv2,Flower102)-\u001b[0m\n",
      "ref_sim: 0.9331 gap=0.1943 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.9789 gap=0.2401 train(resnet18,Flower102)-\n",
      "ref_sim: 0.9792 gap=0.2404 train(resnet18,SDog120)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.6950 gap=-0.0438 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\u001b[0m\n",
      "ref_sim: 0.8736 gap=0.1348 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.8450 gap=0.1062 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.8691 gap=0.1303 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.8869 gap=0.1481 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.8861 gap=0.1473 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.8478 gap=0.1090 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.8583 gap=0.1195 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.8277 gap=0.0889 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.7814 gap=0.0426 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.8062 gap=0.0674 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.8728 gap=0.1340 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.8358 gap=0.0970 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.8296 gap=0.0908 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.8713 gap=0.1325 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.8781 gap=0.1393 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.8641 gap=0.1253 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.8735 gap=0.1346 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.8887 gap=0.1499 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.8797 gap=0.1409 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.8770 gap=0.1382 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.8872 gap=0.1484 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.8707 gap=0.1319 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.8646 gap=0.1258 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.7882 gap=0.0494 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.8257 gap=0.0869 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.8872 gap=0.1484 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.9238 gap=0.1850 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.9077 gap=0.1689 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.8895 gap=0.1507 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "\u001b[93m[ERROR] ref_sim: 0.5076 gap=-0.2312 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\u001b[0m\n",
      "ref_sim: 0.9248 gap=0.1860 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.7133 gap=-0.0255 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\u001b[0m\n",
      "ref_sim: 0.8945 gap=0.1557 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.7269 gap=-0.0119 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\u001b[0m\n",
      "ref_sim: 0.9100 gap=0.1712 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.9417 gap=0.2029 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.9079 gap=0.1691 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.9766 gap=0.2378 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.9614 gap=0.2226 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.8807 gap=0.1419 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.9654 gap=0.2266 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.7666 gap=0.0277 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8824 gap=0.1436 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.8760 gap=0.1372 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.9329 gap=0.1941 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.9496 gap=0.2108 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.9226 gap=0.1838 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.9749 gap=0.2361 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.9763 gap=0.2375 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.9811 gap=0.2423 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.9808 gap=0.2420 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.9832 gap=0.2443 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.9851 gap=0.2463 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.7987 gap=0.0599 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.9530 gap=0.2142 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.9697 gap=0.2309 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.9833 gap=0.2444 train(resnet18,SDog120)-distill()-\n",
      "\u001b[93m[ERROR] ref_sim: 0.6906 gap=-0.0482 train(mbnetv2,Flower102)-steal(mbnetv2)-\u001b[0m\n",
      "ref_sim: 0.9621 gap=0.2233 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.9359 gap=0.1971 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.9810 gap=0.2422 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.8352 gap=0.0964 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.9752 gap=0.2364 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.9683 gap=0.2295 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.9647 gap=0.2259 train(resnet18,SDog120)-steal(resnet18)-\n",
      "80\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "initial_evaluation: score=0.6418, divergence=0.0000, diversity=1.2836, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6418, divergence=0.0000, diversity=1.2836, num_succ=0, num_remain=84\n",
      " 100-th evaluation: score=0.6420, divergence=0.0001, diversity=1.2836, num_succ=0, num_remain=52\n",
      " 200-th evaluation: score=0.6420, divergence=0.0002, diversity=1.2837, num_succ=0, num_remain=52\n",
      " 300-th evaluation: score=0.6421, divergence=0.0003, diversity=1.2837, num_succ=0, num_remain=49\n",
      " 400-th evaluation: score=0.6422, divergence=0.0003, diversity=1.2838, num_succ=0, num_remain=46\n",
      " 500-th evaluation: score=0.6423, divergence=0.0004, diversity=1.2838, num_succ=0, num_remain=52\n",
      " 600-th evaluation: score=0.6424, divergence=0.0004, diversity=1.2839, num_succ=0, num_remain=45\n",
      " 700-th evaluation: score=0.6425, divergence=0.0005, diversity=1.2839, num_succ=0, num_remain=55\n",
      " 800-th evaluation: score=0.6425, divergence=0.0005, diversity=1.2840, num_succ=0, num_remain=59\n",
      " 900-th evaluation: score=0.6426, divergence=0.0006, diversity=1.2840, num_succ=0, num_remain=47\n",
      "evaluating inputs\n",
      "parent_sim: 0.0620 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.3036 gap=0.2416 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.2890 gap=0.2270 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.7380 gap=0.6760 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.8702 gap=0.8082 train(resnet18,Flower102)-\n",
      "ref_sim: 0.8697 gap=0.8077 train(resnet18,SDog120)-\n",
      "ref_sim: 0.3656 gap=0.3036 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.3817 gap=0.3197 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.2102 gap=0.1483 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.2306 gap=0.1686 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.4618 gap=0.3998 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.5390 gap=0.4771 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.6064 gap=0.5444 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.5160 gap=0.4541 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.5026 gap=0.4407 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.4965 gap=0.4345 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.5044 gap=0.4424 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.2387 gap=0.1767 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.1289 gap=0.0670 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.1137 gap=0.0517 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.1254 gap=0.0634 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.4301 gap=0.3681 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.2902 gap=0.2282 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4052 gap=0.3432 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.5336 gap=0.4716 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.4043 gap=0.3423 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.5858 gap=0.5238 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.4488 gap=0.3868 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.4602 gap=0.3982 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.7169 gap=0.6549 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.3980 gap=0.3360 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.4407 gap=0.3787 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.6347 gap=0.5727 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.6534 gap=0.5914 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.8174 gap=0.7554 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.9028 gap=0.8408 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.3741 gap=0.3122 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.9017 gap=0.8397 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.7382 gap=0.6763 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.8235 gap=0.7615 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5670 gap=0.5051 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8687 gap=0.8067 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.8164 gap=0.7545 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.7643 gap=0.7023 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.9488 gap=0.8869 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.8885 gap=0.8265 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.9538 gap=0.8918 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8679 gap=0.8059 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.2125 gap=0.1505 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.2945 gap=0.2325 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.4522 gap=0.3902 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.8363 gap=0.7743 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.8388 gap=0.7769 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.8331 gap=0.7711 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8500 gap=0.7880 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8567 gap=0.7947 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.7603 gap=0.6983 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.8403 gap=0.7783 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.8559 gap=0.7939 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.8646 gap=0.8026 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.1162 gap=0.0542 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.7927 gap=0.7308 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.7986 gap=0.7366 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.9349 gap=0.8729 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.7881 gap=0.7262 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.9443 gap=0.8824 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.9451 gap=0.8831 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.8273 gap=0.7654 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.7112 gap=0.6493 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.9271 gap=0.8651 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.8253 gap=0.7634 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.8240 gap=0.7620 train(resnet18,SDog120)-steal(resnet18)-\n",
      "81\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "initial_evaluation: score=0.4710, divergence=0.0000, diversity=0.9421, num_succ=0, num_remain=7\n",
      "   0-th evaluation: score=0.4715, divergence=0.0004, diversity=0.9423, num_succ=0, num_remain=87\n",
      " 100-th evaluation: score=0.4728, divergence=0.0014, diversity=0.9427, num_succ=1, num_remain=50\n",
      " 200-th evaluation: score=0.4733, divergence=0.0018, diversity=0.9429, num_succ=1, num_remain=40\n",
      " 300-th evaluation: score=0.4738, divergence=0.0022, diversity=0.9432, num_succ=1, num_remain=35\n",
      " 400-th evaluation: score=0.4743, divergence=0.0025, diversity=0.9435, num_succ=1, num_remain=35\n",
      " 500-th evaluation: score=0.4748, divergence=0.0029, diversity=0.9438, num_succ=1, num_remain=31\n",
      " 600-th evaluation: score=0.4752, divergence=0.0031, diversity=0.9441, num_succ=1, num_remain=34\n",
      " 700-th evaluation: score=0.4757, divergence=0.0035, diversity=0.9445, num_succ=1, num_remain=36\n",
      " 800-th evaluation: score=0.4760, divergence=0.0037, diversity=0.9446, num_succ=1, num_remain=38\n",
      " 900-th evaluation: score=0.4764, divergence=0.0040, diversity=0.9447, num_succ=1, num_remain=35\n",
      "evaluating inputs\n",
      "parent_sim: 0.3716 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0197 gap=-0.3520 pretrain(resnet18,ImageNet)-\u001b[0m\n",
      "ref_sim: 0.5504 gap=0.1787 train(mbnetv2,Flower102)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0137 gap=-0.3579 train(mbnetv2,SDog120)-\u001b[0m\n",
      "ref_sim: 0.6866 gap=0.3149 train(resnet18,Flower102)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0195 gap=-0.3522 train(resnet18,SDog120)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0255 gap=-0.3461 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0147 gap=-0.3569 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0145 gap=-0.3572 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0199 gap=-0.3517 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0288 gap=-0.3428 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0213 gap=-0.3503 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0184 gap=-0.3533 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0139 gap=-0.3578 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0202 gap=-0.3515 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0165 gap=-0.3552 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0177 gap=-0.3540 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0155 gap=-0.3561 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0189 gap=-0.3527 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0192 gap=-0.3524 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0142 gap=-0.3575 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0147 gap=-0.3569 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0216 gap=-0.3501 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0129 gap=-0.3588 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0146 gap=-0.3571 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0124 gap=-0.3592 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0255 gap=-0.3461 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0140 gap=-0.3576 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0137 gap=-0.3579 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0415 gap=-0.3301 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0244 gap=-0.3473 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0469 gap=-0.3247 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0484 gap=-0.3232 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0157 gap=-0.3559 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0081 gap=-0.3636 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0235 gap=-0.3482 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\u001b[0m\n",
      "ref_sim: 0.5018 gap=0.1301 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5583 gap=0.1867 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1149 gap=-0.2567 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\u001b[0m\n",
      "ref_sim: 0.6278 gap=0.2562 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5608 gap=0.1891 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6080 gap=0.2363 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0276 gap=-0.3440 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0142 gap=-0.3575 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.6358 gap=0.2642 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0401 gap=-0.3315 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.5363 gap=0.1646 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2728 gap=-0.0988 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.6048 gap=0.2332 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8360 gap=0.4643 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.7316 gap=0.3599 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0107 gap=-0.3609 train(mbnetv2,SDog120)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0189 gap=-0.3527 train(mbnetv2,SDog120)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0295 gap=-0.3422 train(mbnetv2,SDog120)-prune(0.8)-\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.7386 gap=0.3669 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.6940 gap=0.3223 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.7540 gap=0.3823 train(resnet18,Flower102)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0296 gap=-0.3421 train(resnet18,SDog120)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0396 gap=-0.3321 train(resnet18,SDog120)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0399 gap=-0.3318 train(resnet18,SDog120)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.8090 gap=0.4374 train(mbnetv2,Flower102)-distill()-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0215 gap=-0.3502 train(mbnetv2,SDog120)-distill()-\u001b[0m\n",
      "ref_sim: 0.8424 gap=0.4707 train(resnet18,Flower102)-distill()-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0414 gap=-0.3302 train(resnet18,SDog120)-distill()-\u001b[0m\n",
      "ref_sim: 0.5535 gap=0.1818 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.9282 gap=0.5565 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0205 gap=-0.3511 train(mbnetv2,SDog120)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0767 gap=-0.2950 train(mbnetv2,SDog120)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.4393 gap=0.0676 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.6678 gap=0.2962 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6149 gap=0.2432 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.0236 gap=-0.3481 train(resnet18,SDog120)-steal(resnet18)-\u001b[0m\n",
      "82\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "initial_evaluation: score=0.4729, divergence=0.0000, diversity=0.9458, num_succ=0, num_remain=6\n",
      "   0-th evaluation: score=0.4731, divergence=0.0002, diversity=0.9458, num_succ=0, num_remain=83\n",
      " 100-th evaluation: score=0.4742, divergence=0.0011, diversity=0.9462, num_succ=0, num_remain=45\n",
      " 200-th evaluation: score=0.4749, divergence=0.0016, diversity=0.9465, num_succ=0, num_remain=35\n",
      " 300-th evaluation: score=0.4753, divergence=0.0019, diversity=0.9468, num_succ=0, num_remain=36\n",
      " 400-th evaluation: score=0.4758, divergence=0.0022, diversity=0.9470, num_succ=0, num_remain=34\n",
      " 500-th evaluation: score=0.4762, divergence=0.0026, diversity=0.9473, num_succ=0, num_remain=33\n",
      " 600-th evaluation: score=0.4768, divergence=0.0030, diversity=0.9476, num_succ=0, num_remain=30\n",
      " 700-th evaluation: score=0.4773, divergence=0.0034, diversity=0.9477, num_succ=0, num_remain=36\n",
      " 800-th evaluation: score=0.4777, divergence=0.0037, diversity=0.9480, num_succ=0, num_remain=30\n",
      " 900-th evaluation: score=0.4780, divergence=0.0039, diversity=0.9482, num_succ=0, num_remain=37\n",
      "evaluating inputs\n",
      "parent_sim: 0.3712 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.4879 gap=0.1167 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.8013 gap=0.4301 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.5640 gap=0.1929 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.8371 gap=0.4660 train(resnet18,Flower102)-\n",
      "ref_sim: 0.5293 gap=0.1582 train(resnet18,SDog120)-\n",
      "ref_sim: 0.4741 gap=0.1030 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.6658 gap=0.2946 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.7142 gap=0.3430 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.4000 gap=0.0288 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.3479 gap=-0.0232 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\u001b[0m\n",
      "ref_sim: 0.3908 gap=0.0196 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.6708 gap=0.2996 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.7255 gap=0.3543 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.7211 gap=0.3500 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.7610 gap=0.3898 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.7286 gap=0.3574 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.7375 gap=0.3664 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.8025 gap=0.4313 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.8037 gap=0.4326 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.7928 gap=0.4217 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.4037 gap=0.0326 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.3925 gap=0.0213 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4971 gap=0.1259 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.4014 gap=0.0302 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.4083 gap=0.0371 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4844 gap=0.1132 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.5068 gap=0.1356 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.5122 gap=0.1410 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.4521 gap=0.0809 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.6126 gap=0.2414 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.6794 gap=0.3082 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.7076 gap=0.3364 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "\u001b[93m[ERROR] ref_sim: 0.3027 gap=-0.0685 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2160 gap=-0.1552 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3699 gap=-0.0013 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\u001b[0m\n",
      "ref_sim: 0.7629 gap=0.3917 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.7258 gap=0.3546 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.7811 gap=0.4099 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.8230 gap=0.4518 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.6606 gap=0.2894 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8984 gap=0.5272 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.3832 gap=0.0120 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1935 gap=-0.1777 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.3775 gap=0.0063 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.4751 gap=0.1039 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.3614 gap=-0.0097 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\u001b[0m\n",
      "ref_sim: 0.4106 gap=0.0395 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.7283 gap=0.3571 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.6658 gap=0.2946 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.6959 gap=0.3247 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.6120 gap=0.2409 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.6305 gap=0.2594 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.6172 gap=0.2461 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8497 gap=0.4785 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8439 gap=0.4728 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.8199 gap=0.4487 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.5482 gap=0.1770 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.5559 gap=0.1848 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.5537 gap=0.1826 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.7037 gap=0.3325 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.6379 gap=0.2668 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.9127 gap=0.5415 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.4085 gap=0.0373 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.8070 gap=0.4358 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8617 gap=0.4905 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6927 gap=0.3215 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5850 gap=0.2138 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.7607 gap=0.3895 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8690 gap=0.4978 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.4238 gap=0.0526 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.4589 gap=0.0877 train(resnet18,SDog120)-steal(resnet18)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "initial_evaluation: score=0.4540, divergence=0.0000, diversity=0.9080, num_succ=0, num_remain=9\n",
      "   0-th evaluation: score=0.4543, divergence=0.0003, diversity=0.9080, num_succ=0, num_remain=84\n",
      " 100-th evaluation: score=0.4554, divergence=0.0012, diversity=0.9083, num_succ=1, num_remain=42\n",
      " 200-th evaluation: score=0.4558, divergence=0.0015, diversity=0.9085, num_succ=1, num_remain=44\n",
      " 300-th evaluation: score=0.4563, divergence=0.0019, diversity=0.9087, num_succ=2, num_remain=39\n",
      " 400-th evaluation: score=0.4567, divergence=0.0023, diversity=0.9090, num_succ=2, num_remain=34\n",
      " 500-th evaluation: score=0.4571, divergence=0.0025, diversity=0.9091, num_succ=2, num_remain=43\n",
      " 600-th evaluation: score=0.4576, divergence=0.0029, diversity=0.9093, num_succ=2, num_remain=33\n",
      " 700-th evaluation: score=0.4581, divergence=0.0033, diversity=0.9096, num_succ=2, num_remain=40\n",
      " 800-th evaluation: score=0.4586, divergence=0.0037, diversity=0.9098, num_succ=2, num_remain=30\n",
      " 900-th evaluation: score=0.4589, divergence=0.0039, diversity=0.9099, num_succ=2, num_remain=35\n",
      "evaluating inputs\n",
      "parent_sim: 0.5704 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.5037 gap=-0.0667 pretrain(resnet18,ImageNet)-\u001b[0m\n",
      "ref_sim: 0.5823 gap=0.0119 train(mbnetv2,Flower102)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.3353 gap=-0.2351 train(mbnetv2,SDog120)-\u001b[0m\n",
      "ref_sim: 0.6655 gap=0.0951 train(resnet18,Flower102)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.5079 gap=-0.0625 train(resnet18,SDog120)-\u001b[0m\n",
      "ref_sim: 0.5815 gap=0.0111 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.6372 gap=0.0668 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.6521 gap=0.0817 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4443 gap=-0.1261 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4476 gap=-0.1228 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5121 gap=-0.0583 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\u001b[0m\n",
      "ref_sim: 0.6256 gap=0.0552 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.6576 gap=0.0872 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.7086 gap=0.1382 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.6354 gap=0.0650 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.6539 gap=0.0835 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.7101 gap=0.1397 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.6379 gap=0.0675 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.6528 gap=0.0824 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.7158 gap=0.1454 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4571 gap=-0.1133 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4656 gap=-0.1048 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5124 gap=-0.0580 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4318 gap=-0.1386 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4497 gap=-0.1207 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5189 gap=-0.0515 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4759 gap=-0.0945 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4622 gap=-0.1082 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4951 gap=-0.0753 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.6575 gap=0.0871 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.6365 gap=0.0661 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.6152 gap=0.0448 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4577 gap=-0.1127 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5378 gap=-0.0326 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5072 gap=-0.0632 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\u001b[0m\n",
      "ref_sim: 0.6424 gap=0.0720 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8205 gap=0.2501 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.7131 gap=0.1427 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.6832 gap=0.1128 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5789 gap=0.0085 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6959 gap=0.1255 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4670 gap=-0.1034 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3672 gap=-0.2032 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5559 gap=-0.0145 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4643 gap=-0.1061 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4473 gap=-0.1231 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4189 gap=-0.1515 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5366 gap=-0.0338 train(mbnetv2,Flower102)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5524 gap=-0.0180 train(mbnetv2,Flower102)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5528 gap=-0.0176 train(mbnetv2,Flower102)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4134 gap=-0.1570 train(mbnetv2,SDog120)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4154 gap=-0.1550 train(mbnetv2,SDog120)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3586 gap=-0.2118 train(mbnetv2,SDog120)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.6743 gap=0.1039 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.6649 gap=0.0945 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.6828 gap=0.1124 train(resnet18,Flower102)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.5165 gap=-0.0539 train(resnet18,SDog120)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5080 gap=-0.0624 train(resnet18,SDog120)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5460 gap=-0.0244 train(resnet18,SDog120)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.5729 gap=0.0025 train(mbnetv2,Flower102)-distill()-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2161 gap=-0.3543 train(mbnetv2,SDog120)-distill()-\u001b[0m\n",
      "ref_sim: 0.6949 gap=0.1245 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.5785 gap=0.0081 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.6511 gap=0.0807 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8314 gap=0.2610 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4739 gap=-0.0965 train(mbnetv2,SDog120)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4788 gap=-0.0916 train(mbnetv2,SDog120)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.5989 gap=0.0285 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.7366 gap=0.1662 train(resnet18,Flower102)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2587 gap=-0.3117 train(resnet18,SDog120)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4485 gap=-0.1219 train(resnet18,SDog120)-steal(resnet18)-\u001b[0m\n",
      "84\t generating inputs for pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "initial_evaluation: score=0.6136, divergence=0.0000, diversity=1.2272, num_succ=0, num_remain=6\n",
      "   0-th evaluation: score=0.6140, divergence=0.0004, diversity=1.2272, num_succ=0, num_remain=91\n",
      " 100-th evaluation: score=0.6145, divergence=0.0007, diversity=1.2275, num_succ=0, num_remain=60\n",
      " 200-th evaluation: score=0.6147, divergence=0.0009, diversity=1.2277, num_succ=0, num_remain=53\n",
      " 300-th evaluation: score=0.6149, divergence=0.0010, diversity=1.2278, num_succ=0, num_remain=49\n",
      " 400-th evaluation: score=0.6150, divergence=0.0011, diversity=1.2279, num_succ=0, num_remain=49\n",
      " 500-th evaluation: score=0.6152, divergence=0.0012, diversity=1.2280, num_succ=0, num_remain=40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 600-th evaluation: score=0.6153, divergence=0.0013, diversity=1.2280, num_succ=0, num_remain=46\n",
      " 700-th evaluation: score=0.6154, divergence=0.0014, diversity=1.2281, num_succ=0, num_remain=43\n",
      " 800-th evaluation: score=0.6155, divergence=0.0015, diversity=1.2282, num_succ=0, num_remain=35\n",
      " 900-th evaluation: score=0.6157, divergence=0.0015, diversity=1.2282, num_succ=0, num_remain=32\n",
      "evaluating inputs\n",
      "parent_sim: 0.1011 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.2346 gap=0.1335 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.4471 gap=0.3460 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.3859 gap=0.2848 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.4582 gap=0.3571 train(resnet18,Flower102)-\n",
      "ref_sim: 0.3574 gap=0.2563 train(resnet18,SDog120)-\n",
      "ref_sim: 0.2876 gap=0.1865 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.2825 gap=0.1814 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.2918 gap=0.1907 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.3671 gap=0.2660 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.3307 gap=0.2296 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.4821 gap=0.3810 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.2378 gap=0.1367 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.1895 gap=0.0884 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.1956 gap=0.0945 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3653 gap=0.2642 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.2585 gap=0.1574 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.5269 gap=0.4258 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.3551 gap=0.2540 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.3430 gap=0.2419 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.3423 gap=0.2412 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.3016 gap=0.2005 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.3862 gap=0.2851 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.5666 gap=0.4655 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3476 gap=0.2465 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.4185 gap=0.3174 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.3758 gap=0.2747 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.4758 gap=0.3747 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.3535 gap=0.2524 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.5208 gap=0.4197 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.4824 gap=0.3813 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.4161 gap=0.3150 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.5573 gap=0.4562 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.5789 gap=0.4778 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.5589 gap=0.4578 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.5799 gap=0.4788 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.5585 gap=0.4574 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5085 gap=0.4074 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.5325 gap=0.4314 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.4880 gap=0.3869 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5037 gap=0.4026 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4535 gap=0.3524 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.4822 gap=0.3811 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3887 gap=0.2876 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.5893 gap=0.4882 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.2770 gap=0.1759 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.4901 gap=0.3890 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4564 gap=0.3553 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.4191 gap=0.3180 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.4859 gap=0.3848 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.3358 gap=0.2347 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3524 gap=0.2513 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4179 gap=0.3168 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.5308 gap=0.4297 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.4489 gap=0.3478 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.4469 gap=0.3458 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.4356 gap=0.3345 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3658 gap=0.2647 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.3484 gap=0.2473 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.3709 gap=0.2698 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.5268 gap=0.4257 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.3926 gap=0.2915 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.4071 gap=0.3060 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.4229 gap=0.3218 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.6573 gap=0.5562 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.4150 gap=0.3139 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.4438 gap=0.3427 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.4120 gap=0.3109 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.6727 gap=0.5716 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.4529 gap=0.3518 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6394 gap=0.5383 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.4158 gap=0.3147 train(resnet18,SDog120)-steal(resnet18)-\n",
      "85\t generating inputs for pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "initial_evaluation: score=0.6674, divergence=0.0000, diversity=1.3348, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6674, divergence=0.0001, diversity=1.3348, num_succ=0, num_remain=86\n",
      " 100-th evaluation: score=0.6675, divergence=0.0001, diversity=1.3348, num_succ=0, num_remain=59\n",
      " 200-th evaluation: score=0.6676, divergence=0.0002, diversity=1.3348, num_succ=0, num_remain=50\n",
      " 300-th evaluation: score=0.6676, divergence=0.0002, diversity=1.3349, num_succ=0, num_remain=43\n",
      " 400-th evaluation: score=0.6677, divergence=0.0002, diversity=1.3349, num_succ=0, num_remain=42\n",
      " 500-th evaluation: score=0.6677, divergence=0.0003, diversity=1.3349, num_succ=0, num_remain=32\n",
      " 600-th evaluation: score=0.6677, divergence=0.0003, diversity=1.3349, num_succ=0, num_remain=30\n",
      " 700-th evaluation: score=0.6677, divergence=0.0003, diversity=1.3349, num_succ=0, num_remain=33\n",
      " 800-th evaluation: score=0.6678, divergence=0.0003, diversity=1.3349, num_succ=0, num_remain=37\n",
      " 900-th evaluation: score=0.6678, divergence=0.0003, diversity=1.3349, num_succ=0, num_remain=40\n",
      "evaluating inputs\n",
      "parent_sim: 0.1220 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.3795 gap=0.2574 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.5412 gap=0.4192 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.2295 gap=0.1075 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.6376 gap=0.5156 train(resnet18,Flower102)-\n",
      "ref_sim: 0.6447 gap=0.5227 train(resnet18,SDog120)-\n",
      "ref_sim: 0.4873 gap=0.3653 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.4540 gap=0.3320 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.4699 gap=0.3479 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.3546 gap=0.2326 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.3540 gap=0.2320 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.4386 gap=0.3166 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.4276 gap=0.3056 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.4459 gap=0.3239 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4915 gap=0.3695 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.4934 gap=0.3714 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.5084 gap=0.3864 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4618 gap=0.3398 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.5066 gap=0.3846 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.5386 gap=0.4166 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.4340 gap=0.3120 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.3679 gap=0.2459 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.3566 gap=0.2346 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4142 gap=0.2922 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3158 gap=0.1938 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.3483 gap=0.2263 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.5960 gap=0.4740 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2991 gap=0.1771 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.4743 gap=0.3523 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.6301 gap=0.5081 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.4468 gap=0.3248 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.5961 gap=0.4741 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.5629 gap=0.4409 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.5654 gap=0.4433 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.3941 gap=0.2721 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.6061 gap=0.4841 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.3525 gap=0.2305 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3046 gap=0.1826 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.4811 gap=0.3591 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.5127 gap=0.3907 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5174 gap=0.3954 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3929 gap=0.2709 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.2816 gap=0.1596 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3703 gap=0.2483 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.5729 gap=0.4508 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.2880 gap=0.1660 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.4412 gap=0.3192 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3589 gap=0.2369 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.4051 gap=0.2831 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.5771 gap=0.4551 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.5658 gap=0.4438 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3318 gap=0.2097 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.2687 gap=0.1467 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.2960 gap=0.1740 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.6700 gap=0.5479 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.6540 gap=0.5320 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.6615 gap=0.5395 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.5406 gap=0.4185 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.5349 gap=0.4129 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.5176 gap=0.3956 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.4070 gap=0.2850 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.3793 gap=0.2573 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.7320 gap=0.6100 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.6007 gap=0.4787 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.5228 gap=0.4008 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.6218 gap=0.4998 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6088 gap=0.4868 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5423 gap=0.4203 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.4642 gap=0.3422 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.6687 gap=0.5467 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.4047 gap=0.2827 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.4827 gap=0.3607 train(resnet18,SDog120)-steal(resnet18)-\n",
      "86\t generating inputs for pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "initial_evaluation: score=0.6688, divergence=0.0000, diversity=1.3376, num_succ=0, num_remain=9\n",
      "   0-th evaluation: score=0.6689, divergence=0.0001, diversity=1.3376, num_succ=0, num_remain=90\n",
      " 100-th evaluation: score=0.6690, divergence=0.0002, diversity=1.3376, num_succ=0, num_remain=68\n",
      " 200-th evaluation: score=0.6691, divergence=0.0003, diversity=1.3376, num_succ=0, num_remain=65\n",
      " 300-th evaluation: score=0.6691, divergence=0.0003, diversity=1.3377, num_succ=0, num_remain=60\n",
      " 400-th evaluation: score=0.6692, divergence=0.0003, diversity=1.3377, num_succ=0, num_remain=58\n",
      " 500-th evaluation: score=0.6692, divergence=0.0004, diversity=1.3377, num_succ=0, num_remain=57\n",
      " 600-th evaluation: score=0.6693, divergence=0.0004, diversity=1.3378, num_succ=0, num_remain=55\n",
      " 700-th evaluation: score=0.6693, divergence=0.0004, diversity=1.3378, num_succ=0, num_remain=53\n",
      " 800-th evaluation: score=0.6693, divergence=0.0004, diversity=1.3378, num_succ=0, num_remain=58\n",
      " 900-th evaluation: score=0.6694, divergence=0.0005, diversity=1.3378, num_succ=0, num_remain=63\n",
      "evaluating inputs\n",
      "parent_sim: 0.2020 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.4498 gap=0.2478 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.5032 gap=0.3012 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.4710 gap=0.2691 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.2421 gap=0.0401 train(resnet18,Flower102)-\n",
      "ref_sim: 0.2827 gap=0.0808 train(resnet18,SDog120)-\n",
      "ref_sim: 0.4061 gap=0.2041 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.3748 gap=0.1728 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.3764 gap=0.1744 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.3457 gap=0.1437 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.5913 gap=0.3893 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.4947 gap=0.2927 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.3595 gap=0.1575 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.3609 gap=0.1590 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4001 gap=0.1981 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3467 gap=0.1447 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.3449 gap=0.1430 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4618 gap=0.2598 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.3642 gap=0.1622 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.3967 gap=0.1947 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.3441 gap=0.1421 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.4802 gap=0.2782 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.5010 gap=0.2991 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.6204 gap=0.4184 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.4798 gap=0.2778 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.4960 gap=0.2940 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.5328 gap=0.3308 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.5708 gap=0.3688 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.4713 gap=0.2693 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.7067 gap=0.5048 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.2971 gap=0.0951 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.2948 gap=0.0928 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.5047 gap=0.3027 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.7699 gap=0.5680 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.6616 gap=0.4597 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.6188 gap=0.4168 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.4036 gap=0.2016 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3770 gap=0.1750 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.6014 gap=0.3994 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.3775 gap=0.1755 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.4837 gap=0.2818 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3284 gap=0.1264 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.5148 gap=0.3128 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5242 gap=0.3222 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.6664 gap=0.4645 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.4215 gap=0.2195 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5209 gap=0.3189 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4980 gap=0.2960 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.4492 gap=0.2472 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.3220 gap=0.1201 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.2833 gap=0.0813 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.4374 gap=0.2354 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4667 gap=0.2648 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4611 gap=0.2591 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.2572 gap=0.0553 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.2666 gap=0.0647 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.2405 gap=0.0385 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.3207 gap=0.1188 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.3201 gap=0.1182 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.3158 gap=0.1139 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.5595 gap=0.3576 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.4515 gap=0.2496 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.3391 gap=0.1372 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.3529 gap=0.1509 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.2446 gap=0.0427 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.3216 gap=0.1196 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6329 gap=0.4310 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6226 gap=0.4206 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.5191 gap=0.3172 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.4032 gap=0.2012 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5190 gap=0.3171 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6101 gap=0.4081 train(resnet18,SDog120)-steal(resnet18)-\n",
      "87\t generating inputs for pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "initial_evaluation: score=0.4810, divergence=0.0000, diversity=0.9619, num_succ=0, num_remain=7\n",
      "   0-th evaluation: score=0.4812, divergence=0.0002, diversity=0.9619, num_succ=0, num_remain=83\n",
      " 100-th evaluation: score=0.4819, divergence=0.0008, diversity=0.9621, num_succ=0, num_remain=42\n",
      " 200-th evaluation: score=0.4822, divergence=0.0011, diversity=0.9622, num_succ=0, num_remain=40\n",
      " 300-th evaluation: score=0.4824, divergence=0.0013, diversity=0.9623, num_succ=0, num_remain=33\n",
      " 400-th evaluation: score=0.4826, divergence=0.0014, diversity=0.9624, num_succ=0, num_remain=36\n",
      " 500-th evaluation: score=0.4828, divergence=0.0016, diversity=0.9625, num_succ=0, num_remain=33\n",
      " 600-th evaluation: score=0.4832, divergence=0.0019, diversity=0.9626, num_succ=0, num_remain=32\n",
      " 700-th evaluation: score=0.4834, divergence=0.0020, diversity=0.9627, num_succ=0, num_remain=29\n",
      " 800-th evaluation: score=0.4836, divergence=0.0022, diversity=0.9628, num_succ=0, num_remain=32\n",
      " 900-th evaluation: score=0.4838, divergence=0.0023, diversity=0.9629, num_succ=0, num_remain=34\n",
      "evaluating inputs\n",
      "parent_sim: 0.2018 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.3189 gap=0.1171 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.5445 gap=0.3427 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.4863 gap=0.2845 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.8498 gap=0.6479 train(resnet18,Flower102)-\n",
      "ref_sim: 0.7954 gap=0.5936 train(resnet18,SDog120)-\n",
      "ref_sim: 0.4718 gap=0.2700 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.3676 gap=0.1657 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.2830 gap=0.0812 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.3698 gap=0.1680 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.5413 gap=0.3395 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.4360 gap=0.2342 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.3974 gap=0.1956 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.3881 gap=0.1863 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1017 gap=-0.1001 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.3757 gap=0.1739 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.4100 gap=0.2082 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.6813 gap=0.4795 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.2691 gap=0.0673 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.2406 gap=0.0387 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.6350 gap=0.4332 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.4641 gap=0.2623 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.3517 gap=0.1499 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.3205 gap=0.1187 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.4871 gap=0.2853 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.4856 gap=0.2838 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.4695 gap=0.2677 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.4549 gap=0.2531 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.4199 gap=0.2181 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.4069 gap=0.2051 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.5469 gap=0.3451 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.4293 gap=0.2275 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.4517 gap=0.2499 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.6161 gap=0.4143 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.6171 gap=0.4153 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.6147 gap=0.4129 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.4775 gap=0.2757 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8358 gap=0.6340 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.7880 gap=0.5862 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.8321 gap=0.6303 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.7600 gap=0.5582 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8423 gap=0.6405 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.5603 gap=0.3585 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5027 gap=0.3009 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.9210 gap=0.7192 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.6786 gap=0.4768 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.4287 gap=0.2269 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.4343 gap=0.2325 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.6644 gap=0.4626 train(mbnetv2,Flower102)-prune(0.2)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.6629 gap=0.4611 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.7082 gap=0.5064 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.4851 gap=0.2833 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.4849 gap=0.2831 train(mbnetv2,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.4441 gap=0.2423 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.8558 gap=0.6540 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8519 gap=0.6501 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.8489 gap=0.6471 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.7898 gap=0.5880 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.8238 gap=0.6220 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.8077 gap=0.6059 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.6468 gap=0.4450 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.4558 gap=0.2540 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.8703 gap=0.6685 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.7354 gap=0.5336 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.7312 gap=0.5294 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8933 gap=0.6915 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6871 gap=0.4853 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6898 gap=0.4880 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "ref_sim: 0.6638 gap=0.4620 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.8778 gap=0.6760 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.5251 gap=0.3233 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.5981 gap=0.3963 train(resnet18,SDog120)-steal(resnet18)-\n",
      "88\t generating inputs for pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "initial_evaluation: score=0.5331, divergence=0.0000, diversity=1.0662, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.5333, divergence=0.0002, diversity=1.0662, num_succ=0, num_remain=87\n",
      " 100-th evaluation: score=0.5339, divergence=0.0007, diversity=1.0664, num_succ=0, num_remain=51\n",
      " 200-th evaluation: score=0.5342, divergence=0.0009, diversity=1.0665, num_succ=0, num_remain=49\n",
      " 300-th evaluation: score=0.5345, divergence=0.0012, diversity=1.0667, num_succ=0, num_remain=50\n",
      " 400-th evaluation: score=0.5348, divergence=0.0014, diversity=1.0668, num_succ=0, num_remain=54\n",
      " 500-th evaluation: score=0.5351, divergence=0.0016, diversity=1.0670, num_succ=0, num_remain=46\n",
      " 600-th evaluation: score=0.5354, divergence=0.0019, diversity=1.0671, num_succ=1, num_remain=42\n",
      " 700-th evaluation: score=0.5357, divergence=0.0020, diversity=1.0673, num_succ=1, num_remain=42\n",
      " 800-th evaluation: score=0.5360, divergence=0.0023, diversity=1.0674, num_succ=1, num_remain=50\n",
      " 900-th evaluation: score=0.5362, divergence=0.0024, diversity=1.0676, num_succ=1, num_remain=39\n",
      "evaluating inputs\n",
      "parent_sim: 0.2663 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.3976 gap=0.1314 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.5723 gap=0.3061 train(mbnetv2,Flower102)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2127 gap=-0.0536 train(mbnetv2,SDog120)-\u001b[0m\n",
      "ref_sim: 0.6879 gap=0.4217 train(resnet18,Flower102)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1977 gap=-0.0686 train(resnet18,SDog120)-\u001b[0m\n",
      "ref_sim: 0.5032 gap=0.2369 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.6115 gap=0.3452 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.7771 gap=0.5108 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.4177 gap=0.1514 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.4183 gap=0.1520 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.5253 gap=0.2591 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.7194 gap=0.4532 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.6902 gap=0.4240 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.6815 gap=0.4152 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.8047 gap=0.5384 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.7934 gap=0.5272 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.5489 gap=0.2827 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.8185 gap=0.5522 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.7768 gap=0.5106 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.6285 gap=0.3622 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.4933 gap=0.2270 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.4745 gap=0.2083 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4464 gap=0.1801 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.4687 gap=0.2024 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.4611 gap=0.1949 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.3728 gap=0.1066 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.4312 gap=0.1650 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.4756 gap=0.2094 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.4699 gap=0.2036 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.5049 gap=0.2386 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.7310 gap=0.4647 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.6144 gap=0.3482 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2469 gap=-0.0194 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\u001b[0m\n",
      "ref_sim: 0.5139 gap=0.2476 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.2943 gap=0.0280 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "ref_sim: 0.7198 gap=0.4536 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6071 gap=0.3408 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.5839 gap=0.3176 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.6937 gap=0.4274 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.5852 gap=0.3189 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.7120 gap=0.4457 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.3941 gap=0.1278 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.3592 gap=0.0929 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.3911 gap=0.1248 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1474 gap=-0.1189 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2189 gap=-0.0474 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2280 gap=-0.0383 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.5624 gap=0.2961 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.6826 gap=0.4163 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.5307 gap=0.2644 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2411 gap=-0.0251 train(mbnetv2,SDog120)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2015 gap=-0.0648 train(mbnetv2,SDog120)-prune(0.5)-\u001b[0m\n",
      "ref_sim: 0.3343 gap=0.0681 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.6942 gap=0.4280 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.6995 gap=0.4333 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.7261 gap=0.4598 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.2773 gap=0.0110 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.2974 gap=0.0311 train(resnet18,SDog120)-prune(0.5)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2056 gap=-0.0607 train(resnet18,SDog120)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.5822 gap=0.3159 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.3399 gap=0.0736 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.7808 gap=0.5146 train(resnet18,Flower102)-distill()-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2113 gap=-0.0550 train(resnet18,SDog120)-distill()-\u001b[0m\n",
      "ref_sim: 0.6865 gap=0.4202 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.7122 gap=0.4459 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.3305 gap=0.0642 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1849 gap=-0.0814 train(mbnetv2,SDog120)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.3921 gap=0.1259 train(resnet18,Flower102)-steal(mbnetv2)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.7367 gap=0.4705 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.3481 gap=0.0819 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.4090 gap=0.1427 train(resnet18,SDog120)-steal(resnet18)-\n",
      "89\t generating inputs for pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "initial_evaluation: score=0.5072, divergence=0.0000, diversity=1.0143, num_succ=0, num_remain=9\n",
      "   0-th evaluation: score=0.5073, divergence=0.0002, diversity=1.0143, num_succ=0, num_remain=83\n",
      " 100-th evaluation: score=0.5079, divergence=0.0006, diversity=1.0144, num_succ=0, num_remain=44\n",
      " 200-th evaluation: score=0.5080, divergence=0.0008, diversity=1.0145, num_succ=0, num_remain=35\n",
      " 300-th evaluation: score=0.5083, divergence=0.0009, diversity=1.0147, num_succ=0, num_remain=32\n",
      " 400-th evaluation: score=0.5084, divergence=0.0010, diversity=1.0148, num_succ=0, num_remain=35\n",
      " 500-th evaluation: score=0.5087, divergence=0.0012, diversity=1.0149, num_succ=0, num_remain=31\n",
      " 600-th evaluation: score=0.5089, divergence=0.0013, diversity=1.0150, num_succ=0, num_remain=29\n",
      " 700-th evaluation: score=0.5090, divergence=0.0015, diversity=1.0151, num_succ=0, num_remain=29\n",
      " 800-th evaluation: score=0.5092, divergence=0.0016, diversity=1.0152, num_succ=0, num_remain=27\n",
      " 900-th evaluation: score=0.5094, divergence=0.0017, diversity=1.0153, num_succ=0, num_remain=33\n",
      "evaluating inputs\n",
      "parent_sim: 0.5083 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.6068 gap=0.0985 pretrain(mbnetv2,ImageNet)-\n",
      "ref_sim: 0.6149 gap=0.1065 train(mbnetv2,Flower102)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.3111 gap=-0.1972 train(mbnetv2,SDog120)-\u001b[0m\n",
      "ref_sim: 0.8689 gap=0.3606 train(resnet18,Flower102)-\n",
      "ref_sim: 0.7219 gap=0.2136 train(resnet18,SDog120)-\n",
      "ref_sim: 0.7891 gap=0.2808 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "ref_sim: 0.7629 gap=0.2546 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.7328 gap=0.2245 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4493 gap=-0.0590 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-\u001b[0m\n",
      "ref_sim: 0.5653 gap=0.0570 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.5301 gap=0.0218 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.7261 gap=0.2178 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.7207 gap=0.2124 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.7589 gap=0.2506 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.7645 gap=0.2561 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.7530 gap=0.2447 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "ref_sim: 0.7795 gap=0.2712 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\n",
      "ref_sim: 0.7230 gap=0.2147 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.7657 gap=0.2574 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "ref_sim: 0.7727 gap=0.2644 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-prune(0.8)-\n",
      "ref_sim: 0.7475 gap=0.2392 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.6855 gap=0.1772 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.6815 gap=0.1731 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.7790 gap=0.2707 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.7300 gap=0.2216 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.7057 gap=0.1974 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.7002 gap=0.1919 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.7780 gap=0.2697 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.5950 gap=0.0867 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.7175 gap=0.2092 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.7617 gap=0.2534 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.7907 gap=0.2824 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2542 gap=-0.2541 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2887 gap=-0.2197 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3304 gap=-0.1779 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-distill()-\u001b[0m\n",
      "ref_sim: 0.6105 gap=0.1022 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8033 gap=0.2950 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.7025 gap=0.1942 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.8379 gap=0.3296 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.8013 gap=0.2929 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.8215 gap=0.3132 pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.3208 gap=-0.1875 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1773 gap=-0.3310 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4567 gap=-0.0516 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2235 gap=-0.2848 pretrain(mbnetv2,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3551 gap=-0.1533 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2847 gap=-0.2236 pretrain(mbnetv2,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.6112 gap=0.1029 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.5519 gap=0.0435 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.7015 gap=0.1932 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2987 gap=-0.2097 train(mbnetv2,SDog120)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2833 gap=-0.2250 train(mbnetv2,SDog120)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3406 gap=-0.1677 train(mbnetv2,SDog120)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.8499 gap=0.3416 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.8591 gap=0.3508 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.8594 gap=0.3511 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.7300 gap=0.2217 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.7722 gap=0.2639 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.7416 gap=0.2333 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.5531 gap=0.0448 train(mbnetv2,Flower102)-distill()-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4967 gap=-0.0116 train(mbnetv2,SDog120)-distill()-\u001b[0m\n",
      "ref_sim: 0.8226 gap=0.3143 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.6346 gap=0.1263 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.7721 gap=0.2638 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.7988 gap=0.2905 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.3309 gap=-0.1775 train(mbnetv2,SDog120)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4527 gap=-0.0556 train(mbnetv2,SDog120)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.5322 gap=0.0239 train(resnet18,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.7381 gap=0.2298 train(resnet18,Flower102)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4219 gap=-0.0864 train(resnet18,SDog120)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4281 gap=-0.0802 train(resnet18,SDog120)-steal(resnet18)-\u001b[0m\n",
      "90\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\n",
      "initial_evaluation: score=0.6182, divergence=0.0000, diversity=1.2364, num_succ=0, num_remain=9\n",
      "   0-th evaluation: score=0.6183, divergence=0.0001, diversity=1.2364, num_succ=0, num_remain=87\n",
      " 100-th evaluation: score=0.6184, divergence=0.0002, diversity=1.2364, num_succ=0, num_remain=60\n",
      " 200-th evaluation: score=0.6184, divergence=0.0002, diversity=1.2365, num_succ=0, num_remain=48\n",
      " 300-th evaluation: score=0.6185, divergence=0.0002, diversity=1.2365, num_succ=0, num_remain=50\n",
      " 400-th evaluation: score=0.6185, divergence=0.0003, diversity=1.2365, num_succ=0, num_remain=46\n",
      " 500-th evaluation: score=0.6186, divergence=0.0003, diversity=1.2365, num_succ=0, num_remain=50\n",
      " 600-th evaluation: score=0.6186, divergence=0.0003, diversity=1.2366, num_succ=0, num_remain=41\n",
      " 700-th evaluation: score=0.6186, divergence=0.0003, diversity=1.2366, num_succ=0, num_remain=47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 800-th evaluation: score=0.6187, divergence=0.0004, diversity=1.2366, num_succ=0, num_remain=42\n",
      " 900-th evaluation: score=0.6187, divergence=0.0004, diversity=1.2366, num_succ=0, num_remain=44\n",
      "evaluating inputs\n",
      "parent_sim: 0.8225 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.7997 gap=-0.0228 pretrain(resnet18,ImageNet)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2036 gap=-0.6189 train(mbnetv2,Flower102)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.6657 gap=-0.1568 train(mbnetv2,SDog120)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2603 gap=-0.5622 train(resnet18,Flower102)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5872 gap=-0.2354 train(resnet18,SDog120)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7872 gap=-0.0353 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.8154 gap=-0.0071 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7650 gap=-0.0575 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7443 gap=-0.0782 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.8056 gap=-0.0170 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.8067 gap=-0.0159 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.8090 gap=-0.0135 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7990 gap=-0.0235 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.8218 gap=-0.0007 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.8017 gap=-0.0209 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7956 gap=-0.0269 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.8108 gap=-0.0117 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7677 gap=-0.0548 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7826 gap=-0.0399 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7684 gap=-0.0542 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.8536 gap=0.0310 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.7497 gap=-0.0728 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7066 gap=-0.1159 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.8916 gap=0.0691 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.8805 gap=0.0580 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.7238 gap=-0.0987 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.8753 gap=0.0528 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.8700 gap=0.0474 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.7402 gap=-0.0823 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7087 gap=-0.1138 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.6403 gap=-0.1822 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4829 gap=-0.3397 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7111 gap=-0.1115 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.6985 gap=-0.1240 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.6352 gap=-0.1874 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3736 gap=-0.4490 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3598 gap=-0.4627 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1055 gap=-0.7170 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3205 gap=-0.5020 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1206 gap=-0.7019 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1510 gap=-0.6715 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7512 gap=-0.0713 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7626 gap=-0.0599 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5074 gap=-0.3152 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7056 gap=-0.1169 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.8630 gap=0.0405 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.8109 gap=-0.0116 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2611 gap=-0.5614 train(mbnetv2,Flower102)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2091 gap=-0.6134 train(mbnetv2,Flower102)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4593 gap=-0.3632 train(mbnetv2,Flower102)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5708 gap=-0.2517 train(mbnetv2,SDog120)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.6986 gap=-0.1239 train(mbnetv2,SDog120)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.8083 gap=-0.0142 train(mbnetv2,SDog120)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2416 gap=-0.5809 train(resnet18,Flower102)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2333 gap=-0.5892 train(resnet18,Flower102)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2401 gap=-0.5824 train(resnet18,Flower102)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.6209 gap=-0.2016 train(resnet18,SDog120)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.6189 gap=-0.2036 train(resnet18,SDog120)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.6725 gap=-0.1500 train(resnet18,SDog120)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1716 gap=-0.6509 train(mbnetv2,Flower102)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7920 gap=-0.0305 train(mbnetv2,SDog120)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1797 gap=-0.6428 train(resnet18,Flower102)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3921 gap=-0.4304 train(resnet18,SDog120)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1597 gap=-0.6628 train(mbnetv2,Flower102)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2425 gap=-0.5800 train(mbnetv2,Flower102)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.9346 gap=0.1121 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.8051 gap=-0.0174 train(mbnetv2,SDog120)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1898 gap=-0.6327 train(resnet18,Flower102)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1595 gap=-0.6630 train(resnet18,Flower102)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.8464 gap=0.0239 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.7053 gap=-0.1172 train(resnet18,SDog120)-steal(resnet18)-\u001b[0m\n",
      "91\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "initial_evaluation: score=0.6253, divergence=0.0000, diversity=1.2506, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6253, divergence=0.0000, diversity=1.2506, num_succ=0, num_remain=89\n",
      " 100-th evaluation: score=0.6254, divergence=0.0001, diversity=1.2506, num_succ=0, num_remain=53\n",
      " 200-th evaluation: score=0.6254, divergence=0.0001, diversity=1.2506, num_succ=0, num_remain=49\n",
      " 300-th evaluation: score=0.6254, divergence=0.0001, diversity=1.2506, num_succ=0, num_remain=47\n",
      " 400-th evaluation: score=0.6255, divergence=0.0001, diversity=1.2507, num_succ=0, num_remain=44\n",
      " 500-th evaluation: score=0.6255, divergence=0.0002, diversity=1.2507, num_succ=0, num_remain=45\n",
      " 600-th evaluation: score=0.6255, divergence=0.0002, diversity=1.2507, num_succ=0, num_remain=43\n",
      " 700-th evaluation: score=0.6255, divergence=0.0002, diversity=1.2507, num_succ=0, num_remain=38\n",
      " 800-th evaluation: score=0.6256, divergence=0.0002, diversity=1.2507, num_succ=0, num_remain=41\n",
      " 900-th evaluation: score=0.6256, divergence=0.0002, diversity=1.2507, num_succ=0, num_remain=38\n",
      "evaluating inputs\n",
      "parent_sim: 0.5554 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m[ERROR] ref_sim: 0.4028 gap=-0.1525 pretrain(resnet18,ImageNet)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2825 gap=-0.2729 train(mbnetv2,Flower102)-\u001b[0m\n",
      "ref_sim: 0.5744 gap=0.0191 train(mbnetv2,SDog120)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1556 gap=-0.3998 train(resnet18,Flower102)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1715 gap=-0.3839 train(resnet18,SDog120)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3651 gap=-0.1903 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2147 gap=-0.3407 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1924 gap=-0.3630 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5005 gap=-0.0549 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4922 gap=-0.0632 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4506 gap=-0.1048 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2708 gap=-0.2846 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2564 gap=-0.2990 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3035 gap=-0.2519 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2698 gap=-0.2856 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3218 gap=-0.2336 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3285 gap=-0.2268 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1882 gap=-0.3672 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1847 gap=-0.3706 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2708 gap=-0.2846 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4530 gap=-0.1024 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5453 gap=-0.0101 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4822 gap=-0.0732 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4662 gap=-0.0892 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4268 gap=-0.1286 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4989 gap=-0.0565 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4112 gap=-0.1442 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3962 gap=-0.1592 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5163 gap=-0.0390 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2981 gap=-0.2573 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1477 gap=-0.4077 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1456 gap=-0.4098 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4003 gap=-0.1551 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\u001b[0m\n",
      "ref_sim: 0.5811 gap=0.0257 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4237 gap=-0.1317 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3004 gap=-0.2549 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2274 gap=-0.3280 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2642 gap=-0.2911 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2593 gap=-0.2961 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2853 gap=-0.2701 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1734 gap=-0.3820 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.6117 gap=0.0563 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5857 gap=0.0303 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.7007 gap=0.1453 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4881 gap=-0.0673 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.7159 gap=0.1605 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5655 gap=0.0101 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2924 gap=-0.2630 train(mbnetv2,Flower102)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1921 gap=-0.3633 train(mbnetv2,Flower102)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4209 gap=-0.1345 train(mbnetv2,Flower102)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5341 gap=-0.0213 train(mbnetv2,SDog120)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5239 gap=-0.0315 train(mbnetv2,SDog120)-prune(0.5)-\u001b[0m\n",
      "ref_sim: 0.5885 gap=0.0331 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1672 gap=-0.3882 train(resnet18,Flower102)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1516 gap=-0.4037 train(resnet18,Flower102)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1895 gap=-0.3659 train(resnet18,Flower102)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1862 gap=-0.3692 train(resnet18,SDog120)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1758 gap=-0.3796 train(resnet18,SDog120)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2097 gap=-0.3457 train(resnet18,SDog120)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4034 gap=-0.1520 train(mbnetv2,Flower102)-distill()-\u001b[0m\n",
      "ref_sim: 0.6480 gap=0.0926 train(mbnetv2,SDog120)-distill()-\n",
      "\u001b[93m[ERROR] ref_sim: 0.1716 gap=-0.3837 train(resnet18,Flower102)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2604 gap=-0.2950 train(resnet18,SDog120)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2390 gap=-0.3164 train(mbnetv2,Flower102)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2991 gap=-0.2563 train(mbnetv2,Flower102)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.6761 gap=0.1207 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.4017 gap=-0.1537 train(mbnetv2,SDog120)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2919 gap=-0.2635 train(resnet18,Flower102)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4251 gap=-0.1303 train(resnet18,Flower102)-steal(resnet18)-\u001b[0m\n",
      "ref_sim: 0.7765 gap=0.2211 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2043 gap=-0.3511 train(resnet18,SDog120)-steal(resnet18)-\u001b[0m\n",
      "92\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "initial_evaluation: score=0.6635, divergence=0.0000, diversity=1.3270, num_succ=0, num_remain=7\n",
      "   0-th evaluation: score=0.6635, divergence=0.0000, diversity=1.3270, num_succ=0, num_remain=90\n",
      " 100-th evaluation: score=0.6636, divergence=0.0001, diversity=1.3270, num_succ=0, num_remain=50\n",
      " 200-th evaluation: score=0.6636, divergence=0.0001, diversity=1.3271, num_succ=0, num_remain=53\n",
      " 300-th evaluation: score=0.6637, divergence=0.0001, diversity=1.3271, num_succ=0, num_remain=38\n",
      " 400-th evaluation: score=0.6637, divergence=0.0001, diversity=1.3271, num_succ=0, num_remain=38\n",
      " 500-th evaluation: score=0.6637, divergence=0.0001, diversity=1.3271, num_succ=0, num_remain=39\n",
      " 600-th evaluation: score=0.6637, divergence=0.0002, diversity=1.3271, num_succ=0, num_remain=34\n",
      " 700-th evaluation: score=0.6637, divergence=0.0002, diversity=1.3272, num_succ=0, num_remain=35\n",
      " 800-th evaluation: score=0.6638, divergence=0.0002, diversity=1.3272, num_succ=0, num_remain=36\n",
      " 900-th evaluation: score=0.6638, divergence=0.0002, diversity=1.3272, num_succ=0, num_remain=45\n",
      "evaluating inputs\n",
      "parent_sim: 0.3540 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.4647 gap=0.1107 pretrain(resnet18,ImageNet)-\n",
      "ref_sim: 0.4505 gap=0.0965 train(mbnetv2,Flower102)-\n",
      "ref_sim: 0.4188 gap=0.0648 train(mbnetv2,SDog120)-\n",
      "ref_sim: 0.6979 gap=0.3439 train(resnet18,Flower102)-\n",
      "ref_sim: 0.6426 gap=0.2886 train(resnet18,SDog120)-\n",
      "ref_sim: 0.4296 gap=0.0757 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_sim: 0.3756 gap=0.0216 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\n",
      "ref_sim: 0.4371 gap=0.0832 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\n",
      "ref_sim: 0.5800 gap=0.2260 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\n",
      "ref_sim: 0.6755 gap=0.3215 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\n",
      "ref_sim: 0.6097 gap=0.2557 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\n",
      "ref_sim: 0.4665 gap=0.1125 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\n",
      "ref_sim: 0.4807 gap=0.1267 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4854 gap=0.1314 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\n",
      "ref_sim: 0.3894 gap=0.0354 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\n",
      "ref_sim: 0.4287 gap=0.0747 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.3310 gap=-0.0229 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.3859 gap=0.0319 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\n",
      "ref_sim: 0.4047 gap=0.0507 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.3350 gap=-0.0190 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\u001b[0m\n",
      "ref_sim: 0.7499 gap=0.3959 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\n",
      "ref_sim: 0.5126 gap=0.1586 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\n",
      "ref_sim: 0.4801 gap=0.1262 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\n",
      "ref_sim: 0.8266 gap=0.4727 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\n",
      "ref_sim: 0.9134 gap=0.5594 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\n",
      "ref_sim: 0.5911 gap=0.2371 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\n",
      "ref_sim: 0.7805 gap=0.4265 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\n",
      "ref_sim: 0.8822 gap=0.5282 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\n",
      "ref_sim: 0.5062 gap=0.1522 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\n",
      "ref_sim: 0.4195 gap=0.0655 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\n",
      "ref_sim: 0.4094 gap=0.0554 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\n",
      "ref_sim: 0.4441 gap=0.0901 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\n",
      "ref_sim: 0.5734 gap=0.2194 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\n",
      "ref_sim: 0.4869 gap=0.1329 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\n",
      "ref_sim: 0.3595 gap=0.0055 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2677 gap=-0.0863 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\u001b[0m\n",
      "ref_sim: 0.4675 gap=0.1135 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.3559 gap=0.0019 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.4232 gap=0.0692 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2461 gap=-0.1079 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\u001b[0m\n",
      "ref_sim: 0.6346 gap=0.2806 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\n",
      "ref_sim: 0.6636 gap=0.3096 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\n",
      "ref_sim: 0.5543 gap=0.2003 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\n",
      "ref_sim: 0.5377 gap=0.1837 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\n",
      "ref_sim: 0.6627 gap=0.3087 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\n",
      "ref_sim: 0.6696 gap=0.3156 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\n",
      "ref_sim: 0.6335 gap=0.2795 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\n",
      "ref_sim: 0.4028 gap=0.0488 train(mbnetv2,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.4488 gap=0.0948 train(mbnetv2,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.5183 gap=0.1643 train(mbnetv2,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.4467 gap=0.0927 train(mbnetv2,SDog120)-prune(0.2)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.3383 gap=-0.0157 train(mbnetv2,SDog120)-prune(0.5)-\u001b[0m\n",
      "ref_sim: 0.6195 gap=0.2655 train(mbnetv2,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.7111 gap=0.3571 train(resnet18,Flower102)-prune(0.2)-\n",
      "ref_sim: 0.7011 gap=0.3471 train(resnet18,Flower102)-prune(0.5)-\n",
      "ref_sim: 0.7239 gap=0.3700 train(resnet18,Flower102)-prune(0.8)-\n",
      "ref_sim: 0.7388 gap=0.3848 train(resnet18,SDog120)-prune(0.2)-\n",
      "ref_sim: 0.7038 gap=0.3498 train(resnet18,SDog120)-prune(0.5)-\n",
      "ref_sim: 0.7859 gap=0.4319 train(resnet18,SDog120)-prune(0.8)-\n",
      "ref_sim: 0.5088 gap=0.1548 train(mbnetv2,Flower102)-distill()-\n",
      "ref_sim: 0.4525 gap=0.0985 train(mbnetv2,SDog120)-distill()-\n",
      "ref_sim: 0.6408 gap=0.2868 train(resnet18,Flower102)-distill()-\n",
      "ref_sim: 0.8307 gap=0.4767 train(resnet18,SDog120)-distill()-\n",
      "ref_sim: 0.4330 gap=0.0790 train(mbnetv2,Flower102)-steal(mbnetv2)-\n",
      "ref_sim: 0.7806 gap=0.4266 train(mbnetv2,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6593 gap=0.3053 train(mbnetv2,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.8026 gap=0.4486 train(mbnetv2,SDog120)-steal(resnet18)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.2644 gap=-0.0896 train(resnet18,Flower102)-steal(mbnetv2)-\u001b[0m\n",
      "ref_sim: 0.6743 gap=0.3204 train(resnet18,Flower102)-steal(resnet18)-\n",
      "ref_sim: 0.6928 gap=0.3388 train(resnet18,SDog120)-steal(mbnetv2)-\n",
      "ref_sim: 0.6796 gap=0.3256 train(resnet18,SDog120)-steal(resnet18)-\n",
      "93\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\n",
      "initial_evaluation: score=0.6711, divergence=0.0000, diversity=1.3422, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6711, divergence=0.0000, diversity=1.3422, num_succ=0, num_remain=89\n",
      " 100-th evaluation: score=0.6712, divergence=0.0001, diversity=1.3422, num_succ=0, num_remain=75\n",
      " 200-th evaluation: score=0.6712, divergence=0.0001, diversity=1.3422, num_succ=0, num_remain=69\n",
      " 300-th evaluation: score=0.6712, divergence=0.0001, diversity=1.3422, num_succ=0, num_remain=67\n",
      " 400-th evaluation: score=0.6712, divergence=0.0001, diversity=1.3422, num_succ=0, num_remain=57\n",
      " 500-th evaluation: score=0.6712, divergence=0.0001, diversity=1.3422, num_succ=0, num_remain=51\n",
      " 600-th evaluation: score=0.6712, divergence=0.0001, diversity=1.3422, num_succ=0, num_remain=47\n",
      " 700-th evaluation: score=0.6712, divergence=0.0001, diversity=1.3422, num_succ=0, num_remain=56\n",
      " 800-th evaluation: score=0.6713, divergence=0.0001, diversity=1.3422, num_succ=0, num_remain=48\n",
      " 900-th evaluation: score=0.6713, divergence=0.0001, diversity=1.3423, num_succ=0, num_remain=45\n",
      "evaluating inputs\n",
      "parent_sim: 0.9162 pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.5)-\n",
      "\u001b[93m[ERROR] ref_sim: 0.7223 gap=-0.1939 pretrain(resnet18,ImageNet)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0151 gap=-0.9011 train(mbnetv2,Flower102)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3667 gap=-0.5495 train(mbnetv2,SDog120)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0129 gap=-0.9033 train(resnet18,Flower102)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0126 gap=-0.9036 train(resnet18,SDog120)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.8380 gap=-0.0782 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.8256 gap=-0.0906 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7341 gap=-0.1821 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.8038 gap=-0.1124 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.6812 gap=-0.2350 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7215 gap=-0.1947 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7653 gap=-0.1509 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7572 gap=-0.1590 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7889 gap=-0.1273 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.8143 gap=-0.1019 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.8029 gap=-0.1133 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.8486 gap=-0.0676 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.8118 gap=-0.1044 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.2)-\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m[ERROR] ref_sim: 0.8218 gap=-0.0944 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.8333 gap=-0.0829 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.6897 gap=-0.2265 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7571 gap=-0.1591 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7946 gap=-0.1216 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7847 gap=-0.1315 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.8159 gap=-0.1003 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5716 gap=-0.3446 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7133 gap=-0.2029 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7900 gap=-0.1262 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5136 gap=-0.4026 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.6564 gap=-0.2598 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7214 gap=-0.1948 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5947 gap=-0.3215 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.6859 gap=-0.2303 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.6135 gap=-0.3027 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1241 gap=-0.7921 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.6928 gap=-0.2234 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1154 gap=-0.8008 pretrain(resnet18,ImageNet)-transfer(Flower102,0.1)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4805 gap=-0.4357 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0963 gap=-0.8199 pretrain(resnet18,ImageNet)-transfer(Flower102,0.5)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1751 gap=-0.7411 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0624 gap=-0.8538 pretrain(resnet18,ImageNet)-transfer(Flower102,1)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.8205 gap=-0.0957 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.7631 gap=-0.1531 pretrain(resnet18,ImageNet)-transfer(SDog120,0.1)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5193 gap=-0.3969 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3646 gap=-0.5516 pretrain(resnet18,ImageNet)-transfer(SDog120,0.5)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.5529 gap=-0.3633 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.6047 gap=-0.3115 pretrain(resnet18,ImageNet)-transfer(SDog120,1)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0132 gap=-0.9030 train(mbnetv2,Flower102)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0178 gap=-0.8984 train(mbnetv2,Flower102)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2471 gap=-0.6691 train(mbnetv2,Flower102)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3030 gap=-0.6132 train(mbnetv2,SDog120)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2143 gap=-0.7019 train(mbnetv2,SDog120)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1244 gap=-0.7918 train(mbnetv2,SDog120)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0130 gap=-0.9032 train(resnet18,Flower102)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0121 gap=-0.9041 train(resnet18,Flower102)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0129 gap=-0.9033 train(resnet18,Flower102)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0134 gap=-0.9028 train(resnet18,SDog120)-prune(0.2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0122 gap=-0.9040 train(resnet18,SDog120)-prune(0.5)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0121 gap=-0.9041 train(resnet18,SDog120)-prune(0.8)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3970 gap=-0.5192 train(mbnetv2,Flower102)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.4074 gap=-0.5088 train(mbnetv2,SDog120)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0081 gap=-0.9081 train(resnet18,Flower102)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0101 gap=-0.9061 train(resnet18,SDog120)-distill()-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0180 gap=-0.8982 train(mbnetv2,Flower102)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0075 gap=-0.9087 train(mbnetv2,Flower102)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.2870 gap=-0.6292 train(mbnetv2,SDog120)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0258 gap=-0.8904 train(mbnetv2,SDog120)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.1334 gap=-0.7828 train(resnet18,Flower102)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.0412 gap=-0.8750 train(resnet18,Flower102)-steal(resnet18)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.8946 gap=-0.0216 train(resnet18,SDog120)-steal(mbnetv2)-\u001b[0m\n",
      "\u001b[93m[ERROR] ref_sim: 0.3472 gap=-0.5690 train(resnet18,SDog120)-steal(resnet18)-\u001b[0m\n",
      "94\t generating inputs for pretrain(mbnetv2,ImageNet)-transfer(Flower102,1)-steal(mbnetv2)-\n",
      "initial_evaluation: score=0.6546, divergence=0.0000, diversity=1.3092, num_succ=0, num_remain=10\n",
      "   0-th evaluation: score=0.6546, divergence=0.0000, diversity=1.3092, num_succ=0, num_remain=87\n",
      " 100-th evaluation: score=0.6547, divergence=0.0001, diversity=1.3092, num_succ=0, num_remain=60\n",
      " 200-th evaluation: score=0.6547, divergence=0.0001, diversity=1.3092, num_succ=0, num_remain=55\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import copy\n",
    "from scipy import spatial\n",
    "from utils import lazy_property, Utils\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(name)-12s %(levelname)-8s %(message)s\")\n",
    "\n",
    "\n",
    "from benchmark import ImageBenchmark\n",
    "bench = ImageBenchmark()\n",
    "models = list(bench.list_models())\n",
    "models_dict = {}\n",
    "for i, model in enumerate(models):\n",
    "    if not model.torch_model_exists():\n",
    "        continue\n",
    "#     print(f'{i}\\t {model.__str__()}')\n",
    "    models_dict[model.__str__()] = model\n",
    "\n",
    "    \n",
    "def get_comparable_models(target_model):\n",
    "    target_model_name = target_model.__str__()\n",
    "    target_model_segs = target_model_name.split('-')\n",
    "    parent_model_name = '-'.join(target_model_segs[:-2]) + '-'\n",
    "    parent_model = models_dict[parent_model_name]\n",
    "    # print(f'parent_model: {parent_model}')\n",
    "    reference_models = []\n",
    "    for model in models:\n",
    "        if not model.__str__().startswith(target_model_segs[0]):\n",
    "            reference_models.append(model)\n",
    "            # print(f'reference_model: {model}')\n",
    "    return parent_model, reference_models\n",
    "\n",
    "\n",
    "def compute_ddv(model, normal_inputs, adv_inputs):\n",
    "    normal_outputs = model.batch_forward(normal_inputs).cpu().numpy()\n",
    "    adv_outputs = model.batch_forward(adv_inputs).cpu().numpy()\n",
    "    output_pairs = zip(normal_outputs, adv_outputs)\n",
    "    # print(list(output_pairs)[0])\n",
    "    ddv = []  # DDV is short for decision distance vector\n",
    "    for i, (ya, yb) in enumerate(output_pairs):\n",
    "        dist = spatial.distance.cosine(ya, yb)\n",
    "        ddv.append(dist)\n",
    "    ddv = Utils.normalize(np.array(ddv))\n",
    "    return ddv\n",
    "\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    # Background colors:\n",
    "    GREYBG = '\\033[100m'\n",
    "    REDBG = '\\033[101m'\n",
    "    GREENBG = '\\033[102m'\n",
    "    YELLOWBG = '\\033[103m'\n",
    "    BLUEBG = '\\033[104m'\n",
    "    PINKBG = '\\033[105m'\n",
    "    CYANBG = '\\033[106m'\n",
    "\n",
    "    \n",
    "DEVICE = 'cuda'\n",
    "image_size = 224\n",
    "\n",
    "\n",
    "def expand_vector(x, image_size):\n",
    "    batch_size = x.size(0)\n",
    "    x = x.view(-1, 3, image_size, image_size)\n",
    "    z = torch.zeros(batch_size, 3, image_size, image_size).to(DEVICE)\n",
    "    z[:, :, :image_size, :image_size] = x\n",
    "    return z\n",
    "\n",
    "\n",
    "def evaluate_inputs_1(model, inputs, seed_outputs, seed_preds, prev_score_arr, lambda1=0.5):\n",
    "    if prev_score_arr is None:\n",
    "        prev_score_arr = torch.ones(len(inputs)).to(DEVICE) * -1000\n",
    "    outputs = model(inputs)\n",
    "    _, preds = outputs.data.max(1)\n",
    "    changed = preds.ne(seed_preds)\n",
    "#     outputs = F.softmax(outputs, -1)\n",
    "#     seed_outputs = F.softmax(seed_outputs, -1)\n",
    "#     print(target_outputs)\n",
    "    reduce_dims = tuple(range(outputs.dim())[1:])\n",
    "    \n",
    "    output_mean = seed_outputs.mean(axis=0)\n",
    "    target_outputs = output_mean - seed_outputs\n",
    "#     print(seed_outputs)\n",
    "#     print(output_mean)\n",
    "#     print(target_outputs)\n",
    "    \n",
    "    target_dist_arr = -torch.sum((outputs - target_outputs) ** 2, dim=reduce_dims) ** 0.5\n",
    "    target_dist = target_dist_arr.mean()\n",
    "    \n",
    "    divergence_arr = torch.sum((outputs - seed_outputs) ** 2, dim=reduce_dims) ** 0.5\n",
    "    divergence = torch.mean(divergence_arr)\n",
    "    \n",
    "    seed_var_arr = torch.sum((seed_outputs - output_mean) ** 2, dim=reduce_dims) ** 0.5\n",
    "    seed_var = torch.mean(seed_var_arr)\n",
    "    \n",
    "    output_var_arr = torch.sum((outputs - output_mean) ** 2, dim=reduce_dims) ** 0.5\n",
    "    output_var = output_var_arr.mean()\n",
    "    \n",
    "#     print(seed_var_arr, output_var_arr.shape, sep='\\n')\n",
    "# #     divergence_cos = F.cosine_similarity(outputs, seed_outputs)\n",
    "# #     divergence_kld = F.kl_div(seed_outputs, outputs, reduction='none')\n",
    "# #     print(divergence_kld)\n",
    "#     diversity_matrix = torch.cdist(outputs, outputs, p=2.0)\n",
    "#     diversity = torch.mean(diversity_matrix)\n",
    "#     quantile = lambda t, q: t.view(-1).kthvalue(1 + round(float(q) * (t.numel() - 1))).values.item()\n",
    "#     diversity_quantile = quantile(diversity_matrix, 0.011)\n",
    "# #     diversity = diversity ** 2\n",
    "#     score = divergence + lambda1 * diversity\n",
    "    new_score_arr = divergence_arr\n",
    "    new_score_improved = new_score_arr.gt(prev_score_arr)\n",
    "    var_in_limit = seed_var_arr.ge(output_var_arr)\n",
    "#     improved = new_score_improved & var_in_limit\n",
    "    improved = new_score_improved\n",
    "    # print(f' new_score_improved={new_score_improved}\\n var_in_limit={var_in_limit}\\n improved={improved}')\n",
    "    improved_indices = torch.nonzero(improved).cpu().numpy().squeeze(-1).tolist()\n",
    "    # print(score_improved, var_in_limit, improved_indices, score_arr, sep='\\n')\n",
    "    \n",
    "#     succ = preds.ne(seed_preds)\n",
    "#     low_divergence_indices = list(torch.nonzero(divergence_arr.lt(divergence)).cpu().numpy())\n",
    "#     low_target_dist_indices = list(torch.nonzero(target_dist_arr.lt(target_dist)).cpu().numpy())\n",
    "# #     low_diversity_indices = list(torch.nonzero(diversity_matrix.lt(diversity_quantile)).cpu().numpy())\n",
    "#     remaining_indices = set()\n",
    "# #     print(changed)\n",
    "#     for i in low_target_dist_indices:\n",
    "#         remaining_indices.add(i[0])\n",
    "# #     for i in low_diversity_indices:\n",
    "# #         if i[0] == i[1]:\n",
    "# #             continue\n",
    "# #         remaining_indices.add(i[0])\n",
    "# #         remaining_indices.add(i[1])\n",
    "#     remaining_indices = sorted(remaining_indices)\n",
    "    remaining_indices = list(range(len(inputs)))\n",
    "#     print(f' low_divergence_indices={len(low_divergence_indices)}\\n low_diversity_indices={len(low_diversity_indices)}\\n remaining_indices={len(remaining_indices)}')\n",
    "    score_arr = copy.copy(prev_score_arr)\n",
    "    score_arr[improved_indices] = new_score_arr[improved_indices]\n",
    "    \n",
    "    score = score_arr.mean()\n",
    "    eval_line = f'score={score:.4f}, num_remain={len(remaining_indices)}, num_improved={len(improved_indices)}'\n",
    "    return {\n",
    "        'outputs': outputs,\n",
    "        'preds': preds,\n",
    "        'score_arr': score_arr,\n",
    "        'score': score,\n",
    "        'remaining': remaining_indices,\n",
    "        'improved_indices': improved_indices,\n",
    "        'eval_line': eval_line\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_inputs_2(model, inputs, seed_outputs, seed_preds, prev_score_arr, lambda1=0.5):\n",
    "    outputs = model(inputs)\n",
    "    _, preds = outputs.data.max(1)\n",
    "    changed = preds.ne(seed_preds)\n",
    "    outputs = torch.nn.functional.softmax(outputs, -1)\n",
    "    seed_outputs = torch.nn.functional.softmax(seed_outputs, -1)\n",
    "    reduce_dims = tuple(range(outputs.dim())[1:])\n",
    "    divergence_arr = torch.sum((outputs - seed_outputs) ** 2, dim=reduce_dims) ** 0.5\n",
    "    divergence = torch.mean(divergence_arr)\n",
    "#     divergence_cos = F.cosine_similarity(outputs, seed_outputs)\n",
    "#     divergence_kld = F.kl_div(seed_outputs, outputs, reduction='none')\n",
    "#     print(divergence_kld)\n",
    "    diversity_matrix = torch.cdist(outputs, outputs, p=2.0)\n",
    "    diversity = torch.mean(diversity_matrix)\n",
    "    quantile = lambda t, q: t.view(-1).kthvalue(1 + round(float(q) * (t.numel() - 1))).values.item()\n",
    "    diversity_quantile = quantile(diversity_matrix, 0.011)\n",
    "#     diversity = diversity ** 2\n",
    "    score = divergence + lambda1 * diversity\n",
    "    succ = preds.ne(seed_preds)\n",
    "    low_divergence_indices = list(torch.nonzero(divergence_arr.lt(divergence)).cpu().numpy())\n",
    "    low_diversity_indices = list(torch.nonzero(diversity_matrix.lt(diversity_quantile)).cpu().numpy())\n",
    "    remaining_indices = set()\n",
    "#     print(changed)\n",
    "    for i in low_divergence_indices:\n",
    "        if not changed[i].cpu():\n",
    "            remaining_indices.add(i[0])\n",
    "    for i in low_diversity_indices:\n",
    "        if i[0] == i[1]:\n",
    "            continue\n",
    "        if not changed[i[0]]:\n",
    "            remaining_indices.add(i[0])\n",
    "        if not changed[i[1]]:\n",
    "            remaining_indices.add(i[1])\n",
    "    remaining_indices = sorted(remaining_indices)\n",
    "    improved_indices = list(range(len(inputs)))\n",
    "#     print(f' low_divergence_indices={len(low_divergence_indices)}\\n low_diversity_indices={len(low_diversity_indices)}\\n remaining_indices={len(remaining_indices)}')\n",
    "    eval_line = f'score={score:.4f}, divergence={divergence:.4f}, diversity={diversity:.4f}, num_succ={succ.sum()}, num_remain={len(remaining_indices)}'\n",
    "    return {\n",
    "        'outputs': outputs,\n",
    "        'preds': preds,\n",
    "        'score_arr': divergence_arr,\n",
    "        'score': score,\n",
    "        'divergence': divergence,\n",
    "        'diversity': diversity,\n",
    "        'succ': succ,\n",
    "        'remaining': remaining_indices,\n",
    "        'improved_indices': improved_indices,\n",
    "        'eval_line': eval_line\n",
    "    }\n",
    "    \n",
    "    \n",
    "def optimize_towards_goal(\n",
    "    model, seed_inputs, seed_outputs, seed_preds, evaluate_inputs,\n",
    "    max_iters=10000, mutation_size=1, epsilon=0.5, lambda1=0.0,\n",
    "    log_every=100, save_every=1000):\n",
    "#     seed_inputs = torch.from_numpy(seed_inputs).to(DEVICE)\n",
    "#     seed_outputs = torch.from_numpy(seed_outputs).to(DEVICE)\n",
    "#     seed_preds = torch.from_numpy(seed_preds).to(DEVICE)\n",
    "    input_shape = seed_inputs[0].shape\n",
    "    n_inputs = seed_inputs.shape[0]\n",
    "    ndims = np.prod(input_shape)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = copy.deepcopy(seed_inputs)\n",
    "        saved_inputs = {}\n",
    "        evaluation = evaluate_inputs(model, inputs, seed_outputs, seed_preds, None, lambda1)\n",
    "        print(f'initial_evaluation: {evaluation[\"eval_line\"]}')\n",
    "        \n",
    "        remaining_pos = list(range(ndims))\n",
    "\n",
    "        for i in range(max_iters):\n",
    "#             print(f'mutation {i}-th iteration')\n",
    "            # mutation_pos = np.random.randint(0, ndims)\n",
    "            if len(remaining_pos) < mutation_size:\n",
    "                print(f'not enough remaining pos')\n",
    "                break\n",
    "            mutation_pos = np.random.choice(remaining_pos, size=mutation_size, replace=False)\n",
    "            mutation = np.zeros(ndims).astype(np.float32)\n",
    "            mutation[mutation_pos] = epsilon\n",
    "            mutation = np.reshape(mutation, input_shape)\n",
    "\n",
    "            mutation_batch = np.zeros(shape=inputs.shape).astype(np.float32)\n",
    "            mutation_indices = evaluation['remaining']\n",
    "            if len(mutation_indices) == 0:\n",
    "                print(f'no remaining indice')\n",
    "                break\n",
    "            mutation_batch[mutation_indices] = mutation\n",
    "            mutation_batch = torch.from_numpy(mutation_batch).to(DEVICE)\n",
    "\n",
    "            prev_score = evaluation[\"score\"]\n",
    "            mutate_right_inputs = (inputs + mutation_batch).clamp(-2.6, 2.6)\n",
    "            mutate_right_eval = evaluate_inputs(model, mutate_right_inputs, seed_outputs, seed_preds, evaluation[\"score_arr\"])\n",
    "            mutate_right_score = mutate_right_eval['score']\n",
    "            mutate_left_inputs = (inputs - mutation_batch).clamp(-2.6, 2.6)\n",
    "            mutate_left_eval = evaluate_inputs(model, mutate_left_inputs, seed_outputs, seed_preds, evaluation[\"score_arr\"])\n",
    "            mutate_left_score = mutate_left_eval['score']\n",
    "\n",
    "            if mutate_right_score <= prev_score and mutate_left_score <= prev_score:\n",
    "                pass\n",
    "            elif mutate_right_score > mutate_left_score:\n",
    "#                 print(f'mutate right: {prev_score}->{mutate_right_score}')\n",
    "                improved_indices = mutate_right_eval['improved_indices']\n",
    "                inputs[improved_indices] = mutate_right_inputs[improved_indices]\n",
    "                evaluation = mutate_right_eval\n",
    "                remaining_pos = sorted(set(remaining_pos) - set(mutation_pos))\n",
    "            else:\n",
    "#                 print(f'mutate left: {prev_score}->{mutate_left_score}')\n",
    "                improved_indices = mutate_left_eval['improved_indices']\n",
    "                inputs[improved_indices] = mutate_left_inputs[improved_indices]\n",
    "                evaluation = mutate_left_eval\n",
    "                remaining_pos = sorted(set(remaining_pos) - set(mutation_pos))\n",
    "            if i % log_every == 0:\n",
    "                print(f'{i:4d}-th evaluation: {evaluation[\"eval_line\"]}')\n",
    "            if i % save_every == 0:\n",
    "                saved_inputs[i] = copy.copy(inputs.cpu().numpy())\n",
    "        return inputs, saved_inputs\n",
    "\n",
    "    \n",
    "def compute_ddv_with_outputs(model, normal_outputs, adv_outputs):\n",
    "    output_pairs = zip(normal_outputs, adv_outputs)\n",
    "    # print(list(output_pairs)[0])\n",
    "    ddv = []  # DDV is short for decision distance vector\n",
    "    for i, (ya, yb) in enumerate(output_pairs):\n",
    "        dist = spatial.distance.cosine(ya, yb)\n",
    "        ddv.append(dist)\n",
    "    ddv = Utils.normalize(np.array(ddv))\n",
    "    return ddv\n",
    "\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    if not model.torch_model_exists():\n",
    "        continue\n",
    "    model_name = model.__str__()\n",
    "    model_path = model.torch_model_path\n",
    "    if i < 6: # skip pretrained models\n",
    "        continue\n",
    "    if 'quantize' in model_name: # skip quantized models\n",
    "        continue\n",
    "        \n",
    "#     if i != 8:\n",
    "#         continue\n",
    "    out_path = os.path.join(model_path, 'blackbox_inputs_diversity0.5_m1e0.2.npz')\n",
    "#     if os.path.exists(out_path):\n",
    "#         continue\n",
    "    \n",
    "    print(f'{i}\\t generating inputs for {model.__str__()}')\n",
    "    seed_inputs = model.get_seed_inputs(100, rand=False)\n",
    "    seed_inputs = torch.from_numpy(seed_inputs).to(DEVICE)\n",
    "    model.torch_model.to(DEVICE)\n",
    "    seed_outputs = model.batch_forward(seed_inputs)\n",
    "    _, seed_preds = seed_outputs.data.max(1)\n",
    "\n",
    "    adv_inputs, saved_inputs = optimize_towards_goal(\n",
    "        model.torch_model_on_device, seed_inputs, seed_outputs, seed_preds, evaluate_inputs=evaluate_inputs_2,\n",
    "        mutation_size=1, epsilon=0.1, lambda1=0.5, max_iters=1000, log_every=100, save_every=100)\n",
    "    adv_outputs = model.batch_forward(adv_inputs).cpu()\n",
    "    _, adv_preds = adv_outputs.data.max(1)\n",
    "    \n",
    "    seed_inputs=seed_inputs.cpu().numpy()\n",
    "    adv_inputs=adv_inputs.cpu().numpy()\n",
    "    \n",
    "    ddv = compute_ddv(model, seed_inputs, adv_inputs)\n",
    "    \n",
    "    print(f'evaluating inputs')\n",
    "    parent_model, ref_models = get_comparable_models(model)\n",
    "    parent_sim = 0\n",
    "    for i, ref_model in enumerate([parent_model] + ref_models):\n",
    "        if 'quantize' in ref_model.__str__(): # quantized models are equivalent to its teacher model\n",
    "            continue\n",
    "        try:\n",
    "            ref_model.torch_model.to(DEVICE)\n",
    "            ref_ddv = compute_ddv(ref_model, seed_inputs, adv_inputs)\n",
    "            ref_sim = spatial.distance.cosine(ddv, ref_ddv)\n",
    "            ref_model.torch_model.cpu()\n",
    "            if i == 0:\n",
    "                parent_sim = ref_sim\n",
    "                gap = 1\n",
    "                print(f'parent_sim: {ref_sim:.4f} {ref_model}')\n",
    "            else:\n",
    "                gap = ref_sim - parent_sim\n",
    "                if gap > 0:\n",
    "                    print(f'ref_sim: {ref_sim:.4f} gap={gap:.4f} {ref_model}')\n",
    "                else:\n",
    "                    print(f'{bcolors.WARNING}[ERROR] ref_sim: {ref_sim:.4f} gap={gap:.4f} {ref_model}{bcolors.ENDC}')\n",
    "        except Exception as e:\n",
    "            print(f'failed to compare: {ref_model}')\n",
    "            print(f'exception: {e}')\n",
    "    \n",
    "    np.savez(out_path, seed_inputs=seed_inputs, adv_inputs=adv_inputs, ddv=ddv, saved_inputs=saved_inputs)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Utils\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def show_images(images, labels, title='examples'):\n",
    "    images = np.transpose(images, (0, 2, 3, 1))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "    for n in range(25):\n",
    "        plt.subplot(5,5,n+1)\n",
    "        img = images[n]\n",
    "        img = img.squeeze()\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'{labels[n]}')\n",
    "        plt.axis('off')\n",
    "    _ = plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "# show_images(seed_inputs, list(range(seed_inputs.shape[0])))\n",
    "# print(seed_inputs[0])\n",
    "# batch_outputs1 = model1.batch_forward(seed_inputs)\n",
    "# batch_preds1 = batch_outputs1.to('cpu').data.max(1)\n",
    "# print(batch_preds1)\n",
    "\n",
    "m = models[2]\n",
    "mm = m.torch_model\n",
    "test_loader = m.benchmark.get_dataloader(m.dataset_id, split='test')\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     mm.eval()\n",
    "#     total = 0\n",
    "#     top1 = 0\n",
    "#     for i, (batch, label) in enumerate(test_loader):\n",
    "#         batch, label = batch.to(DEVICE), label.to(DEVICE)\n",
    "#         total += batch.size(0)\n",
    "#         out = mm(batch)\n",
    "#         _, pred = out.max(dim=1)\n",
    "#         top1 += int(pred.eq(label).sum().item())\n",
    "\n",
    "# acc = float(top1) / total * 100\n",
    "# print(top1, total, acc)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        if i != 10:\n",
    "            continue\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        outputs = mm(images)\n",
    "        _, preds = outputs.max(dim=1)\n",
    "        print(outputs[0])\n",
    "        labels = [f'{label}-{preds[i]}' for i,label in enumerate(list(labels))]\n",
    "        show_images(images.to('cpu').numpy(), labels)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.fe_mobilenet import mbnetv2_dropout\n",
    "import os\n",
    "\n",
    "torch_model = mbnetv2_dropout(\n",
    "            pretrained=False,\n",
    "            num_classes=67\n",
    "        )\n",
    "ckpt = torch.load(os.path.join('models', 'train(mbnetv2,MIT67)-', 'ckpt.pth'))\n",
    "torch_model.load_state_dict(ckpt['state_dict'])\n",
    "mm = torch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
