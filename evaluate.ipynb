{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import logging\n",
    "import random\n",
    "from scipy import spatial\n",
    "from utils import Utils\n",
    "import os\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(name)-12s %(levelname)-8s %(message)s\")\n",
    "\n",
    "from benchmark import ImageBenchmark\n",
    "bench = ImageBenchmark()\n",
    "models = list(bench.list_models())\n",
    "models_dict = {}\n",
    "for i, model in enumerate(models):\n",
    "    if not model.torch_model_exists():\n",
    "        continue\n",
    "    print(f'{i}\\t {model.__str__()}')\n",
    "    models_dict[model.__str__()] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'\n",
    "\n",
    "def gen_adv_inputs(model, inputs):\n",
    "    from advertorch.attacks import LinfPGDAttack\n",
    "    def myloss(yhat, y):\n",
    "        return -((yhat[:,0]-y[:,0])**2 + 0.1*((yhat[:,1:]-y[:,1:])**2).mean(1)).mean()\n",
    "        \n",
    "    model = model.to(DEVICE)\n",
    "    inputs = torch.from_numpy(inputs).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        clean_outputs = model(inputs)\n",
    "    \n",
    "    output_shape = clean_outputs.shape\n",
    "    batch_size = output_shape[0]\n",
    "    num_classes = output_shape[1]\n",
    "    \n",
    "    output_mean = clean_outputs.mean(axis=0)\n",
    "    target_outputs = output_mean - clean_outputs\n",
    "    \n",
    "    y = torch.zeros(size=output_shape).to(DEVICE)\n",
    "    y[:, :] = 100000\n",
    "    # more diversity\n",
    "    y = target_outputs * 1000\n",
    "#     rand_idx = torch.randint(low=0, high=num_classes, size=(batch_size,))\n",
    "#     y = torch.nn.functional.one_hot(rand_idx, num_classes=num_classes).to(DEVICE) * 10\n",
    "#     print(y)\n",
    "    \n",
    "    adversary = LinfPGDAttack(\n",
    "        model, loss_fn=myloss, eps=0.1,\n",
    "        nb_iter=50, eps_iter=0.01, \n",
    "        rand_init=True, clip_min=inputs.min().item(), clip_max=inputs.max().item(),\n",
    "        targeted=True\n",
    "    )\n",
    "    \n",
    "    adv_inputs = adversary.perturb(inputs, y)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        adv_outputs = model(adv_inputs).to('cpu').numpy()\n",
    "#     print(adv_outputs)\n",
    "    torch.cuda.empty_cache()\n",
    "    return adv_inputs.to('cpu').numpy()\n",
    "\n",
    "\n",
    "model = models_dict['pretrain(mbnetv2,ImageNet)-transfer(Flower102,0.1)-prune(0.2)-']\n",
    "model.torch_model.to(DEVICE)\n",
    "seed_inputs = model.get_seed_inputs(100, rand=False)\n",
    "seed_outputs = model.batch_forward(seed_inputs)\n",
    "_, seed_preds = seed_outputs.to('cpu').data.max(1)\n",
    "\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "adv_inputs = gen_adv_inputs(model.torch_model, seed_inputs)\n",
    "adv_outputs = model.batch_forward(adv_inputs)\n",
    "_, adv_preds = adv_outputs.to('cpu').data.max(1)\n",
    "model.torch_model.cpu()\n",
    "\n",
    "time_spent = (datetime.now() - start_time).total_seconds()\n",
    "print(f'spent {time_spent} seconds')\n",
    "\n",
    "print(f\"seed_preds={seed_preds}, adv_preds={adv_preds}, seed_outputs={seed_outputs}, adv_outputs={adv_outputs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'\n",
    "\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    # Background colors:\n",
    "    GREYBG = '\\033[100m'\n",
    "    REDBG = '\\033[101m'\n",
    "    GREENBG = '\\033[102m'\n",
    "    YELLOWBG = '\\033[103m'\n",
    "    BLUEBG = '\\033[104m'\n",
    "    PINKBG = '\\033[105m'\n",
    "    CYANBG = '\\033[106m'\n",
    "\n",
    "\n",
    "def gen_adv_inputs(model, inputs):\n",
    "    from advertorch.attacks import LinfPGDAttack\n",
    "    def myloss(yhat, y):\n",
    "        return -((yhat[:,0]-y[:,0])**2 + 0.1*((yhat[:,1:]-y[:,1:])**2).mean(1)).mean()\n",
    "        \n",
    "    model = model.to(DEVICE)\n",
    "    inputs = torch.from_numpy(inputs).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        clean_outputs = model(inputs)\n",
    "    \n",
    "    output_shape = clean_outputs.shape\n",
    "    batch_size = output_shape[0]\n",
    "    num_classes = output_shape[1]\n",
    "    \n",
    "    output_mean = clean_outputs.mean(axis=0)\n",
    "    target_outputs = output_mean - clean_outputs\n",
    "    \n",
    "#     # No diversity, high divergence\n",
    "#     y = torch.zeros(size=output_shape).to(DEVICE)\n",
    "#     y[:, 0] = 100000  # Low diversity, high divergence\n",
    "#     y[:] = output_mean  # Low diversity, low divergence\n",
    "    \n",
    "#     y = target_outputs\n",
    "#     y = target_outputs * 0.1  # High diversity, low divergence \n",
    "    y = target_outputs * 1000  # High diversity, high divergence\n",
    "    \n",
    "    adversary = LinfPGDAttack(\n",
    "        model, loss_fn=myloss, eps=0.06,\n",
    "        nb_iter=50, eps_iter=0.01, \n",
    "        rand_init=True, clip_min=inputs.min().item(), clip_max=inputs.max().item(),\n",
    "        targeted=True\n",
    "    )\n",
    "    \n",
    "    adv_inputs = adversary.perturb(inputs, y)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        adv_outputs = model(adv_inputs).to('cpu').numpy()\n",
    "#     print(adv_outputs)\n",
    "    torch.cuda.empty_cache()\n",
    "    return adv_inputs.to('cpu').numpy()\n",
    "\n",
    "\n",
    "def get_comparable_models(target_model):\n",
    "    target_model_name = target_model.__str__()\n",
    "    target_model_segs = target_model_name.split('-')\n",
    "    parent_model_name = '-'.join(target_model_segs[:-2]) + '-'\n",
    "    parent_model = models_dict[parent_model_name]\n",
    "    # print(f'parent_model: {parent_model}')\n",
    "    reference_models = []\n",
    "    for model in models:\n",
    "        if not model.__str__().startswith(target_model_segs[0]):\n",
    "            reference_models.append(model)\n",
    "            # print(f'reference_model: {model}')\n",
    "    return parent_model, reference_models\n",
    "\n",
    "\n",
    "def compute_ddv(model, normal_inputs, adv_inputs):\n",
    "    normal_outputs = model.batch_forward(normal_inputs).cpu().numpy()\n",
    "    adv_outputs = model.batch_forward(adv_inputs).cpu().numpy()\n",
    "    output_pairs = zip(normal_outputs, adv_outputs)\n",
    "    # print(list(output_pairs)[0])\n",
    "    ddv = []  # DDV is short for decision distance vector\n",
    "    for i, (ya, yb) in enumerate(output_pairs):\n",
    "        dist = spatial.distance.cosine(ya, yb)\n",
    "        ddv.append(dist)\n",
    "    ddv = Utils.normalize(np.array(ddv))\n",
    "    return ddv\n",
    "\n",
    "\n",
    "def load_inputs(model):\n",
    "    inputs_path = os.path.join(model.torch_model_path, 'inputs.npz')\n",
    "    npzfile = np.load(inputs_path, allow_pickle=True)\n",
    "    seed_inputs = npzfile['seed_inputs']\n",
    "    adv_inputs = npzfile['adv_inputs']\n",
    "    saved_inputs = npzfile['saved_inputs'].item()\n",
    "    # print(saved_inputs)\n",
    "    return seed_inputs, adv_inputs\n",
    "    \n",
    "\n",
    "skip_steal_homo = True\n",
    "skip_quant_float = True\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    if not model.torch_model_exists():\n",
    "        continue\n",
    "    model_name = model.__str__()\n",
    "    if not model_name.startswith('pretrain'):\n",
    "        continue\n",
    "    if len(model_name.split('-')) < 3:\n",
    "        continue\n",
    "    if i < 6:\n",
    "        continue\n",
    "    if 'quantize(float16)' in model_name and skip_quant_float:\n",
    "        continue\n",
    "    if 'steal' in model_name and skip_steal_homo:\n",
    "        arch1 = model_name[model_name.find('(')+1:model_name.find(',')]\n",
    "        arch2 = model_name[model_name.rfind('(')+1:model_name.rfind(')')]\n",
    "        if arch1 == arch2:\n",
    "            continue\n",
    "\n",
    "#     if 'steal' not in model_name:\n",
    "#         continue        \n",
    "#     if 'quantize' not in model_name:\n",
    "#         continue\n",
    "#     if not model_name.endswith('prune(0.8)-'):\n",
    "#         continue\n",
    "#     if i != 50:\n",
    "#         continue\n",
    "    \n",
    "    parent_model, ref_models = get_comparable_models(model)\n",
    "    print(f'{i}\\t {model_name} testing')\n",
    "    \n",
    "    source_model = model\n",
    "    if 'quantize' in model_name:\n",
    "        model.torch_model.cpu()\n",
    "        source_model = parent_model\n",
    "    \n",
    "    seed_inputs = model.get_seed_inputs(100, rand=False)\n",
    "#     seed_inputs = np.array([seed_inputs[0]] * 100)  # remove diversity of inputs\n",
    "    adv_inputs = gen_adv_inputs(source_model.torch_model, seed_inputs)\n",
    "    \n",
    "#     adv_inputs = model.get_seed_inputs(100, rand=False)  # all normal inputs\n",
    "\n",
    "    # all adversarial inputs\n",
    "#     adv_inputs2 = gen_adv_inputs(source_model.torch_model, seed_inputs)\n",
    "#     seed_inputs = adv_inputs2\n",
    "\n",
    "#     seed_inputs, adv_inputs = load_inputs(model)  # load saved inputs\n",
    "    source_model.torch_model.to(DEVICE)\n",
    "    ddv = compute_ddv(model, seed_inputs, adv_inputs)\n",
    "    # print(f'self_sim: {spatial.distance.cosine(ddv, ddv):.4f}')\n",
    "    \n",
    "    parent_sim = 0\n",
    "    gap_min = 100\n",
    "    for i, ref_model in enumerate([parent_model] + ref_models):\n",
    "        if 'quantize' in ref_model.__str__(): # quantized models are equivalent to its teacher model\n",
    "            continue\n",
    "        try:\n",
    "            ref_model.torch_model.to(DEVICE)\n",
    "            ref_ddv = compute_ddv(ref_model, seed_inputs, adv_inputs)\n",
    "            ref_sim = spatial.distance.cosine(ddv, ref_ddv)\n",
    "            ref_model.torch_model.cpu()\n",
    "            if i == 0:\n",
    "                parent_sim = ref_sim\n",
    "                gap = 1\n",
    "                print(f'parent_sim: {ref_sim:.4f} {ref_model}')\n",
    "            else:\n",
    "                gap = ref_sim - parent_sim\n",
    "                if gap > 0:\n",
    "                    print(f'ref_sim: {ref_sim:.4f} gap={gap:.4f} {ref_model}')\n",
    "                else:\n",
    "                    print(f'{bcolors.WARNING}[ERROR] ref_sim: {ref_sim:.4f} gap={gap:.4f} {ref_model}{bcolors.ENDC}')\n",
    "                if gap < gap_min:\n",
    "                    gap_min = gap\n",
    "        except Exception as e:\n",
    "            print(f'failed to compare: {ref_model}')\n",
    "            print(f'exception: {e}')\n",
    "    print(f'--gap_min:{gap_min:.4f}, parent_sim:{parent_sim:.4f}, correct:{gap_min>0}, model:{model_name}')\n",
    "    # break\n",
    "    source_model.torch_model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(10, 3, 3)\n",
    "y = np.array([x[0]] * 10)\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
